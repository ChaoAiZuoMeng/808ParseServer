	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4123
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

<<<<<<< HEAD
2019-12-18 10:23:53 [ main:198 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 10:23:53 [ main:204 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 10:23:53 [ main:206 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 10:23:53 [ main:211 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 10:23:54 [ main:473 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 10:23:54 [ main:473 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 10:23:54 [ main:474 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 10:23:54 [ main:474 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 10:23:54 [ main:474 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 10:23:54 [ main:475 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 10:23:54 [ main:475 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 10:23:54 [ main:476 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 10:23:54 [ main:476 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 10:23:54 [ main:479 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 10:23:54 [ main:479 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 10:23:54 [ main:479 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 10:23:54 [ main:480 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 10:23:54 [ main:480 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 10:23:54 [ main:480 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 10:23:54 [ main:480 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 10:23:54 [ main:480 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 10:23:54 [ main:481 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 10:23:54 [ kafka-producer-network-thread | producer-1:483 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 10:23:54 [ main:484 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 10:23:54 [ main:484 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 10:23:54 [ main:486 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 10:23:54 [ kafka-producer-network-thread | producer-1:488 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 10:23:54 [ kafka-producer-network-thread | producer-1:488 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21509 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21510 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21510 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21511 ] - [ DEBUG ] [Producer clientId=producer-1] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:163)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21513 ] - [ DEBUG ] [Producer clientId=producer-1] Node -1 disconnected.
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21513 ] - [ WARN ] [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21513 ] - [ DEBUG ] [Producer clientId=producer-1] Give up sending metadata request since no node is available
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21565 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 10:24:15 [ kafka-producer-network-thread | producer-1:21565 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42582 ] - [ DEBUG ] [Producer clientId=producer-1] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:163)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42582 ] - [ DEBUG ] [Producer clientId=producer-1] Node -1 disconnected.
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42582 ] - [ WARN ] [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42582 ] - [ DEBUG ] [Producer clientId=producer-1] Give up sending metadata request since no node is available
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42633 ] - [ DEBUG ] [Producer clientId=producer-1] Give up sending metadata request since no node is available
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42684 ] - [ DEBUG ] [Producer clientId=producer-1] Give up sending metadata request since no node is available
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42735 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 10:24:36 [ kafka-producer-network-thread | producer-1:42735 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 10:27:04 [ main:83 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
=======
2019-12-18 11:02:38 [ main:12 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initializing the Kafka consumer
2019-12-18 11:02:38 [ main:187 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 11:02:38 [ main:256 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 11:02:38 [ main:285 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 11:02:38 [ main:291 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 11:02:38 [ main:292 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 11:02:38 [ main:293 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 11:02:38 [ main:294 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 11:02:38 [ main:295 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 11:02:38 [ main:296 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 11:02:38 [ main:297 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 11:02:38 [ main:298 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 11:02:38 [ main:352 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 11:02:38 [ main:353 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 11:02:38 [ main:353 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 11:02:38 [ main:356 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 11:02:38 [ main:363 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 11:02:38 [ main:364 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 11:02:38 [ main:365 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 11:02:38 [ main:365 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 11:02:38 [ main:368 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 11:02:38 [ main:368 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 11:02:38 [ main:371 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Kafka consumer initialized
2019-12-18 11:02:38 [ main:371 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Subscribed to topic(s): msg0200
2019-12-18 11:02:38 [ main:372 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 11:02:38 [ main:605 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 11:02:38 [ main:761 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 11:02:38 [ main:764 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 11:02:38 [ main:765 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 11:02:38 [ main:772 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 11:02:38 [ main:772 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed connection to node -1. Fetching API versions.
2019-12-18 11:02:38 [ main:772 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating API versions fetch from node -1.
2019-12-18 11:02:38 [ main:791 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 11:02:38 [ main:792 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 11:02:38 [ main:801 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 11:02:38 [ main:805 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576638158846, latencyMs=204, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 11:02:38 [ main:805 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 11:02:38 [ main:806 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 11:02:38 [ kafka-coordinator-heartbeat-thread | 4123:811 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Heartbeat thread started
2019-12-18 11:02:38 [ main:811 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending synchronous auto-commit of offsets {}
2019-12-18 11:02:38 [ main:811 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Revoking previously assigned partitions []
2019-12-18 11:02:38 [ main:812 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Disabling heartbeat thread
2019-12-18 11:02:38 [ main:812 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] (Re-)joining group
2019-12-18 11:02:38 [ main:815 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending JoinGroup ((type: JoinGroupRequest, groupId=4123, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@6646153)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 11:02:38 [ main:818 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 11:02:38 [ main:820 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 11:02:38 [ main:825 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 11:02:38 [ main:826 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 11:02:38 [ main:826 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 11:02:38 [ main:826 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating API versions fetch from node 2147483646.
2019-12-18 11:02:38 [ main:830 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 11:02:38 [ main:849 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@3a079870
2019-12-18 11:02:38 [ main:849 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Performing assignment using strategy range with subscriptions {consumer-1-a131765d-5aeb-4718-b1ce-d7ab432f3e59=Subscription(topics=[msg0200])}
2019-12-18 11:02:38 [ main:851 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Finished assignment for group: {consumer-1-a131765d-5aeb-4718-b1ce-d7ab432f3e59=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 11:02:38 [ main:854 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=4123, generationId=144, memberId=consumer-1-a131765d-5aeb-4718-b1ce-d7ab432f3e59, groupAssignment=consumer-1-a131765d-5aeb-4718-b1ce-d7ab432f3e59)
2019-12-18 11:02:38 [ main:864 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Successfully joined group with generation 144
2019-12-18 11:02:38 [ main:867 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Enabling heartbeat thread
2019-12-18 11:02:38 [ main:870 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 11:02:38 [ main:871 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 11:02:38 [ main:878 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Resetting offset for partition msg0200-0 to the committed offset 515
2019-12-18 11:02:38 [ main:878 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Resetting offset for partition msg0200-1 to the committed offset 508
2019-12-18 11:02:38 [ main:879 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:38 [ main:880 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:38 [ main:881 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:38 [ main:883 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:38 [ main:884 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 11:02:38 [ main:885 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 11:02:38 [ main:886 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 11:02:38 [ main:887 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 11:02:38 [ main:887 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed connection to node 1. Fetching API versions.
2019-12-18 11:02:38 [ main:887 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating API versions fetch from node 1.
2019-12-18 11:02:38 [ main:890 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 11:02:39 [ main:1411 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:39 [ main:1412 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:39 [ main:1418 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 11:02:39 [ main:1419 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 11:02:39 [ main:1420 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 11:02:39 [ main:1421 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 11:02:39 [ main:1422 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:39 [ main:1422 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:39 [ main:1422 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:39 [ main:1872 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 11:02:39 [ main:1887 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 515 for partition msg0200-0
2019-12-18 11:02:39 [ main:1887 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 508 for partition msg0200-1
2019-12-18 11:02:39 [ main:1888 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 11:02:39 [ main:1926 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:39 [ main:1926 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:39 [ main:1927 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:39 [ main:1927 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:39 [ main:1927 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:40 [ main:2430 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:40 [ main:2430 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:40 [ main:2431 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:40 [ main:2431 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:40 [ main:2431 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:40 [ main:2877 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 11:02:40 [ main:2879 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 515 for partition msg0200-0
2019-12-18 11:02:40 [ main:2879 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 508 for partition msg0200-1
2019-12-18 11:02:40 [ main:2879 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 11:02:40 [ main:2934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:40 [ main:2934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:40 [ main:2936 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:40 [ main:2936 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:40 [ main:2937 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:41 [ main:3440 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:41 [ main:3441 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 11:02:41 [ main:3441 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:41 [ main:3442 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 11:02:41 [ main:3442 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:11:42 [ main:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 14:11:42 [ main:4 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:11:42 [ main:136 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer has been closed
2019-12-18 14:14:10 [ main:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

<<<<<<< HEAD
2019-12-18 10:27:04 [ main:155 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 10:27:04 [ main:161 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 10:27:04 [ main:163 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 10:27:04 [ main:171 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 10:27:05 [ main:436 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 10:27:05 [ main:437 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 10:27:05 [ main:437 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 10:27:05 [ main:438 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 10:27:05 [ main:438 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 10:27:05 [ main:438 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 10:27:05 [ main:439 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 10:27:05 [ main:439 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 10:27:05 [ main:440 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 10:27:05 [ main:442 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 10:27:05 [ main:443 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 10:27:05 [ main:443 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 10:27:05 [ main:443 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 10:27:05 [ main:443 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 10:27:05 [ main:443 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 10:27:05 [ main:444 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 10:27:05 [ main:444 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 10:27:05 [ main:445 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:448 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 10:27:05 [ main:448 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 10:27:05 [ main:449 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 10:27:05 [ main:450 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:452 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:452 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:456 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:456 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:457 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:457 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:522 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:522 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:545 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:545 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:545 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:548 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:580 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:584 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:585 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:585 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:586 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:586 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:586 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:588 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:592 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:592 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:592 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:592 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:592 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 10:27:05 [ kafka-producer-network-thread | producer-1:595 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 10:59:13 [ main:80 ] - [ INFO ] ProducerConfig values: 
=======
2019-12-18 14:14:10 [ main:4 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:14:10 [ main:144 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:14:10 [ main:171 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 14:14:10 [ main:191 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:14:10 [ main:195 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:14:10 [ main:195 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:14:10 [ main:196 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:14:10 [ main:197 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:14:10 [ main:201 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:14:10 [ main:203 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:14:10 [ main:205 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:14:10 [ main:208 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:14:10 [ main:299 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 14:14:10 [ main:301 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 14:14:10 [ main:302 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 14:14:10 [ main:324 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 14:14:10 [ main:342 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 14:14:10 [ main:343 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 14:14:10 [ main:343 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 14:14:10 [ main:344 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 14:14:10 [ main:350 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:14:10 [ main:350 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:14:10 [ main:352 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 14:14:10 [ main:354 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 14:14:10 [ main:354 ] - [ INFO ] 开始接收数据。
2019-12-18 14:14:10 [ main:366 ] - [ INFO ] ProducerConfig values: 
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 10:59:13 [ main:151 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 10:59:13 [ main:157 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 10:59:13 [ main:159 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 10:59:13 [ main:163 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 10:59:13 [ main:424 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 10:59:13 [ main:424 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 10:59:13 [ main:425 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 10:59:13 [ main:425 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 10:59:13 [ main:425 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 10:59:13 [ main:426 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 10:59:13 [ main:426 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 10:59:13 [ main:427 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 10:59:13 [ main:427 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 10:59:13 [ main:430 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 10:59:13 [ main:430 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 10:59:13 [ main:430 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 10:59:13 [ main:430 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 10:59:13 [ main:431 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 10:59:13 [ main:431 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 10:59:13 [ main:431 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 10:59:13 [ main:431 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 10:59:13 [ main:432 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 10:59:13 [ kafka-producer-network-thread | producer-1:434 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 10:59:13 [ main:435 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 10:59:13 [ main:435 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 10:59:13 [ main:437 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 10:59:13 [ kafka-producer-network-thread | producer-1:439 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 10:59:13 [ kafka-producer-network-thread | producer-1:439 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 10:59:13 [ kafka-producer-network-thread | producer-1:443 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 10:59:13 [ kafka-producer-network-thread | producer-1:444 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 10:59:13 [ kafka-producer-network-thread | producer-1:444 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 10:59:13 [ kafka-producer-network-thread | producer-1:444 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:510 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:510 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:518 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:518 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:518 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:520 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:535 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:540 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:541 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:541 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:545 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:546 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:546 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:546 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:547 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 10:59:14 [ kafka-producer-network-thread | producer-1:548 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 11:05:13 [ main:73 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
=======
2019-12-18 14:14:10 [ main:391 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:14:10 [ main:396 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:14:10 [ main:396 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:14:10 [ main:405 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:14:10 [ main:406 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:14:10 [ main:407 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:14:10 [ main:407 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:14:10 [ main:408 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:14:10 [ main:408 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:14:10 [ main:409 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:14:10 [ main:410 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:14:10 [ main:416 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:14:10 [ main:418 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:14:10 [ main:420 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:14:10 [ main:421 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:14:10 [ main:421 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:14:10 [ main:422 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:14:10 [ main:422 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:14:10 [ main:423 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:14:10 [ main:423 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:14:10 [ main:424 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:14:10 [ main:430 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:14:10 [ kafka-producer-network-thread | producer-1:431 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:14:10 [ main:431 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:14:10 [ main:432 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:14:10 [ main:433 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:14:10 [ main:433 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:14:10 [ main:603 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:14:10 [ main:790 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:14:10 [ main:792 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:14:10 [ main:806 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:14:10 [ main:813 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 14:14:10 [ main:814 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 14:14:10 [ main:816 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 14:14:10 [ main:844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:14:10 [ main:845 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:14:10 [ main:852 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 14:14:10 [ main:854 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576649650963, latencyMs=262, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 14:14:10 [ main:854 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:14:10 [ main:854 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:14:10 [ kafka-coordinator-heartbeat-thread | serviceSys:857 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 14:14:10 [ main:857 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 14:14:10 [ main:857 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 14:14:10 [ main:857 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 14:14:10 [ main:858 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 14:14:10 [ main:860 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@5db250b4)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:14:10 [ main:862 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 14:14:10 [ main:863 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 14:14:10 [ main:864 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 14:14:10 [ main:865 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 14:14:10 [ main:865 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 14:14:10 [ main:865 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 14:14:10 [ main:870 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:14:11 [ main:892 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@3c72f59f
2019-12-18 14:14:11 [ main:893 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-888e3371-5856-47ef-aff7-480087d3ecdf=Subscription(topics=[msg0200])}
2019-12-18 14:14:11 [ main:895 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-888e3371-5856-47ef-aff7-480087d3ecdf=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 14:14:11 [ main:896 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=1, memberId=consumer-1-888e3371-5856-47ef-aff7-480087d3ecdf, groupAssignment=consumer-1-888e3371-5856-47ef-aff7-480087d3ecdf)
2019-12-18 14:14:11 [ main:919 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 1
2019-12-18 14:14:11 [ main:920 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 14:14:11 [ main:923 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 14:14:11 [ main:925 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 14:14:11 [ main:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Found no committed offset for partition msg0200-0
2019-12-18 14:14:11 [ main:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Found no committed offset for partition msg0200-1
2019-12-18 14:14:11 [ main:930 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ main:932 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 14:14:11 [ main:933 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 14:14:11 [ main:934 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 14:14:11 [ main:935 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 14:14:11 [ main:935 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 14:14:11 [ main:936 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 14:14:11 [ main:943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:14:11 [ main:961 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Handling ListOffsetResponse response for msg0200-0. Fetched offset 415, timestamp -1
2019-12-18 14:14:11 [ main:962 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Handling ListOffsetResponse response for msg0200-1. Fetched offset 407, timestamp -1
2019-12-18 14:14:11 [ main:962 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to offset 415.
2019-12-18 14:14:11 [ main:963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to offset 407.
2019-12-18 14:14:11 [ main:964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 407 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ main:964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 415 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ main:964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ main:985 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 407 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=7044)
2019-12-18 14:14:11 [ main:986 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 415 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=6900)
2019-12-18 14:14:11 [ main:1036 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 14:14:11 [ main:1044 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 14:14:11 [ main:1044 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 14:14:11 [ main:1045 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 14:14:11 [ main:1046 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ main:1046 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ main:1046 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ main:1049 ] - [ INFO ] 接收到201条数据。
2019-12-18 14:14:11 [ main:1052 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1052 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1252 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1255 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1259 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1259 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1259 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1260 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1260 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1260 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1260 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1260 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1261 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1262 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1262 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1262 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1262 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1263 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1263 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1263 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1264 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1265 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1265 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1266 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1266 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1266 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1266 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1266 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1266 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1267 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1267 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1267 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1267 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1267 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1267 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1268 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1268 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1268 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1268 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1268 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1269 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1269 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1269 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1269 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1269 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1270 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1270 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1270 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1270 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1270 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1271 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1271 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1271 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1271 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1271 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1272 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1272 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1272 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1273 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1273 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1273 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1273 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1274 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1274 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1274 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1274 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1275 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1276 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1279 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1280 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1280 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1280 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1281 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1282 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1282 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1283 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1283 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1283 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1283 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1284 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1284 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1285 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1285 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1285 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1285 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1285 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1285 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1286 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1286 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1286 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1286 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1293 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1293 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1294 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1294 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1294 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1294 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1294 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1295 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1295 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1295 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1295 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1296 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1297 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1297 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1297 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1297 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1297 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1297 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1297 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1298 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1298 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1298 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1298 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1298 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1298 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1299 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1299 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1299 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1299 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1299 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1299 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1299 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1299 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1300 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1300 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1300 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1300 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1300 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1300 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1300 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1301 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1301 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1301 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1301 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1301 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1301 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1301 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1301 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1302 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1302 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1302 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1309 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1332 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1332 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1332 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1332 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1333 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1333 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1333 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1333 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1333 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1333 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1333 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1333 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1333 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1334 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1334 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1334 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1334 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1334 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1334 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1334 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1334 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1335 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1335 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1335 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1335 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1339 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1339 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1340 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1340 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1340 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1340 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1340 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1340 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1341 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1341 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1341 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1341 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1341 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1341 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1341 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1341 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1342 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1342 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1342 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1342 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1342 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1342 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1342 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1343 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1343 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1343 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1343 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1343 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1346 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1347 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1347 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1347 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1347 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1347 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1347 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1348 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1348 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1348 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1348 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1348 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1348 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1348 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1348 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1349 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1349 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1349 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1349 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1349 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1349 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1349 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1349 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1349 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1350 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1350 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1350 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1350 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1350 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1350 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1350 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1350 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1350 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1351 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1351 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1351 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1351 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1351 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1359 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1377 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1377 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1377 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1430 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1430 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1430 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1430 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1430 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1430 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1430 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1430 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1431 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1431 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1432 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1432 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1432 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1432 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1432 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1432 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1432 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1432 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1433 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1433 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1433 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1433 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1433 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1433 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1433 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1433 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1433 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1434 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1434 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1434 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1434 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1434 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1434 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1434 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1434 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1434 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1434 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1434 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1434 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1435 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1435 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1435 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1435 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1435 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1435 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1435 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1435 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1436 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1436 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1436 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1436 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1436 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1436 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1437 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1437 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1437 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1437 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1437 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1437 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1437 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1437 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1437 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1437 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1437 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1438 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1438 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1438 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1438 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1438 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1438 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1438 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1438 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1438 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1438 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1438 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1438 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1439 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1439 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1439 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1439 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1439 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1439 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1443 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1443 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1443 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1443 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1443 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1443 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1443 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1444 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1444 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1445 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1446 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1446 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1446 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1446 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1446 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1446 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1446 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1460 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1460 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1460 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1460 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1460 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1460 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1460 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1460 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1461 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1461 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1461 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1461 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1461 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1461 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1461 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1461 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1480 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1481 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1481 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1482 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1482 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1482 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1482 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1482 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1483 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1483 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1483 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1483 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1483 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1483 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1483 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1483 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1483 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1483 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1483 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1483 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1483 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1484 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1484 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1484 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1484 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1484 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1484 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1484 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1484 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1484 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:11 [ main:1484 ] - [ INFO ] hex: 01
2019-12-18 14:14:11 [ main:1484 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:11 [ main:1484 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:11 [ main:1485 ] - [ INFO ] 接收到的数据为: 1 49 112 56 -103 37 0 0 0 32 0 12 0 13 1 -31 91 4 7 43 116 -41 0 41 0 0 0 -78 24 5 39 35 83 81 1 4 0 0 0 19 3 2 0 0 37 4 0 0 0 0 48 1 26 49 1 0 -5 16 0 -1 -1 -1 0 -1 -1 -1 0 -1 -1 -1 0 -1 -1 -1 
2019-12-18 14:14:11 [ main:1485 ] - [ INFO ] hex: 01317038992500000020000c000d01e15b04072b74d70029000000b21805272353510104000000130302000025040000000030011a310100fb1000ffffff00ffffff00ffffff00ffffff
2019-12-18 14:14:11 [ main:1620 ] - [ INFO ] 开始发送数据 ---
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1622 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1623 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1628 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1629 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1631 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1631 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1631 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1631 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1639 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1639 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=gateway) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:14:11 [ kafka-coordinator-heartbeat-thread | serviceSys:1643 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:11 [ kafka-coordinator-heartbeat-thread | serviceSys:1643 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1649 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = gateway, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = gateway, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 14:14:11 [ main:1668 ] - [ INFO ] 发送的数据为10 5 18 1 48 48 32 18 107 10 12 48 49 51 49 55 48 51 56 57 57 50 53 18 19 50 48 49 57 45 49 50 45 49 56 32 49 52 58 49 52 58 49 49 34 3 49 46 57 66 0 74 19 50 48 49 56 45 48 53 45 50 55 32 50 51 58 53 51 58 53 49 82 10 49 50 48 46 50 57 57 54 51 49 90 9 51 49 46 53 52 57 56 53 53 98 1 48 106 3 49 55 56 114 2 52 49 122 3 48 46 48 -94 1 1 49 26 4 88 -115 -128 48 34 0 
2019-12-18 14:14:11 [ main:1670 ] - [ INFO ] hex: 0a051201303020126b0a0c3031333137303338393932351213323031392d31322d31382031343a31343a31312203312e3942004a13323031382d30352d32372032333a35333a3531520a3132302e3239393633315a0933312e3534393835356201306a03313738720234317a03302e30a20101311a04588d80302200
2019-12-18 14:14:11 [ main:1671 ] - [ INFO ] 以上数据发送成功 ---
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1674 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1679 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1681 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1682 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1682 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1682 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1682 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1699 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1700 ] - [ DEBUG ] Added sensor with name topic.gateway.records-per-batch
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1700 ] - [ DEBUG ] Added sensor with name topic.gateway.bytes
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1700 ] - [ DEBUG ] Added sensor with name topic.gateway.compression-rate
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1701 ] - [ DEBUG ] Added sensor with name topic.gateway.record-retries
2019-12-18 14:14:11 [ kafka-producer-network-thread | producer-1:1701 ] - [ DEBUG ] Added sensor with name topic.gateway.record-errors
2019-12-18 14:14:12 [ main:1974 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1974 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1974 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1975 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1975 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1975 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1975 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1975 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1975 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1975 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1975 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1976 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1976 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1976 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1976 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1976 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1976 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1976 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1977 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1977 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1977 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1977 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1978 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1979 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1981 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1982 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1982 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1982 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1982 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1982 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1982 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1982 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1982 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1982 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1982 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1982 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1983 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1983 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1983 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1983 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1983 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1983 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1983 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1984 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1984 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1984 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1984 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1984 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1985 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1985 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1985 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1985 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1985 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1985 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1985 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1985 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1985 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1985 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1985 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1985 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1985 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1986 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1986 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1986 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1986 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1986 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1986 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1986 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1986 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1986 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1986 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1986 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1986 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1987 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1987 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1987 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1987 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1987 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1987 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1987 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1987 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1987 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1987 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1987 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1988 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1988 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1988 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1988 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1988 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1988 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1988 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1988 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1988 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1988 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1988 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1988 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1989 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1989 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1989 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1989 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1989 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1989 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1989 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1989 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1989 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1989 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1989 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1990 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1990 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1990 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1990 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1990 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1990 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1990 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1990 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1990 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1990 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1990 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1990 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1991 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1991 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1991 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1991 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1991 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1991 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1991 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1991 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1991 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1991 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1991 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1991 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1992 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1992 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1992 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1992 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1992 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1992 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1992 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1992 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1992 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1992 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1992 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1992 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1992 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1994 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1994 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1994 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1994 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1994 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1994 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1995 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1995 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1995 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1995 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1995 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1995 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1995 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1995 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1995 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1996 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1996 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1996 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1996 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1996 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1996 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1996 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1996 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1996 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1996 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1996 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1996 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1996 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1997 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1997 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1997 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1997 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1997 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1997 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1997 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1998 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1998 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1998 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1998 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1998 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1998 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1998 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1998 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1998 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1998 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1998 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1998 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1999 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1999 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1999 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1999 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1999 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1999 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1999 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1999 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1999 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:1999 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:1999 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:1999 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:1999 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2000 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2000 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2000 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2000 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2000 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2000 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2000 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2000 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2000 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2000 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2000 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2000 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2001 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2001 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2001 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2001 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2001 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2001 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2001 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2001 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2001 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2001 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2001 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2001 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2001 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2002 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2002 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2003 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2003 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2003 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2003 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2003 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2003 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2004 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2004 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2004 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2005 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2005 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2005 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2005 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2006 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2006 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2006 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2006 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2006 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2006 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2006 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2006 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2007 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2007 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2007 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2007 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2007 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2007 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2007 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2008 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2008 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2008 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2011 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2011 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2011 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2012 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2012 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2013 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2013 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2013 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2013 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2013 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2013 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2014 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2014 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2014 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2014 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2014 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2014 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2015 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2019 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2019 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2020 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2020 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2020 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2020 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2020 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2020 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2020 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2021 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2021 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2021 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2021 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2022 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2022 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2022 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2022 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2022 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2022 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2022 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2022 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2022 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2022 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2022 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2022 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2023 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2023 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2023 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2023 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2023 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2023 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2023 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2024 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2024 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2024 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2024 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2024 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2024 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2024 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2024 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2024 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2024 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2024 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2024 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2024 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2025 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2025 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2025 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2025 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2025 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2025 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2025 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2025 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2025 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2025 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2025 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2025 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2025 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2026 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2026 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2026 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2026 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2026 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2026 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2026 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2026 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2107 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2107 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2107 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2107 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2107 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2108 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2108 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2108 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2108 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2108 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2108 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2108 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2108 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2108 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2108 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2108 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2108 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2122 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2122 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2122 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2122 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2122 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2122 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2123 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2123 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2123 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2123 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2123 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2123 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2123 ] - [ INFO ] 接收到的数据为: 1 
2019-12-18 14:14:12 [ main:2123 ] - [ INFO ] hex: 01
2019-12-18 14:14:12 [ main:2123 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:14:12 [ main:2123 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:14:12 [ main:2124 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:12 [ main:2129 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:12 [ main:2130 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:12 [ main:2130 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:12 [ main:2142 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:14:12 [ main:2142 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:14:12 [ main:2143 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:12 [ main:2635 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:12 [ main:2635 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:12 [ main:2635 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:12 [ main:2635 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:12 [ main:2635 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:13 [ main:3124 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:14:13 [ main:3124 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:13 [ main:3128 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:14:13 [ main:3128 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:14:13 [ main:3128 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:13 [ main:3139 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:13 [ main:3140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:13 [ main:3140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:13 [ main:3140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:13 [ main:3140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:13 [ main:3645 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:13 [ main:3645 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:13 [ main:3645 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:13 [ main:3645 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:13 [ main:3645 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:14 [ kafka-coordinator-heartbeat-thread | serviceSys:3925 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:14:14 [ main:3929 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 14:14:14 [ main:4130 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:14:14 [ main:4130 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:14 [ main:4133 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:14:14 [ main:4134 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:14:14 [ main:4134 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:14 [ main:4149 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:14 [ main:4149 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:14 [ main:4150 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:14 [ main:4150 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:14 [ main:4150 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:14 [ main:4654 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:14 [ main:4654 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:14 [ main:4654 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:14 [ main:4655 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:14 [ main:4655 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:15 [ main:5133 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:14:15 [ main:5133 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:15 [ main:5140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:14:15 [ main:5140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:14:15 [ main:5141 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:15 [ main:5158 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:15 [ main:5158 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:15 [ main:5159 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:15 [ main:5159 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:15 [ main:5159 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:15 [ main:5662 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:15 [ main:5663 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:15 [ main:5663 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:15 [ main:5663 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:15 [ main:5663 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:16 [ main:6138 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:14:16 [ main:6139 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:16 [ main:6142 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:14:16 [ main:6142 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:14:16 [ main:6142 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:16 [ main:6166 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:16 [ main:6166 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:16 [ main:6166 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:16 [ main:6166 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:16 [ main:6166 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:16 [ main:6670 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:16 [ main:6671 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:16 [ main:6671 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:16 [ main:6671 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:16 [ main:6672 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:17 [ kafka-coordinator-heartbeat-thread | serviceSys:6929 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:14:17 [ main:6931 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 14:14:17 [ main:7142 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:14:17 [ main:7142 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:17 [ main:7146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:14:17 [ main:7146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:14:17 [ main:7146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:14:17 [ main:7175 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:17 [ main:7175 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:14:17 [ main:7176 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:17 [ main:7176 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:14:17 [ main:7176 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:16:59 [ Thread-0:1 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
<<<<<<< HEAD
	enable.idempotence = false
=======
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 11:05:13 [ main:146 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 11:05:13 [ main:159 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 11:05:13 [ main:161 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 11:05:13 [ main:166 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 11:05:13 [ main:425 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 11:05:13 [ main:425 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 11:05:13 [ main:426 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 11:05:13 [ main:426 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 11:05:13 [ main:426 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 11:05:13 [ main:426 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 11:05:13 [ main:427 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 11:05:13 [ main:427 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 11:05:13 [ main:428 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 11:05:13 [ main:431 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 11:05:13 [ main:431 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 11:05:13 [ main:431 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 11:05:13 [ main:431 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 11:05:13 [ main:432 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 11:05:13 [ main:432 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 11:05:13 [ main:432 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 11:05:13 [ main:432 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 11:05:13 [ main:433 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:435 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 11:05:13 [ main:436 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 11:05:13 [ main:436 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 11:05:13 [ main:437 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:439 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:439 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:443 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:444 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:444 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:445 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:507 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:507 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:514 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:514 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:514 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:518 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:531 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:535 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:536 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:536 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:536 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:536 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:536 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:538 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 11:05:13 [ kafka-producer-network-thread | producer-1:545 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 11:12:09 [ main:73 ] - [ INFO ] ProducerConfig values: 
=======
2019-12-18 14:16:59 [ Thread-0:5 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:16:59 [ Thread-0:176 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:16:59 [ Thread-0:202 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 14:17:00 [ Thread-0:282 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:17:00 [ Thread-0:293 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:17:00 [ Thread-0:299 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:17:00 [ Thread-0:299 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:17:00 [ Thread-0:300 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:17:00 [ Thread-0:304 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:17:00 [ Thread-0:307 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:17:00 [ Thread-0:310 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:17:00 [ Thread-0:312 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:17:00 [ Thread-0:351 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 14:17:00 [ Thread-0:352 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 14:17:00 [ Thread-0:353 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 14:17:00 [ Thread-0:358 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 14:17:00 [ Thread-0:365 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 14:17:00 [ Thread-0:366 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 14:17:00 [ Thread-0:367 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 14:17:00 [ Thread-0:368 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 14:17:00 [ Thread-0:373 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:17:00 [ Thread-0:373 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:17:00 [ Thread-0:375 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 14:17:00 [ Thread-0:376 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 14:17:00 [ Thread-0:377 ] - [ INFO ] 开始接收数据。
2019-12-18 14:17:00 [ Thread-0:400 ] - [ INFO ] ProducerConfig values: 
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 11:12:09 [ main:140 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 11:12:09 [ main:146 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 11:12:09 [ main:148 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 11:12:09 [ main:153 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 11:12:09 [ main:425 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 11:12:09 [ main:425 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 11:12:09 [ main:425 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 11:12:09 [ main:426 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 11:12:09 [ main:426 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 11:12:09 [ main:426 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 11:12:09 [ main:427 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 11:12:09 [ main:427 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 11:12:09 [ main:428 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 11:12:09 [ main:431 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 11:12:09 [ main:431 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 11:12:09 [ main:431 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 11:12:09 [ main:431 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 11:12:09 [ main:431 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 11:12:09 [ main:432 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 11:12:09 [ main:432 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 11:12:09 [ main:432 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 11:12:09 [ main:433 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:434 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 11:12:09 [ main:436 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 11:12:09 [ main:436 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 11:12:09 [ main:437 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:439 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:439 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:443 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:444 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:445 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:445 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:512 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:512 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:519 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:520 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:520 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:522 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:536 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:540 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:541 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:546 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:546 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:546 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:546 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:547 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 11:12:09 [ kafka-producer-network-thread | producer-1:549 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 11:40:14 [ main:77 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
=======
2019-12-18 14:17:00 [ Thread-0:424 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:17:00 [ Thread-0:436 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:17:00 [ Thread-0:437 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:17:00 [ Thread-0:443 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:17:00 [ Thread-0:443 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:17:00 [ Thread-0:447 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:17:00 [ Thread-0:448 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:17:00 [ Thread-0:450 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:17:00 [ Thread-0:451 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:17:00 [ Thread-0:452 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:17:00 [ Thread-0:454 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:17:00 [ Thread-0:457 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:17:00 [ Thread-0:459 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:17:00 [ Thread-0:461 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:17:00 [ Thread-0:462 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:17:00 [ Thread-0:462 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:17:00 [ Thread-0:463 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:17:00 [ Thread-0:463 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:17:00 [ Thread-0:464 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:17:00 [ Thread-0:465 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:17:00 [ Thread-0:465 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:17:00 [ Thread-0:471 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:17:00 [ kafka-producer-network-thread | producer-1:473 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:17:00 [ Thread-0:473 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:17:00 [ Thread-0:473 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:17:00 [ Thread-0:473 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:17:00 [ Thread-0:474 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:00 [ Thread-0:753 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:00 [ Thread-0:863 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:17:00 [ Thread-0:864 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:17:00 [ Thread-0:865 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:17:00 [ Thread-0:871 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:190)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:219)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:00 [ Thread-0:874 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:00 [ Thread-0:875 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:00 [ Thread-0:882 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Cancelled FIND_COORDINATOR request RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0) with correlation id 0 due to node -1 being disconnected
2019-12-18 14:17:00 [ Thread-0:882 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Coordinator discovery failed, refreshing metadata
2019-12-18 14:17:00 [ Thread-0:882 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:00 [ Thread-0:884 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:00 [ Thread-0:937 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:00 [ Thread-0:938 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:00 [ Thread-0:939 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:00 [ Thread-0:939 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:00 [ Thread-0:939 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:00 [ Thread-0:940 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:00 [ Thread-0:995 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:00 [ Thread-0:1048 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:00 [ Thread-0:1100 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:00 [ Thread-0:1101 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:00 [ Thread-0:1102 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:00 [ Thread-0:1103 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:00 [ Thread-0:1104 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:00 [ Thread-0:1104 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:00 [ Thread-0:1160 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:00 [ Thread-0:1216 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1274 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1329 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:01 [ Thread-0:1329 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:01 [ Thread-0:1334 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:01 [ Thread-0:1335 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:01 [ Thread-0:1335 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:01 [ Thread-0:1336 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1387 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1443 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1497 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1548 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1602 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1654 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1710 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:01 [ Thread-0:1710 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:01 [ Thread-0:1711 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:01 [ Thread-0:1712 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:01 [ Thread-0:1712 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:01 [ Thread-0:1712 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1764 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1819 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1875 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1929 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:1983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:2034 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:2089 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:2140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:01 [ Thread-0:2195 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2250 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2303 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2355 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2410 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2464 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2519 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2574 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2628 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2680 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:02 [ Thread-0:2681 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:02 [ Thread-0:2681 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:02 [ Thread-0:2682 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:02 [ Thread-0:2682 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:02 [ Thread-0:2682 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2736 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2791 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2845 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2899 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:2954 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:3005 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:3059 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:3113 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:02 [ Thread-0:3168 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3223 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3278 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3332 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3387 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3442 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3496 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3549 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3604 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3658 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3712 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3767 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:03 [ Thread-0:3767 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:03 [ Thread-0:3768 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:03 [ Thread-0:3769 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:03 [ Thread-0:3769 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:03 [ Thread-0:3769 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3824 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3880 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:3989 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:4045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:4098 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:4153 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:03 [ Thread-0:4207 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4260 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4317 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4371 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4424 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4478 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4533 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4587 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4642 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4696 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4752 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:04 [ Thread-0:4755 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:04 [ Thread-0:4756 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:04 [ Thread-0:4758 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:04 [ Thread-0:4759 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:04 [ Thread-0:4759 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4813 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4866 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4920 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:4975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:5027 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:5082 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:5136 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:04 [ Thread-0:5191 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5246 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5299 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5353 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5407 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5458 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5514 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5569 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5624 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:05 [ Thread-0:5624 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:05 [ Thread-0:5625 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:05 [ Thread-0:5626 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:05 [ Thread-0:5626 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:05 [ Thread-0:5626 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5681 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5735 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5790 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5898 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:5953 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:6003 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:6059 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:6113 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:05 [ Thread-0:6165 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6219 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6271 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6324 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6379 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6432 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6487 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6541 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:17:06 [ Thread-0:6541 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:17:06 [ Thread-0:6542 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:17:06 [ Thread-0:6543 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:17:06 [ Thread-0:6544 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:17:06 [ Thread-0:6544 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6598 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6654 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6709 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6763 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6816 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6870 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6923 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:6975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:7031 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:7086 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:7140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:06 [ Thread-0:7192 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:07 [ Thread-0:7246 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:07 [ Thread-0:7301 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:07 [ Thread-0:7356 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:07 [ Thread-0:7411 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:17:15 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
<<<<<<< HEAD
	enable.idempotence = false
=======
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 14:17:15 [ Thread-0:4 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:19:01 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 11:40:14 [ main:144 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 11:40:14 [ main:150 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 11:40:14 [ main:152 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 11:40:14 [ main:156 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 11:40:14 [ main:411 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 11:40:14 [ main:411 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 11:40:14 [ main:412 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 11:40:14 [ main:412 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 11:40:14 [ main:412 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 11:40:14 [ main:412 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 11:40:14 [ main:413 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 11:40:14 [ main:413 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 11:40:14 [ main:414 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 11:40:14 [ main:417 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 11:40:14 [ main:417 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 11:40:14 [ main:417 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 11:40:14 [ main:417 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 11:40:14 [ main:417 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 11:40:14 [ main:418 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 11:40:14 [ main:418 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 11:40:14 [ main:418 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 11:40:14 [ main:419 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:421 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 11:40:14 [ main:422 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 11:40:14 [ main:422 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 11:40:14 [ main:423 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:425 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:425 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:429 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:430 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:431 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:431 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:498 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:498 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:505 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:505 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:505 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:508 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:521 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:525 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:526 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:526 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:527 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:527 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:527 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:528 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:531 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:531 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:532 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:532 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:532 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 11:40:14 [ kafka-producer-network-thread | producer-1:534 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 13:12:26 [ main:67 ] - [ INFO ] ProducerConfig values: 
=======
2019-12-18 14:19:01 [ Thread-0:5 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:19:01 [ Thread-0:151 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:19:01 [ Thread-0:182 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 14:19:01 [ Thread-0:215 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:19:01 [ Thread-0:223 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:19:01 [ Thread-0:224 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:19:01 [ Thread-0:224 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:19:01 [ Thread-0:226 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:19:01 [ Thread-0:234 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:19:01 [ Thread-0:236 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:19:01 [ Thread-0:238 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:19:01 [ Thread-0:240 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:19:01 [ Thread-0:317 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 14:19:01 [ Thread-0:319 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 14:19:01 [ Thread-0:321 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 14:19:01 [ Thread-0:327 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 14:19:01 [ Thread-0:334 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 14:19:01 [ Thread-0:335 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 14:19:01 [ Thread-0:336 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 14:19:01 [ Thread-0:337 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 14:19:01 [ Thread-0:342 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:19:01 [ Thread-0:342 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:19:01 [ Thread-0:345 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 14:19:01 [ Thread-0:346 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 14:19:01 [ Thread-0:347 ] - [ INFO ] 开始接收数据。
2019-12-18 14:19:01 [ Thread-0:362 ] - [ INFO ] ProducerConfig values: 
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 13:12:26 [ main:139 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 13:12:26 [ main:148 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 13:12:26 [ main:151 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 13:12:26 [ main:156 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 13:12:27 [ main:417 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 13:12:27 [ main:417 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 13:12:27 [ main:417 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 13:12:27 [ main:418 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 13:12:27 [ main:418 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 13:12:27 [ main:418 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 13:12:27 [ main:419 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 13:12:27 [ main:419 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 13:12:27 [ main:420 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 13:12:27 [ main:422 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 13:12:27 [ main:423 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 13:12:27 [ main:423 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 13:12:27 [ main:423 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 13:12:27 [ main:423 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 13:12:27 [ main:423 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 13:12:27 [ main:424 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 13:12:27 [ main:424 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 13:12:27 [ main:425 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:427 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 13:12:27 [ main:427 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 13:12:27 [ main:428 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 13:12:27 [ main:429 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:431 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:431 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:435 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:436 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:436 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:437 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:504 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:504 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:511 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:512 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:512 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:514 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:528 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:532 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:533 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:533 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:534 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:534 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:534 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:535 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:538 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:538 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:538 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:538 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:539 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 13:12:27 [ kafka-producer-network-thread | producer-1:541 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 13:21:48 [ main:70 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
=======
2019-12-18 14:19:01 [ Thread-0:384 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:19:01 [ Thread-0:394 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:19:01 [ Thread-0:398 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:19:01 [ Thread-0:404 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:19:01 [ Thread-0:405 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:19:01 [ Thread-0:406 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:19:01 [ Thread-0:406 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:19:01 [ Thread-0:407 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:19:01 [ Thread-0:408 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:19:01 [ Thread-0:408 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:19:01 [ Thread-0:410 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:19:01 [ Thread-0:411 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:19:01 [ Thread-0:413 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:19:01 [ Thread-0:415 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:19:01 [ Thread-0:416 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:19:01 [ Thread-0:416 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:19:01 [ Thread-0:416 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:19:01 [ Thread-0:417 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:19:01 [ Thread-0:417 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:19:01 [ Thread-0:417 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:19:01 [ Thread-0:418 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:19:01 [ Thread-0:424 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:19:01 [ Thread-0:426 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:19:01 [ kafka-producer-network-thread | producer-1:426 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:19:01 [ Thread-0:426 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:19:01 [ Thread-0:427 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:19:01 [ Thread-0:429 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:01 [ Thread-0:703 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:01 [ Thread-0:823 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:19:01 [ Thread-0:824 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:19:01 [ Thread-0:825 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:19:01 [ Thread-0:834 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:190)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:219)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:01 [ Thread-0:837 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:01 [ Thread-0:838 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:01 [ Thread-0:841 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Cancelled FIND_COORDINATOR request RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0) with correlation id 0 due to node -1 being disconnected
2019-12-18 14:19:01 [ Thread-0:841 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Coordinator discovery failed, refreshing metadata
2019-12-18 14:19:01 [ Thread-0:842 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:01 [ Thread-0:844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:899 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:02 [ Thread-0:899 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:02 [ Thread-0:901 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:02 [ Thread-0:903 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:02 [ Thread-0:903 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:02 [ Thread-0:904 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:958 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1013 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:02 [ Thread-0:1013 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:02 [ Thread-0:1014 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:02 [ Thread-0:1014 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:02 [ Thread-0:1015 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:02 [ Thread-0:1016 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1068 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1121 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1174 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1228 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:02 [ Thread-0:1228 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:02 [ Thread-0:1229 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:02 [ Thread-0:1229 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:02 [ Thread-0:1230 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:02 [ Thread-0:1230 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1281 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1336 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1391 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1442 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1493 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1549 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1600 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1653 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1708 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:02 [ Thread-0:1708 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:02 [ Thread-0:1709 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:02 [ Thread-0:1709 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:02 [ Thread-0:1710 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:02 [ Thread-0:1710 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1764 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1819 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:02 [ Thread-0:1870 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:1923 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:1977 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2032 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2082 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2136 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2191 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2244 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2299 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2354 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2408 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2461 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2515 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2568 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:03 [ Thread-0:2568 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:03 [ Thread-0:2568 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:03 [ Thread-0:2569 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:03 [ Thread-0:2569 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:03 [ Thread-0:2569 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2624 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2678 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2732 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2786 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:03 [ Thread-0:2840 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:2893 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:2947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:2999 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3055 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3114 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3170 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3224 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3277 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3332 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3383 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3438 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:04 [ Thread-0:3439 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:04 [ Thread-0:3440 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:04 [ Thread-0:3440 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:04 [ Thread-0:3441 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:04 [ Thread-0:3441 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3495 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3548 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3602 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3658 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3713 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3767 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3821 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:04 [ Thread-0:3875 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:3930 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:3984 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4039 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4094 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4148 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4203 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4257 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4310 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4365 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4419 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4474 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4528 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4583 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:05 [ Thread-0:4583 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:05 [ Thread-0:4584 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:05 [ Thread-0:4585 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:05 [ Thread-0:4586 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:05 [ Thread-0:4586 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4641 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4692 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4744 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4799 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:05 [ Thread-0:4855 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:4911 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:4966 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5021 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5076 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5130 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5183 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5237 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5292 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5344 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5399 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5453 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5507 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5561 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5616 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5669 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5724 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5777 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:06 [ Thread-0:5777 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:06 [ Thread-0:5778 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:06 [ Thread-0:5778 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:06 [ Thread-0:5778 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:06 [ Thread-0:5779 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:06 [ Thread-0:5833 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:5885 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:5940 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:5995 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6049 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6103 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6157 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6211 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6265 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6321 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6374 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6427 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6482 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6537 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6591 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6642 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6698 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6753 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6806 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:07 [ Thread-0:6862 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:07 [ Thread-0:6862 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:07 [ Thread-0:6863 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:07 [ Thread-0:6864 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:07 [ Thread-0:6864 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:07 [ Thread-0:6864 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:6920 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:6974 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7026 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7080 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7132 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7187 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7242 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7296 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7351 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7405 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7459 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7513 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7568 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7622 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7674 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7728 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7781 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:08 [ Thread-0:7781 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:08 [ Thread-0:7782 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:08 [ Thread-0:7783 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:08 [ Thread-0:7783 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:08 [ Thread-0:7784 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:08 [ Thread-0:7839 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:7891 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:7943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:7997 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8049 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8104 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8158 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8218 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8272 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8329 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8385 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8438 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8492 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8547 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8603 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8656 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8711 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:09 [ Thread-0:8711 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:09 [ Thread-0:8712 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:09 [ Thread-0:8713 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:09 [ Thread-0:8713 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:09 [ Thread-0:8713 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8766 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8821 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:09 [ Thread-0:8871 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:8927 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:8982 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9036 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9091 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9199 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9253 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9308 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9359 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9413 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9466 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9520 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9575 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:19:10 [ Thread-0:9575 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:19:10 [ Thread-0:9576 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:19:10 [ Thread-0:9577 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:19:10 [ Thread-0:9577 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:19:10 [ Thread-0:9578 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9632 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9686 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9741 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:19:10 [ Thread-0:9795 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:02 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
<<<<<<< HEAD
	enable.idempotence = false
=======
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 13:21:48 [ main:142 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 13:21:48 [ main:149 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 13:21:48 [ main:151 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 13:21:48 [ main:156 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 13:21:49 [ main:432 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 13:21:49 [ main:432 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 13:21:49 [ main:433 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 13:21:49 [ main:433 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 13:21:49 [ main:433 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 13:21:49 [ main:433 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 13:21:49 [ main:434 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 13:21:49 [ main:434 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 13:21:49 [ main:435 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 13:21:49 [ main:438 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 13:21:49 [ main:438 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 13:21:49 [ main:438 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 13:21:49 [ main:438 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 13:21:49 [ main:439 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 13:21:49 [ main:439 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 13:21:49 [ main:439 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 13:21:49 [ main:439 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 13:21:49 [ main:440 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:441 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 13:21:49 [ main:443 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 13:21:49 [ main:443 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 13:21:49 [ main:444 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:446 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:447 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:452 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:453 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:453 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:454 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:524 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:524 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:532 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:532 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:532 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:534 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:548 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:553 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:553 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:553 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:553 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:553 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:553 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:554 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:557 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:557 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:557 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:557 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:557 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 13:21:49 [ kafka-producer-network-thread | producer-1:561 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 13:32:30 [ main:67 ] - [ INFO ] ProducerConfig values: 
=======
2019-12-18 14:20:02 [ Thread-0:7 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:20:02 [ Thread-0:176 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:20:02 [ Thread-0:238 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 14:20:02 [ Thread-0:282 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:20:02 [ Thread-0:291 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:20:02 [ Thread-0:297 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:20:02 [ Thread-0:300 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:20:03 [ Thread-0:301 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:20:03 [ Thread-0:302 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:20:03 [ Thread-0:304 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:20:03 [ Thread-0:305 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:20:03 [ Thread-0:308 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:20:03 [ Thread-0:343 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 14:20:03 [ Thread-0:344 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 14:20:03 [ Thread-0:345 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 14:20:03 [ Thread-0:350 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 14:20:03 [ Thread-0:357 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 14:20:03 [ Thread-0:358 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 14:20:03 [ Thread-0:359 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 14:20:03 [ Thread-0:361 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 14:20:03 [ Thread-0:365 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:20:03 [ Thread-0:365 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:20:03 [ Thread-0:369 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 14:20:03 [ Thread-0:370 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 14:20:03 [ Thread-0:370 ] - [ INFO ] 开始接收数据。
2019-12-18 14:20:03 [ Thread-0:391 ] - [ INFO ] ProducerConfig values: 
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 13:32:31 [ main:136 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 13:32:31 [ main:142 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 13:32:31 [ main:144 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 13:32:31 [ main:149 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 13:32:31 [ main:427 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 13:32:31 [ main:428 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 13:32:31 [ main:428 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 13:32:31 [ main:428 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 13:32:31 [ main:428 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 13:32:31 [ main:429 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 13:32:31 [ main:429 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 13:32:31 [ main:430 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 13:32:31 [ main:430 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 13:32:31 [ main:433 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 13:32:31 [ main:433 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 13:32:31 [ main:433 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 13:32:31 [ main:434 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 13:32:31 [ main:434 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 13:32:31 [ main:434 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 13:32:31 [ main:434 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 13:32:31 [ main:434 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 13:32:31 [ main:435 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:436 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 13:32:31 [ main:437 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 13:32:31 [ main:437 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 13:32:31 [ main:438 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:440 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:441 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:445 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:446 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:446 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:446 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:513 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:514 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:521 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:521 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:521 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:523 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:537 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:542 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:543 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:545 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:547 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:547 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:548 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:548 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:548 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 13:32:31 [ kafka-producer-network-thread | producer-1:550 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
2019-12-18 15:02:41 [ main:87 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [192.168.8.95:9092]
	buffer.memory = 67108864
=======
2019-12-18 14:20:03 [ Thread-0:418 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:20:03 [ Thread-0:430 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:20:03 [ Thread-0:431 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:20:03 [ Thread-0:436 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:20:03 [ Thread-0:437 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:20:03 [ Thread-0:437 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:20:03 [ Thread-0:438 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:20:03 [ Thread-0:438 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:20:03 [ Thread-0:438 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:20:03 [ Thread-0:439 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:20:03 [ Thread-0:440 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:20:03 [ Thread-0:441 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:20:03 [ Thread-0:443 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:20:03 [ Thread-0:446 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:20:03 [ Thread-0:446 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:20:03 [ Thread-0:447 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:20:03 [ Thread-0:447 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:20:03 [ Thread-0:447 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:20:03 [ Thread-0:448 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:20:03 [ Thread-0:448 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:20:03 [ Thread-0:449 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:20:03 [ Thread-0:450 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:20:03 [ kafka-producer-network-thread | producer-1:452 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:20:03 [ Thread-0:453 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:20:03 [ Thread-0:453 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:20:03 [ Thread-0:454 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:20:03 [ Thread-0:454 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:03 [ Thread-0:728 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:03 [ Thread-0:841 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:20:03 [ Thread-0:842 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:20:03 [ Thread-0:843 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:20:03 [ Thread-0:851 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:190)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:219)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:03 [ Thread-0:853 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:03 [ Thread-0:854 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:03 [ Thread-0:857 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Cancelled FIND_COORDINATOR request RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0) with correlation id 0 due to node -1 being disconnected
2019-12-18 14:20:03 [ Thread-0:857 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Coordinator discovery failed, refreshing metadata
2019-12-18 14:20:03 [ Thread-0:857 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:859 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:915 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:03 [ Thread-0:915 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:03 [ Thread-0:916 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:03 [ Thread-0:917 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:03 [ Thread-0:917 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:03 [ Thread-0:917 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:971 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:1024 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:03 [ Thread-0:1024 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:03 [ Thread-0:1025 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:03 [ Thread-0:1026 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:03 [ Thread-0:1026 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:03 [ Thread-0:1026 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:1082 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:1136 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:1191 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:03 [ Thread-0:1245 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:03 [ Thread-0:1245 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:03 [ Thread-0:1246 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:03 [ Thread-0:1247 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:03 [ Thread-0:1247 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:03 [ Thread-0:1249 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1303 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1355 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1421 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1473 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1528 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1581 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1636 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:04 [ Thread-0:1636 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:04 [ Thread-0:1637 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:04 [ Thread-0:1638 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:04 [ Thread-0:1638 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:04 [ Thread-0:1638 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1692 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1743 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1794 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1848 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1903 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:1954 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:2008 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:2062 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:2115 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:2170 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:2225 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:04 [ Thread-0:2277 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2328 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2382 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:05 [ Thread-0:2383 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:05 [ Thread-0:2384 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:05 [ Thread-0:2385 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:05 [ Thread-0:2385 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:05 [ Thread-0:2385 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2440 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2495 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2550 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2602 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2658 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2711 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2766 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2820 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2875 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:2983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:3037 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:3092 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:3147 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:3199 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:05 [ Thread-0:3252 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3306 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3362 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:06 [ Thread-0:3363 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:06 [ Thread-0:3364 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:06 [ Thread-0:3365 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:06 [ Thread-0:3365 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:06 [ Thread-0:3365 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3421 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3474 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3529 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3582 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3637 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3693 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3747 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3802 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3856 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3913 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:3967 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:4019 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:4074 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:4127 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:4179 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:4230 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:06 [ Thread-0:4286 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4341 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4395 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4446 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:07 [ Thread-0:4446 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:07 [ Thread-0:4447 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:07 [ Thread-0:4447 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:07 [ Thread-0:4448 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:07 [ Thread-0:4448 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4501 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4554 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4610 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4663 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4719 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4773 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4824 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4875 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4930 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:4986 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:5042 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:5097 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:5152 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:5205 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:07 [ Thread-0:5261 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5316 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5370 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5424 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5480 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5536 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:08 [ Thread-0:5536 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:08 [ Thread-0:5537 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:08 [ Thread-0:5538 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:08 [ Thread-0:5538 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:08 [ Thread-0:5538 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5591 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5645 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5700 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5753 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5806 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5861 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5912 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:5967 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:6021 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:6076 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:6129 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:6185 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:6239 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:08 [ Thread-0:6294 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6350 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6405 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6458 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6514 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6568 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6623 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6678 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6733 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:09 [ Thread-0:6735 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:09 [ Thread-0:6737 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:09 [ Thread-0:6737 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:09 [ Thread-0:6738 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:09 [ Thread-0:6738 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6792 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6898 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:6954 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:7007 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:7059 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:7114 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:7169 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:7222 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:09 [ Thread-0:7276 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7328 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7383 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7438 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7491 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7546 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7601 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7653 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7708 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7762 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7817 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7872 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:10 [ Thread-0:7872 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:10 [ Thread-0:7873 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:10 [ Thread-0:7874 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:10 [ Thread-0:7874 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:10 [ Thread-0:7875 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7929 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:7983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:8036 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:8092 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:8143 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:8197 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:10 [ Thread-0:8253 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8308 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8361 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8416 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8471 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8522 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8577 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8632 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8687 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8742 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8796 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8851 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:11 [ Thread-0:8851 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:11 [ Thread-0:8853 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:11 [ Thread-0:8854 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:11 [ Thread-0:8854 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:11 [ Thread-0:8854 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8908 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:8963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:9018 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:9072 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:9127 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:9183 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:9238 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:11 [ Thread-0:9293 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9348 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9402 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9457 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9511 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9566 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9620 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9674 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9729 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9783 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9837 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9891 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9944 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:9999 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:12 [ Thread-0:9999 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:12 [ Thread-0:10000 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:12 [ Thread-0:10001 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:12 [ Thread-0:10002 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:12 [ Thread-0:10002 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:10055 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:10108 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:10162 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:10214 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:12 [ Thread-0:10269 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10319 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10375 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10427 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10479 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10539 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10593 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10647 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10702 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10757 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10813 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10868 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10920 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:10972 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:13 [ Thread-0:10972 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:13 [ Thread-0:10973 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:13 [ Thread-0:10974 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:13 [ Thread-0:10974 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:13 [ Thread-0:10976 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:11031 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:11086 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:11140 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:11191 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:11242 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:13 [ Thread-0:11294 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11344 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11398 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11449 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11500 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11553 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11606 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11657 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11711 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11765 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11823 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:14 [ Thread-0:11823 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:14 [ Thread-0:11827 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:14 [ Thread-0:11827 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:14 [ Thread-0:11828 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:14 [ Thread-0:11828 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11883 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11936 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:11992 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:12046 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:12100 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:12155 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:12212 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:14 [ Thread-0:12267 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12321 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12375 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12429 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12483 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12539 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12594 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12648 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12702 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12756 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12812 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:15 [ Thread-0:12812 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:15 [ Thread-0:12813 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.chaokong.thread.ControllerConsumer.run(ControllerConsumer.java:175)
	at java.lang.Thread.run(Thread.java:748)
2019-12-18 14:20:15 [ Thread-0:12813 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:15 [ Thread-0:12813 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:15 [ Thread-0:12813 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12867 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12919 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:12975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:13028 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:13083 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:13137 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:13191 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:13245 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:15 [ Thread-0:13300 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13355 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13406 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13459 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13514 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13569 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13625 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13678 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13731 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13786 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13841 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:16 [ Thread-0:13894 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:16 [ Thread-0:13895 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:38 [ main:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
<<<<<<< HEAD
	enable.idempotence = false
=======
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

<<<<<<< HEAD
2019-12-18 15:02:41 [ main:174 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 15:02:41 [ main:180 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 15:02:41 [ main:182 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.8.95:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:02:41 [ main:188 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 15:02:41 [ main:606 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:02:41 [ main:607 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:02:41 [ main:607 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:02:41 [ main:607 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:02:41 [ main:608 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:02:41 [ main:608 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:02:41 [ main:608 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:02:41 [ main:609 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:02:41 [ main:609 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:02:41 [ main:612 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 15:02:41 [ main:612 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 15:02:41 [ main:612 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 15:02:41 [ main:612 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 15:02:41 [ main:613 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 15:02:41 [ main:613 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 15:02:41 [ main:613 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 15:02:41 [ main:613 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 15:02:41 [ main:614 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:616 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 15:02:41 [ main:617 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:02:41 [ main:617 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:02:41 [ main:619 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:621 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 192.168.8.95:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:621 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:625 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:625 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:626 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:626 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:692 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:692 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:699 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:699 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=caliDataDown) to node 192.168.8.95:9092 (id: -1 rack: null)
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:699 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v4 to send METADATA {topics=[caliDataDown],allow_auto_topic_creation=true} with correlation id 1 to node -1
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:702 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = JSG1eUEgTiK-mEKEQojXBw, nodes = [itcast05:9092 (id: 0 rack: null)], partitions = [Partition(topic = caliDataDown, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])])
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:715 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node itcast05:9092 (id: 0 rack: null)
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:720 ] - [ DEBUG ] Added sensor with name node-0.bytes-sent
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:721 ] - [ DEBUG ] Added sensor with name node-0.bytes-received
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:721 ] - [ DEBUG ] Added sensor with name node-0.latency
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:721 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:721 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:721 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:722 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], ListOffsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED)
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:725 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.records-per-batch
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:725 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.bytes
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:725 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.compression-rate
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:725 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-retries
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:726 ] - [ DEBUG ] Added sensor with name topic.caliDataDown.record-errors
2019-12-18 15:02:41 [ kafka-producer-network-thread | producer-1:728 ] - [ DEBUG ] [Producer clientId=producer-1] Using older server API v3 to send PRODUCE {acks=-1,timeout=30000,partitionSizes=[caliDataDown-0=5506]} with correlation id 3 to node 0
=======
2019-12-18 14:20:38 [ main:3 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:20:39 [ main:166 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:20:39 [ main:201 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 14:20:39 [ main:277 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:20:39 [ main:285 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:20:39 [ main:286 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:20:39 [ main:297 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:20:39 [ main:305 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:20:39 [ main:306 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:20:39 [ main:308 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:20:39 [ main:309 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:20:39 [ main:311 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:20:39 [ main:351 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 14:20:39 [ main:364 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 14:20:39 [ main:365 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 14:20:39 [ main:370 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 14:20:39 [ main:376 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 14:20:39 [ main:377 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 14:20:39 [ main:378 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 14:20:39 [ main:379 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 14:20:39 [ main:382 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:20:39 [ main:382 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:20:39 [ main:388 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 14:20:39 [ main:389 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 14:20:39 [ main:389 ] - [ INFO ] 开始接收数据。
2019-12-18 14:20:39 [ main:406 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 14:20:39 [ main:444 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:20:39 [ main:456 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:20:39 [ main:458 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:20:39 [ main:493 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:20:39 [ main:498 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:20:39 [ main:498 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:20:39 [ main:499 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:20:39 [ main:500 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:20:39 [ main:500 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:20:39 [ main:501 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:20:39 [ main:503 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:20:39 [ main:504 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:20:39 [ main:505 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:20:39 [ main:508 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:20:39 [ main:508 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:20:39 [ main:509 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:20:39 [ main:510 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:20:39 [ main:510 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:20:39 [ main:511 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:20:39 [ main:511 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:20:39 [ main:511 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:20:39 [ main:514 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:20:39 [ kafka-producer-network-thread | producer-1:515 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:20:39 [ main:516 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:20:39 [ main:516 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:20:39 [ main:516 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:20:39 [ main:517 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:39 [ main:694 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:39 [ main:844 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:20:39 [ main:846 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:20:39 [ main:847 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:20:39 [ main:853 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:190)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:219)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:39 [ main:857 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:39 [ main:858 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:39 [ main:861 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Cancelled FIND_COORDINATOR request RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0) with correlation id 0 due to node -1 being disconnected
2019-12-18 14:20:39 [ main:861 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Coordinator discovery failed, refreshing metadata
2019-12-18 14:20:39 [ main:861 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:39 [ main:863 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:39 [ main:916 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:39 [ main:917 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:39 [ main:918 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:39 [ main:919 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:39 [ main:919 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:39 [ main:919 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:39 [ main:975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:39 [ main:1026 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1081 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:40 [ main:1081 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:40 [ main:1082 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:40 [ main:1083 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:40 [ main:1084 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:40 [ main:1084 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1138 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1193 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1247 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1300 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:40 [ main:1300 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:40 [ main:1301 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:40 [ main:1303 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:40 [ main:1303 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:40 [ main:1304 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1357 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1408 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1462 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1515 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1568 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1620 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1680 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:40 [ main:1680 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:40 [ main:1681 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:40 [ main:1684 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:40 [ main:1684 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:40 [ main:1685 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1740 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1793 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1847 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1901 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:1959 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:40 [ main:2012 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2066 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2117 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2169 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2222 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2276 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2328 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2382 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2437 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2488 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:41 [ main:2488 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:41 [ main:2489 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:41 [ main:2489 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:41 [ main:2490 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:41 [ main:2490 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2540 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2593 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2649 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2704 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2759 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2810 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2865 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2918 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:2973 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:41 [ main:3028 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3082 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3135 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3191 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3246 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3300 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3354 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:42 [ main:3354 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:42 [ main:3356 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:42 [ main:3358 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:42 [ main:3358 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:42 [ main:3358 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3412 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3464 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3517 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3572 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3628 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3683 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3737 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3792 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3901 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:3957 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:42 [ main:4010 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4063 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4117 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4172 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4226 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4282 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4336 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4389 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:20:43 [ main:4389 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:20:43 [ main:4390 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection with /10.211.55.3 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:106)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:444)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:398)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:137)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:228)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:205)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:284)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1138)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1103)
	at com.chaokong.thread.ControllerConsumer.getRecords(ControllerConsumer.java:145)
	at com.chaokong.thread.ControllerConsumer.consumer(ControllerConsumer.java:45)
	at com.test.KafkaTest.th(KafkaTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2019-12-18 14:20:43 [ main:4391 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Node -1 disconnected.
2019-12-18 14:20:43 [ main:4391 ] - [ WARN ] [Consumer clientId=consumer-1, groupId=serviceSys] Connection to node -1 could not be established. Broker may not be available.
2019-12-18 14:20:43 [ main:4391 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4445 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:20:43 [ main:4500 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Give up sending metadata request since no node is available
2019-12-18 14:21:45 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 14:21:45 [ Thread-0:5 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:21:46 [ Thread-0:162 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:21:46 [ Thread-0:201 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 14:21:46 [ Thread-0:279 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:21:46 [ Thread-0:286 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:21:46 [ Thread-0:297 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:21:46 [ Thread-0:299 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:21:46 [ Thread-0:302 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:21:46 [ Thread-0:303 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:21:46 [ Thread-0:304 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:21:46 [ Thread-0:305 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:21:46 [ Thread-0:307 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:21:46 [ Thread-0:339 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 14:21:46 [ Thread-0:340 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 14:21:46 [ Thread-0:341 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 14:21:46 [ Thread-0:345 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 14:21:46 [ Thread-0:351 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 14:21:46 [ Thread-0:352 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 14:21:46 [ Thread-0:353 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 14:21:46 [ Thread-0:353 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 14:21:46 [ Thread-0:362 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:21:46 [ Thread-0:362 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:21:46 [ Thread-0:367 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 14:21:46 [ Thread-0:368 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 14:21:46 [ Thread-0:368 ] - [ INFO ] 开始接收数据。
2019-12-18 14:21:46 [ Thread-0:382 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 14:21:46 [ Thread-0:397 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:21:46 [ Thread-0:405 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:21:46 [ Thread-0:406 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:21:46 [ Thread-0:411 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:21:46 [ Thread-0:412 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:21:46 [ Thread-0:413 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:21:46 [ Thread-0:413 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:21:46 [ Thread-0:414 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:21:46 [ Thread-0:415 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:21:46 [ Thread-0:416 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:21:46 [ Thread-0:417 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:21:46 [ Thread-0:419 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:21:46 [ Thread-0:421 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:21:46 [ Thread-0:423 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:21:46 [ Thread-0:424 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:21:46 [ Thread-0:424 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:21:46 [ Thread-0:425 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:21:46 [ Thread-0:425 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:21:46 [ Thread-0:426 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:21:46 [ Thread-0:427 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:21:46 [ Thread-0:427 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:21:46 [ Thread-0:431 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:21:46 [ kafka-producer-network-thread | producer-1:432 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:21:46 [ Thread-0:432 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:21:46 [ Thread-0:433 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:21:46 [ Thread-0:435 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:21:46 [ Thread-0:436 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:21:46 [ Thread-0:675 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:21:46 [ Thread-0:839 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:21:46 [ Thread-0:840 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:21:46 [ Thread-0:842 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:21:46 [ Thread-0:847 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 14:21:46 [ Thread-0:847 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 14:21:46 [ Thread-0:847 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 14:21:46 [ Thread-0:872 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:21:46 [ Thread-0:873 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:21:46 [ Thread-0:918 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 14:21:46 [ Thread-0:927 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576650106895, latencyMs=263, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 14:21:46 [ Thread-0:927 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:21:46 [ Thread-0:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:21:46 [ kafka-coordinator-heartbeat-thread | serviceSys:932 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 14:21:46 [ Thread-0:932 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 14:21:46 [ Thread-0:933 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 14:21:46 [ Thread-0:934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 14:21:46 [ Thread-0:935 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 14:21:46 [ Thread-0:937 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@e81de15)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:21:46 [ Thread-0:940 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 14:21:46 [ Thread-0:941 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 14:21:46 [ Thread-0:942 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 14:21:46 [ Thread-0:943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 14:21:46 [ Thread-0:943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 14:21:46 [ Thread-0:945 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 14:21:46 [ Thread-0:952 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:21:46 [ Thread-0:991 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@7547a07e
2019-12-18 14:21:46 [ Thread-0:992 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-75a539ed-a227-4706-be0d-754fd2285162=Subscription(topics=[msg0200])}
2019-12-18 14:21:46 [ Thread-0:993 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-75a539ed-a227-4706-be0d-754fd2285162=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 14:21:46 [ Thread-0:994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=3, memberId=consumer-1-75a539ed-a227-4706-be0d-754fd2285162, groupAssignment=consumer-1-75a539ed-a227-4706-be0d-754fd2285162)
2019-12-18 14:21:46 [ Thread-0:1026 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 3
2019-12-18 14:21:46 [ Thread-0:1027 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 14:21:47 [ Thread-0:1032 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 14:21:47 [ Thread-0:1034 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 14:21:47 [ Thread-0:1051 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 515
2019-12-18 14:21:47 [ Thread-0:1051 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 508
2019-12-18 14:21:47 [ Thread-0:1052 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:47 [ Thread-0:1052 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:47 [ Thread-0:1053 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:47 [ Thread-0:1054 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:47 [ Thread-0:1057 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 14:21:47 [ Thread-0:1058 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 14:21:47 [ Thread-0:1059 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 14:21:47 [ Thread-0:1062 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 14:21:47 [ Thread-0:1062 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 14:21:47 [ Thread-0:1062 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 14:21:47 [ Thread-0:1068 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:21:47 [ Thread-0:1442 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:21:47 [ Thread-0:1693 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:47 [ Thread-0:1694 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:47 [ Thread-0:1697 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 14:21:47 [ Thread-0:1699 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 14:21:47 [ Thread-0:1700 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 14:21:47 [ Thread-0:1700 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 14:21:47 [ Thread-0:1701 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:47 [ Thread-0:1701 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:47 [ Thread-0:1701 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:48 [ Thread-0:2036 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:21:48 [ Thread-0:2094 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:21:48 [ Thread-0:2095 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:21:48 [ Thread-0:2095 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:21:48 [ kafka-coordinator-heartbeat-thread | serviceSys:2209 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:48 [ kafka-coordinator-heartbeat-thread | serviceSys:2210 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:48 [ Thread-0:2210 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:48 [ Thread-0:2210 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:48 [ Thread-0:2211 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:48 [ Thread-0:2449 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:21:48 [ Thread-0:2716 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:48 [ Thread-0:2717 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:48 [ Thread-0:2718 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:48 [ Thread-0:2718 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:48 [ Thread-0:2718 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:49 [ Thread-0:3040 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:21:49 [ Thread-0:3049 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:21:49 [ Thread-0:3050 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:21:49 [ Thread-0:3050 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:21:49 [ Thread-0:3225 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:49 [ Thread-0:3225 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:49 [ Thread-0:3226 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:49 [ Thread-0:3226 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:49 [ Thread-0:3226 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:49 [ Thread-0:3454 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:21:49 [ kafka-coordinator-heartbeat-thread | serviceSys:3733 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:49 [ kafka-coordinator-heartbeat-thread | serviceSys:3733 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=515, lastStableOffset = 515, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:21:49 [ Thread-0:3734 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:49 [ Thread-0:3734 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:49 [ Thread-0:3735 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:21:50 [ kafka-coordinator-heartbeat-thread | serviceSys:4031 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:21:50 [ Thread-0:4041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:21:50 [ Thread-0:4045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 14:21:50 [ Thread-0:4052 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 515 for partition msg0200-0
2019-12-18 14:21:50 [ Thread-0:4052 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:21:50 [ Thread-0:4052 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=515, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:33:26 [ main:0 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 14:33:26 [ main:166 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:33:26 [ main:181 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:33:26 [ main:189 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:33:26 [ main:293 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:33:26 [ main:343 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:33:26 [ main:344 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:33:26 [ main:346 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:33:26 [ main:347 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:33:26 [ main:348 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:33:26 [ main:349 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:33:26 [ main:350 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:33:26 [ main:352 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:33:26 [ main:353 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:33:26 [ main:359 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:33:26 [ main:360 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:33:26 [ main:360 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:33:26 [ main:361 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:33:26 [ main:361 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:33:26 [ main:362 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:33:26 [ main:363 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:33:26 [ main:364 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:33:26 [ main:366 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:367 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:33:26 [ main:372 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:33:26 [ main:372 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:33:26 [ main:376 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:392 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:392 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:526 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:527 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:529 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:536 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:699 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:699 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:720 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:720 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:745 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:767 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:768 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:770 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:771 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:772 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:772 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:773 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:781 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:786 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-per-batch
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:787 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:789 ] - [ DEBUG ] Added sensor with name topic.msg0200.compression-rate
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:790 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-retries
2019-12-18 14:33:26 [ kafka-producer-network-thread | producer-1:790 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-errors
2019-12-18 14:33:26 [ main:840 ] - [ INFO ] 发送成功
2019-12-18 14:33:42 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 14:33:42 [ Thread-0:5 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 14:33:42 [ Thread-0:162 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:33:43 [ Thread-0:190 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 14:33:43 [ Thread-0:246 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:33:43 [ Thread-0:256 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:33:43 [ Thread-0:256 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:33:43 [ Thread-0:257 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:33:43 [ Thread-0:261 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:33:43 [ Thread-0:269 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:33:43 [ Thread-0:270 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:33:43 [ Thread-0:272 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:33:43 [ Thread-0:278 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:33:43 [ Thread-0:331 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 14:33:43 [ Thread-0:332 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 14:33:43 [ Thread-0:334 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 14:33:43 [ Thread-0:338 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 14:33:43 [ Thread-0:345 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 14:33:43 [ Thread-0:347 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 14:33:43 [ Thread-0:347 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 14:33:43 [ Thread-0:348 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 14:33:43 [ Thread-0:352 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:33:43 [ Thread-0:352 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:33:43 [ Thread-0:355 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 14:33:43 [ Thread-0:356 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 14:33:43 [ Thread-0:356 ] - [ INFO ] 开始接收数据。
2019-12-18 14:33:43 [ Thread-0:373 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 14:33:43 [ Thread-0:403 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 14:33:43 [ Thread-0:415 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 14:33:43 [ Thread-0:416 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 14:33:43 [ Thread-0:421 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 14:33:43 [ Thread-0:422 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 14:33:43 [ Thread-0:423 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 14:33:43 [ Thread-0:424 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 14:33:43 [ Thread-0:424 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 14:33:43 [ Thread-0:425 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 14:33:43 [ Thread-0:425 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 14:33:43 [ Thread-0:427 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 14:33:43 [ Thread-0:428 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 14:33:43 [ Thread-0:429 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 14:33:43 [ Thread-0:432 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 14:33:43 [ Thread-0:432 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 14:33:43 [ Thread-0:433 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 14:33:43 [ Thread-0:433 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 14:33:43 [ Thread-0:434 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 14:33:43 [ Thread-0:434 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 14:33:43 [ Thread-0:435 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 14:33:43 [ Thread-0:435 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 14:33:43 [ Thread-0:440 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 14:33:43 [ kafka-producer-network-thread | producer-1:442 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 14:33:43 [ Thread-0:442 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 14:33:43 [ Thread-0:442 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 14:33:43 [ Thread-0:446 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 14:33:43 [ Thread-0:446 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:33:43 [ Thread-0:702 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:33:43 [ Thread-0:812 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 14:33:43 [ Thread-0:813 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 14:33:43 [ Thread-0:814 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 14:33:43 [ Thread-0:824 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 14:33:43 [ Thread-0:825 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 14:33:43 [ Thread-0:825 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 14:33:43 [ Thread-0:846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:33:43 [ Thread-0:847 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 14:33:43 [ Thread-0:855 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 14:33:43 [ Thread-0:858 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576650823681, latencyMs=162, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 14:33:43 [ Thread-0:858 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:33:43 [ Thread-0:858 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:33:43 [ kafka-coordinator-heartbeat-thread | serviceSys:861 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 14:33:43 [ Thread-0:861 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 14:33:43 [ Thread-0:861 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 14:33:43 [ Thread-0:862 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 14:33:43 [ Thread-0:862 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 14:33:43 [ Thread-0:864 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@5ced0fee)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:33:43 [ Thread-0:865 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 14:33:43 [ Thread-0:866 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 14:33:43 [ Thread-0:868 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 14:33:43 [ Thread-0:868 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 14:33:43 [ Thread-0:868 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 14:33:43 [ Thread-0:869 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 14:33:43 [ Thread-0:872 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:33:43 [ Thread-0:879 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@6b4815fa
2019-12-18 14:33:43 [ Thread-0:879 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-959c690a-0a51-4099-888f-3c1579b0dc07=Subscription(topics=[msg0200])}
2019-12-18 14:33:43 [ Thread-0:880 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-959c690a-0a51-4099-888f-3c1579b0dc07=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 14:33:43 [ Thread-0:881 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=5, memberId=consumer-1-959c690a-0a51-4099-888f-3c1579b0dc07, groupAssignment=consumer-1-959c690a-0a51-4099-888f-3c1579b0dc07)
2019-12-18 14:33:43 [ Thread-0:889 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 5
2019-12-18 14:33:43 [ Thread-0:890 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 14:33:43 [ Thread-0:891 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 14:33:43 [ Thread-0:892 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 14:33:43 [ Thread-0:896 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 515
2019-12-18 14:33:43 [ Thread-0:896 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 508
2019-12-18 14:33:43 [ Thread-0:897 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:43 [ Thread-0:897 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 515 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:43 [ Thread-0:898 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:43 [ Thread-0:899 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:43 [ Thread-0:903 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 14:33:43 [ Thread-0:905 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 14:33:43 [ Thread-0:906 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 14:33:43 [ Thread-0:906 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 14:33:43 [ Thread-0:906 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 14:33:43 [ Thread-0:906 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 14:33:43 [ Thread-0:911 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 14:33:43 [ Thread-0:930 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:43 [ Thread-0:931 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 515 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=70)
2019-12-18 14:33:43 [ Thread-0:935 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 14:33:43 [ Thread-0:947 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 14:33:43 [ Thread-0:948 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 14:33:43 [ Thread-0:948 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 14:33:43 [ Thread-0:949 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:43 [ Thread-0:949 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:43 [ Thread-0:949 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:43 [ Thread-0:951 ] - [ INFO ] 接收到1条数据。
2019-12-18 14:33:43 [ Thread-0:955 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 14:33:43 [ Thread-0:955 ] - [ INFO ] hex: 0101
2019-12-18 14:33:43 [ Thread-0:1097 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 14:33:43 [ Thread-0:1098 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 14:33:44 [ Thread-0:1455 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:44 [ Thread-0:1456 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:44 [ Thread-0:1456 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:44 [ Thread-0:1456 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:44 [ Thread-0:1456 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:44 [ Thread-0:1895 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:33:44 [ Thread-0:1903 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 14:33:44 [ Thread-0:1903 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:33:44 [ Thread-0:1904 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:33:44 [ Thread-0:1963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:44 [ Thread-0:1963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:44 [ Thread-0:1963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:44 [ Thread-0:1964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:44 [ Thread-0:1964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:44 [ Thread-0:2106 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:33:45 [ kafka-coordinator-heartbeat-thread | serviceSys:2470 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:45 [ kafka-coordinator-heartbeat-thread | serviceSys:2470 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:45 [ Thread-0:2470 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:45 [ Thread-0:2470 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:45 [ Thread-0:2470 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:45 [ Thread-0:2899 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:33:45 [ Thread-0:2903 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 14:33:45 [ Thread-0:2904 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:33:45 [ Thread-0:2904 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:33:45 [ Thread-0:2976 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:45 [ Thread-0:2976 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:45 [ Thread-0:2977 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:45 [ Thread-0:2977 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:45 [ Thread-0:2978 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:45 [ Thread-0:3111 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 14:33:46 [ kafka-coordinator-heartbeat-thread | serviceSys:3486 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:46 [ kafka-coordinator-heartbeat-thread | serviceSys:3486 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:46 [ Thread-0:3487 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:46 [ Thread-0:3488 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:46 [ Thread-0:3489 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:46 [ kafka-coordinator-heartbeat-thread | serviceSys:3894 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 14:33:46 [ Thread-0:3900 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 14:33:46 [ Thread-0:3900 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:33:46 [ Thread-0:3906 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 14:33:46 [ Thread-0:3907 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 14:33:46 [ Thread-0:3907 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 14:33:46 [ Thread-0:3996 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:46 [ Thread-0:3997 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 14:33:46 [ Thread-0:3997 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:46 [ Thread-0:3997 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 14:33:46 [ Thread-0:3998 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:09 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 15:51:09 [ Thread-0:4 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 15:51:09 [ Thread-0:179 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:51:09 [ Thread-0:299 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 15:51:09 [ Thread-0:348 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:51:09 [ Thread-0:375 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:51:09 [ Thread-0:376 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:51:09 [ Thread-0:377 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:51:09 [ Thread-0:378 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:51:09 [ Thread-0:380 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:51:09 [ Thread-0:381 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:51:09 [ Thread-0:382 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:51:09 [ Thread-0:384 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:51:09 [ Thread-0:450 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 15:51:09 [ Thread-0:451 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 15:51:09 [ Thread-0:453 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 15:51:09 [ Thread-0:485 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 15:51:09 [ Thread-0:492 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 15:51:09 [ Thread-0:497 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 15:51:09 [ Thread-0:498 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 15:51:09 [ Thread-0:499 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 15:51:09 [ Thread-0:506 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:51:09 [ Thread-0:506 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:51:09 [ Thread-0:514 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 15:51:09 [ Thread-0:515 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 15:51:09 [ Thread-0:516 ] - [ INFO ] 开始接收数据。
2019-12-18 15:51:09 [ Thread-0:550 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 15:51:09 [ Thread-0:560 ] - [ INFO ] [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2019-12-18 15:51:09 [ Thread-0:561 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer has been closed
2019-12-18 15:51:43 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 15:51:43 [ Thread-0:3 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 15:51:43 [ Thread-0:231 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:51:43 [ Thread-0:321 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 15:51:43 [ Thread-0:415 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:51:44 [ Thread-0:452 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:51:44 [ Thread-0:453 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:51:44 [ Thread-0:454 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:51:44 [ Thread-0:455 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:51:44 [ Thread-0:456 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:51:44 [ Thread-0:466 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:51:44 [ Thread-0:468 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:51:44 [ Thread-0:469 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:51:44 [ Thread-0:575 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 15:51:44 [ Thread-0:585 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 15:51:44 [ Thread-0:588 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 15:51:44 [ Thread-0:598 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 15:51:44 [ Thread-0:606 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 15:51:44 [ Thread-0:611 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 15:51:44 [ Thread-0:612 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 15:51:44 [ Thread-0:613 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 15:51:44 [ Thread-0:643 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:51:44 [ Thread-0:669 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:51:44 [ Thread-0:672 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 15:51:44 [ Thread-0:673 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 15:51:44 [ Thread-0:674 ] - [ INFO ] 开始接收数据。
2019-12-18 15:51:44 [ Thread-0:710 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 15:51:44 [ Thread-0:755 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 15:51:44 [ Thread-0:769 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 15:51:44 [ Thread-0:780 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:51:44 [ Thread-0:789 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 15:51:44 [ Thread-0:789 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:51:44 [ Thread-0:790 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:51:44 [ Thread-0:791 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:51:44 [ Thread-0:792 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:51:44 [ Thread-0:793 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:51:44 [ Thread-0:794 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:51:44 [ Thread-0:796 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:51:44 [ Thread-0:797 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:51:44 [ Thread-0:798 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:51:44 [ Thread-0:804 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 15:51:44 [ Thread-0:805 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 15:51:44 [ Thread-0:805 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 15:51:44 [ Thread-0:806 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 15:51:44 [ Thread-0:806 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 15:51:44 [ Thread-0:807 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 15:51:44 [ Thread-0:808 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 15:51:44 [ Thread-0:808 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 15:51:44 [ Thread-0:812 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 15:51:44 [ kafka-producer-network-thread | producer-1:814 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 15:51:44 [ Thread-0:814 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:51:44 [ Thread-0:815 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:51:44 [ Thread-0:815 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 15:51:44 [ Thread-0:816 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:51:44 [ Thread-0:1073 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:51:44 [ Thread-0:1219 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 15:51:44 [ Thread-0:1220 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 15:51:44 [ Thread-0:1221 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 15:51:44 [ Thread-0:1229 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 15:51:44 [ Thread-0:1229 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 15:51:44 [ Thread-0:1229 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 15:51:44 [ Thread-0:1252 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:51:44 [ Thread-0:1253 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:51:44 [ Thread-0:1260 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 15:51:44 [ Thread-0:1263 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576655504835, latencyMs=194, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 15:51:44 [ Thread-0:1264 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:51:44 [ Thread-0:1264 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:51:44 [ kafka-coordinator-heartbeat-thread | serviceSys:1267 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 15:51:44 [ Thread-0:1267 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 15:51:44 [ Thread-0:1268 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 15:51:44 [ Thread-0:1268 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 15:51:44 [ Thread-0:1268 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 15:51:44 [ Thread-0:1270 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@e81de15)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:51:44 [ Thread-0:1272 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 15:51:44 [ Thread-0:1273 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 15:51:44 [ Thread-0:1274 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 15:51:44 [ Thread-0:1275 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 15:51:44 [ Thread-0:1275 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 15:51:44 [ Thread-0:1275 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 15:51:44 [ Thread-0:1278 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:51:44 [ Thread-0:1285 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@7547a07e
2019-12-18 15:51:44 [ Thread-0:1286 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-83299f4d-85db-4494-9aab-630e7d36ba50=Subscription(topics=[msg0200])}
2019-12-18 15:51:44 [ Thread-0:1287 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-83299f4d-85db-4494-9aab-630e7d36ba50=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 15:51:44 [ Thread-0:1288 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=7, memberId=consumer-1-83299f4d-85db-4494-9aab-630e7d36ba50, groupAssignment=consumer-1-83299f4d-85db-4494-9aab-630e7d36ba50)
2019-12-18 15:51:44 [ Thread-0:1297 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 7
2019-12-18 15:51:44 [ Thread-0:1298 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 15:51:44 [ Thread-0:1300 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 15:51:44 [ Thread-0:1301 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 15:51:44 [ Thread-0:1306 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 516
2019-12-18 15:51:44 [ Thread-0:1306 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 508
2019-12-18 15:51:44 [ Thread-0:1307 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:44 [ Thread-0:1307 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:44 [ Thread-0:1307 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:44 [ Thread-0:1309 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:44 [ Thread-0:1310 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 15:51:44 [ Thread-0:1311 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 15:51:44 [ Thread-0:1311 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 15:51:44 [ Thread-0:1312 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 15:51:44 [ Thread-0:1312 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 15:51:44 [ Thread-0:1312 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 15:51:44 [ Thread-0:1317 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:51:45 [ Thread-0:1821 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:51:45 [ Thread-0:1838 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:45 [ Thread-0:1839 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:45 [ Thread-0:1843 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 15:51:45 [ Thread-0:1844 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 15:51:45 [ Thread-0:1845 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 15:51:45 [ Thread-0:1845 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 15:51:45 [ Thread-0:1846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:45 [ Thread-0:1846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:45 [ Thread-0:1846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:45 [ Thread-0:2303 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:51:45 [ Thread-0:2315 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:51:45 [ Thread-0:2315 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:51:45 [ Thread-0:2316 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:51:45 [ Thread-0:2361 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:45 [ Thread-0:2361 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:45 [ Thread-0:2362 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:45 [ Thread-0:2362 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:45 [ Thread-0:2363 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:46 [ Thread-0:2828 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:51:46 [ Thread-0:2868 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:46 [ Thread-0:2868 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:46 [ Thread-0:2869 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:46 [ Thread-0:2869 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:46 [ Thread-0:2869 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:46 [ Thread-0:3305 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:51:46 [ Thread-0:3312 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:51:46 [ Thread-0:3312 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:51:46 [ Thread-0:3313 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:51:46 [ Thread-0:3376 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:46 [ Thread-0:3376 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:46 [ Thread-0:3377 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:46 [ Thread-0:3378 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:46 [ Thread-0:3378 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:47 [ Thread-0:3834 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:51:47 [ Thread-0:3885 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:47 [ Thread-0:3885 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:47 [ Thread-0:3886 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:47 [ Thread-0:3886 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:47 [ Thread-0:3886 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:47 [ kafka-coordinator-heartbeat-thread | serviceSys:4303 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:51:47 [ Thread-0:4306 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:51:47 [ Thread-0:4310 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 15:51:47 [ Thread-0:4319 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:51:47 [ Thread-0:4319 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:51:47 [ Thread-0:4319 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:51:47 [ Thread-0:4395 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:47 [ Thread-0:4396 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:47 [ Thread-0:4396 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:47 [ Thread-0:4396 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:47 [ Thread-0:4396 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:48 [ Thread-0:4840 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:51:48 [ Thread-0:4904 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:48 [ Thread-0:4904 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:51:48 [ Thread-0:4904 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:48 [ Thread-0:4905 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:51:48 [ Thread-0:4905 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:14 [ Thread-0:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-12-18 15:52:14 [ Thread-0:6 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 15:52:14 [ Thread-0:172 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:52:14 [ Thread-0:207 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 15:52:14 [ Thread-0:235 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:52:14 [ Thread-0:241 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:52:14 [ Thread-0:243 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:52:14 [ Thread-0:244 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:52:14 [ Thread-0:245 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:52:14 [ Thread-0:245 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:52:14 [ Thread-0:248 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:52:14 [ Thread-0:250 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:52:14 [ Thread-0:251 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:52:14 [ Thread-0:286 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 15:52:14 [ Thread-0:287 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 15:52:14 [ Thread-0:288 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 15:52:14 [ Thread-0:293 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 15:52:14 [ Thread-0:299 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 15:52:14 [ Thread-0:300 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 15:52:14 [ Thread-0:301 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 15:52:14 [ Thread-0:306 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 15:52:14 [ Thread-0:311 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:52:14 [ Thread-0:311 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:52:14 [ Thread-0:314 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 15:52:14 [ Thread-0:315 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): command
2019-12-18 15:52:14 [ Thread-0:316 ] - [ INFO ] 开始接收数据。
2019-12-18 15:52:14 [ Thread-0:343 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 15:52:14 [ Thread-0:371 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 15:52:14 [ Thread-0:375 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 15:52:14 [ Thread-0:376 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:52:14 [ Thread-0:388 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 15:52:14 [ Thread-0:388 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:52:14 [ Thread-0:389 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:52:14 [ Thread-0:390 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:52:14 [ Thread-0:391 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:52:14 [ Thread-0:392 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:52:14 [ Thread-0:393 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:52:14 [ Thread-0:395 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:52:14 [ Thread-0:396 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:52:14 [ Thread-0:398 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:52:14 [ Thread-0:401 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 15:52:14 [ Thread-0:402 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 15:52:14 [ Thread-0:402 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 15:52:14 [ Thread-0:402 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 15:52:14 [ Thread-0:403 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 15:52:14 [ Thread-0:403 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 15:52:14 [ Thread-0:404 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 15:52:14 [ Thread-0:404 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 15:52:14 [ Thread-0:409 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 15:52:14 [ kafka-producer-network-thread | producer-1:411 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 15:52:14 [ Thread-0:411 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:52:14 [ Thread-0:412 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:52:14 [ Thread-0:413 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 15:52:14 [ Thread-0:414 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:52:14 [ Thread-0:600 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:52:14 [ Thread-0:747 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 15:52:14 [ Thread-0:748 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 15:52:14 [ Thread-0:749 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 15:52:14 [ Thread-0:755 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 15:52:14 [ Thread-0:755 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 15:52:14 [ Thread-0:755 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 15:52:14 [ Thread-0:779 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:52:14 [ Thread-0:779 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:52:14 [ Thread-0:793 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 15:52:14 [ Thread-0:795 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576655534847, latencyMs=201, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 15:52:14 [ Thread-0:795 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:52:14 [ Thread-0:795 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:52:14 [ kafka-coordinator-heartbeat-thread | serviceSys:798 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 15:52:14 [ Thread-0:798 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 15:52:14 [ Thread-0:798 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 15:52:14 [ Thread-0:798 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 15:52:14 [ Thread-0:799 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 15:52:14 [ Thread-0:801 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@42787cf2)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:52:14 [ Thread-0:802 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 15:52:14 [ Thread-0:804 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 15:52:14 [ Thread-0:804 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 15:52:14 [ Thread-0:805 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 15:52:14 [ Thread-0:805 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 15:52:14 [ Thread-0:806 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 15:52:14 [ Thread-0:809 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:52:14 [ Thread-0:819 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@6751122d
2019-12-18 15:52:14 [ Thread-0:820 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-f5453124-306d-4546-9e4e-6f4c0b4d2382=Subscription(topics=[command])}
2019-12-18 15:52:14 [ Thread-0:821 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-f5453124-306d-4546-9e4e-6f4c0b4d2382=Assignment(partitions=[command-0, command-1])}
2019-12-18 15:52:14 [ Thread-0:822 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=9, memberId=consumer-1-f5453124-306d-4546-9e4e-6f4c0b4d2382, groupAssignment=consumer-1-f5453124-306d-4546-9e4e-6f4c0b4d2382)
2019-12-18 15:52:14 [ Thread-0:829 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 9
2019-12-18 15:52:14 [ Thread-0:829 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 15:52:14 [ Thread-0:831 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [command-0, command-1]
2019-12-18 15:52:14 [ Thread-0:832 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [command-0, command-1]
2019-12-18 15:52:14 [ Thread-0:837 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Found no committed offset for partition command-0
2019-12-18 15:52:14 [ Thread-0:837 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Found no committed offset for partition command-1
2019-12-18 15:52:14 [ Thread-0:839 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:14 [ Thread-0:841 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 15:52:14 [ Thread-0:843 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 15:52:14 [ Thread-0:844 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 15:52:14 [ Thread-0:844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 15:52:14 [ Thread-0:845 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 15:52:14 [ Thread-0:846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 15:52:14 [ Thread-0:849 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:52:14 [ Thread-0:875 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Handling ListOffsetResponse response for command-0. Fetched offset 0, timestamp -1
2019-12-18 15:52:14 [ Thread-0:876 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Handling ListOffsetResponse response for command-1. Fetched offset 0, timestamp -1
2019-12-18 15:52:14 [ Thread-0:876 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition command-0 to offset 0.
2019-12-18 15:52:14 [ Thread-0:876 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition command-1 to offset 0.
2019-12-18 15:52:14 [ Thread-0:877 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:14 [ Thread-0:877 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:14 [ Thread-0:878 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:15 [ Thread-0:1411 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:15 [ Thread-0:1414 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:15 [ Thread-0:1424 ] - [ DEBUG ] Added sensor with name command-0.records-lag
2019-12-18 15:52:15 [ Thread-0:1425 ] - [ DEBUG ] Added sensor with name topic.command.bytes-fetched
2019-12-18 15:52:15 [ Thread-0:1426 ] - [ DEBUG ] Added sensor with name topic.command.records-fetched
2019-12-18 15:52:15 [ Thread-0:1429 ] - [ DEBUG ] Added sensor with name command-1.records-lag
2019-12-18 15:52:15 [ Thread-0:1435 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:52:15 [ Thread-0:1437 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:15 [ Thread-0:1438 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:15 [ Thread-0:1438 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:15 [ Thread-0:1838 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:15 [ Thread-0:1851 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:52:15 [ Thread-0:1852 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:52:15 [ Thread-0:1853 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:15 [ kafka-coordinator-heartbeat-thread | serviceSys:1946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:15 [ kafka-coordinator-heartbeat-thread | serviceSys:1946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:16 [ Thread-0:1947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:16 [ Thread-0:1947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:16 [ Thread-0:1947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:16 [ Thread-0:2442 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:52:16 [ Thread-0:2453 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:16 [ Thread-0:2453 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:16 [ Thread-0:2454 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:16 [ Thread-0:2454 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:16 [ Thread-0:2454 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:16 [ Thread-0:2840 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:16 [ Thread-0:2844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:52:16 [ Thread-0:2844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:52:16 [ Thread-0:2845 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:17 [ Thread-0:2960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:17 [ Thread-0:2960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:17 [ Thread-0:2960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:17 [ Thread-0:2960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:17 [ Thread-0:2961 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:17 [ Thread-0:3447 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:52:17 [ Thread-0:3468 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:17 [ Thread-0:3468 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:17 [ Thread-0:3468 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:17 [ Thread-0:3469 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:17 [ Thread-0:3469 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:17 [ kafka-coordinator-heartbeat-thread | serviceSys:3836 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:52:17 [ Thread-0:3841 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:17 [ Thread-0:3844 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 15:52:17 [ Thread-0:3850 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:52:17 [ Thread-0:3850 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:52:17 [ Thread-0:3850 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:18 [ kafka-coordinator-heartbeat-thread | serviceSys:3975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:18 [ kafka-coordinator-heartbeat-thread | serviceSys:3976 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:18 [ Thread-0:3976 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:18 [ Thread-0:3977 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:18 [ Thread-0:3977 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:18 [ Thread-0:4451 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:52:18 [ Thread-0:4484 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:18 [ Thread-0:4484 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:18 [ Thread-0:4485 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:18 [ Thread-0:4486 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:18 [ Thread-0:4486 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:18 [ Thread-0:4846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:18 [ Thread-0:4853 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:52:18 [ Thread-0:4853 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:52:18 [ Thread-0:4854 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:19 [ Thread-0:4993 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:19 [ Thread-0:4993 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:19 [ Thread-0:4994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:19 [ Thread-0:4994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:19 [ Thread-0:4994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:19 [ Thread-0:5455 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:52:19 [ Thread-0:5503 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:19 [ Thread-0:5503 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:19 [ Thread-0:5504 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:19 [ Thread-0:5504 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:19 [ Thread-0:5504 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:19 [ Thread-0:5851 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:19 [ Thread-0:5859 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:52:19 [ Thread-0:5859 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:52:19 [ Thread-0:5860 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:20 [ Thread-0:6014 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:20 [ Thread-0:6014 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:20 [ Thread-0:6015 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:20 [ Thread-0:6015 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:20 [ Thread-0:6016 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:20 [ Thread-0:6460 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:52:20 [ Thread-0:6525 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:20 [ Thread-0:6525 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:20 [ Thread-0:6526 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:20 [ Thread-0:6526 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:20 [ Thread-0:6526 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:20 [ kafka-coordinator-heartbeat-thread | serviceSys:6839 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:52:20 [ Thread-0:6843 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 15:52:20 [ Thread-0:6852 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:20 [ Thread-0:6859 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:52:20 [ Thread-0:6859 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:52:20 [ Thread-0:6860 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:52:21 [ Thread-0:7036 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:21 [ Thread-0:7037 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:52:21 [ Thread-0:7037 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:21 [ Thread-0:7037 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:52:21 [ Thread-0:7038 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:19 [ location:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 15:54:19 [ controller:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-12-18 15:54:19 [ controller:5 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 15:54:19 [ location:5 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 15:54:19 [ location:167 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:54:19 [ controller:167 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:54:19 [ controller:196 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 15:54:19 [ location:196 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 15:54:19 [ controller:232 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:54:19 [ location:241 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:54:19 [ location:250 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:54:19 [ controller:251 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:54:19 [ location:251 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:54:19 [ controller:251 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:54:19 [ location:252 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:54:19 [ controller:252 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:54:19 [ location:253 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:54:19 [ controller:253 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:54:19 [ controller:254 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:54:19 [ location:254 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:54:19 [ location:257 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:54:19 [ location:261 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:54:19 [ controller:263 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:54:19 [ location:264 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:54:19 [ controller:268 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:54:19 [ controller:274 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:54:19 [ location:324 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 15:54:19 [ controller:324 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 15:54:19 [ location:328 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 15:54:19 [ controller:328 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 15:54:19 [ location:329 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 15:54:19 [ location:333 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 15:54:19 [ controller:334 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 15:54:19 [ controller:336 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 15:54:19 [ controller:345 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 15:54:19 [ location:345 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 15:54:19 [ location:346 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 15:54:19 [ location:347 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 15:54:19 [ controller:347 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 15:54:19 [ controller:348 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 15:54:19 [ controller:349 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 15:54:19 [ location:350 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 15:54:19 [ controller:354 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:54:19 [ controller:355 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:54:19 [ controller:358 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Kafka consumer initialized
2019-12-18 15:54:19 [ location:358 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:54:19 [ location:359 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:54:19 [ location:359 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 15:54:19 [ controller:363 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Subscribed to topic(s): command
2019-12-18 15:54:19 [ controller:365 ] - [ INFO ] 开始接收数据。
2019-12-18 15:54:19 [ location:363 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 15:54:19 [ location:366 ] - [ INFO ] 开始接收数据。
2019-12-18 15:54:19 [ location:381 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 15:54:19 [ controller:411 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 15:54:19 [ location:416 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 15:54:19 [ controller:417 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 15:54:19 [ location:426 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 15:54:19 [ controller:427 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 15:54:19 [ location:427 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:54:19 [ controller:427 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:54:19 [ location:434 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 15:54:19 [ location:434 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:54:19 [ controller:435 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 15:54:19 [ location:435 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:54:19 [ location:436 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:54:19 [ controller:436 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:54:19 [ location:436 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:54:19 [ controller:436 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:54:19 [ location:436 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:54:19 [ controller:437 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:54:19 [ location:437 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:54:19 [ controller:437 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:54:19 [ controller:438 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:54:19 [ controller:439 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:54:19 [ controller:440 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:54:19 [ location:441 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:54:19 [ controller:441 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:54:19 [ location:442 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:54:19 [ location:443 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:54:19 [ location:446 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 15:54:19 [ location:446 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 15:54:19 [ location:446 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 15:54:19 [ location:447 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 15:54:19 [ controller:447 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:54:19 [ location:448 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 15:54:19 [ location:449 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 15:54:19 [ controller:449 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 15:54:19 [ controller:450 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 15:54:19 [ controller:450 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 15:54:19 [ location:451 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 15:54:19 [ location:451 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 15:54:19 [ controller:452 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 15:54:19 [ controller:452 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 15:54:19 [ controller:453 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 15:54:19 [ location:454 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 15:54:19 [ controller:454 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 15:54:19 [ controller:456 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 15:54:19 [ controller:456 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 15:54:19 [ kafka-producer-network-thread | producer-1:457 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 15:54:19 [ location:459 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:54:19 [ location:459 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:54:19 [ kafka-producer-network-thread | producer-2:459 ] - [ DEBUG ] [Producer clientId=producer-2] Starting Kafka producer I/O thread.
2019-12-18 15:54:19 [ location:459 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 15:54:19 [ controller:459 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:54:19 [ controller:460 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:54:19 [ controller:460 ] - [ DEBUG ] [Producer clientId=producer-2] Kafka producer started
2019-12-18 15:54:19 [ controller:460 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:54:19 [ location:460 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:54:19 [ controller:694 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:54:19 [ location:696 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:54:19 [ controller:819 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 15:54:19 [ location:821 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 15:54:19 [ controller:822 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 15:54:19 [ controller:823 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 15:54:19 [ location:824 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 15:54:19 [ location:825 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 15:54:19 [ location:840 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 15:54:19 [ location:841 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 15:54:19 [ location:841 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 15:54:19 [ controller:842 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 15:54:19 [ controller:842 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 15:54:19 [ controller:842 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 15:54:19 [ location:863 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:54:19 [ location:864 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:54:19 [ controller:865 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:54:19 [ controller:866 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:54:19 [ location:879 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 15:54:19 [ location:880 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576655659975, latencyMs=190, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 15:54:19 [ location:881 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:19 [ location:881 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:19 [ controller:879 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 15:54:19 [ location:883 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 15:54:19 [ kafka-coordinator-heartbeat-thread | serviceSys:883 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 15:54:19 [ controller:883 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576655659979, latencyMs=194, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 15:54:19 [ controller:884 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:19 [ controller:884 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:19 [ location:884 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 15:54:19 [ kafka-coordinator-heartbeat-thread | serviceSys:885 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Heartbeat thread started
2019-12-18 15:54:19 [ location:885 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 15:54:19 [ location:886 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 15:54:19 [ controller:886 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 15:54:19 [ controller:886 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 15:54:19 [ controller:886 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 15:54:19 [ controller:886 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] (Re-)joining group
2019-12-18 15:54:19 [ controller:889 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@45ae2ecb)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:19 [ controller:891 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 15:54:19 [ location:889 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@35e29dce)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:19 [ location:891 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 15:54:19 [ controller:893 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 15:54:19 [ controller:894 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 15:54:19 [ controller:894 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 15:54:19 [ controller:894 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 15:54:19 [ controller:894 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 15:54:19 [ location:897 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 15:54:19 [ location:898 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 15:54:19 [ location:898 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 15:54:19 [ location:899 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 15:54:19 [ location:899 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 15:54:19 [ location:901 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:54:20 [ controller:904 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:54:20 [ controller:926 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@51f9ec33
2019-12-18 15:54:20 [ controller:927 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending follower SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=11, memberId=consumer-2-6d1a33ae-d57a-4224-ae6a-5da04e68e6e8, groupAssignment=)
2019-12-18 15:54:20 [ location:927 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@4a1c70c9
2019-12-18 15:54:20 [ location:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: 1 rack: null) for sending metadata request
2019-12-18 15:54:20 [ location:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ location:929 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 15:54:20 [ location:930 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 15:54:20 [ location:933 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 15:54:20 [ location:934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 15:54:20 [ location:934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 15:54:20 [ location:934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 15:54:20 [ location:938 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:54:20 [ location:939 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200,command) to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ location:945 ] - [ DEBUG ] Updated cluster metadata version 3 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 15:54:20 [ location:945 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-90f02b56-54d7-4d35-8d70-c3c2b953729f=Subscription(topics=[msg0200]), consumer-2-6d1a33ae-d57a-4224-ae6a-5da04e68e6e8=Subscription(topics=[command])}
2019-12-18 15:54:20 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-90f02b56-54d7-4d35-8d70-c3c2b953729f=Assignment(partitions=[msg0200-0, msg0200-1]), consumer-2-6d1a33ae-d57a-4224-ae6a-5da04e68e6e8=Assignment(partitions=[command-0, command-1])}
2019-12-18 15:54:20 [ location:948 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=11, memberId=consumer-1-90f02b56-54d7-4d35-8d70-c3c2b953729f, groupAssignment=consumer-1-90f02b56-54d7-4d35-8d70-c3c2b953729f,consumer-2-6d1a33ae-d57a-4224-ae6a-5da04e68e6e8)
2019-12-18 15:54:20 [ controller:953 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Successfully joined group with generation 11
2019-12-18 15:54:20 [ controller:954 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 15:54:20 [ controller:955 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Setting newly assigned partitions [command-0, command-1]
2019-12-18 15:54:20 [ controller:956 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetching committed offsets for partitions: [command-0, command-1]
2019-12-18 15:54:20 [ location:962 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 11
2019-12-18 15:54:20 [ location:963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 15:54:20 [ location:963 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 15:54:20 [ location:963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 15:54:20 [ controller:966 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-0 to the committed offset 0
2019-12-18 15:54:20 [ controller:966 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-1 to the committed offset 0
2019-12-18 15:54:20 [ controller:967 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ controller:967 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 516
2019-12-18 15:54:20 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 508
2019-12-18 15:54:20 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ controller:968 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ controller:972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ controller:975 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 15:54:20 [ controller:976 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 15:54:20 [ controller:977 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 15:54:20 [ controller:978 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 15:54:20 [ controller:979 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 15:54:20 [ controller:979 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 15:54:20 [ controller:984 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:54:20 [ controller:1464 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:20 [ location:1464 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:20 [ location:1486 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:20 [ location:1487 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:20 [ location:1491 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 15:54:20 [ location:1492 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 15:54:20 [ location:1493 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 15:54:20 [ location:1493 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 15:54:20 [ location:1494 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ location:1494 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ location:1494 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ controller:1497 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:20 [ controller:1498 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:20 [ controller:1498 ] - [ DEBUG ] Added sensor with name command-0.records-lag
2019-12-18 15:54:20 [ controller:1499 ] - [ DEBUG ] Added sensor with name topic.command.bytes-fetched
2019-12-18 15:54:20 [ controller:1499 ] - [ DEBUG ] Added sensor with name topic.command.records-fetched
2019-12-18 15:54:20 [ controller:1500 ] - [ DEBUG ] Added sensor with name command-1.records-lag
2019-12-18 15:54:20 [ controller:1500 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ controller:1500 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:20 [ controller:1501 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:1960 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:21 [ location:1966 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:21 [ controller:1968 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:54:21 [ controller:1968 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:54:21 [ controller:1969 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:21 [ location:1972 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:54:21 [ location:1972 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:54:21 [ location:1972 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:21 [ location:2004 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ location:2004 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ location:2004 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ location:2004 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ location:2004 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:2012 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ controller:2012 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ controller:2013 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:2013 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:2013 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:2470 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:21 [ location:2470 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:21 [ location:2509 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ location:2509 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ location:2509 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ location:2509 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ location:2510 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:2518 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ controller:2518 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:21 [ controller:2518 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:2518 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:21 [ controller:2518 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:2963 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:22 [ controller:2967 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:54:22 [ controller:2968 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:54:22 [ controller:2968 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:22 [ location:2969 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:22 [ location:2974 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:54:22 [ location:2974 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:54:22 [ location:2974 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:22 [ location:3015 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ location:3015 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ location:3016 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ location:3016 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ location:3016 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:3023 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ controller:3023 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ controller:3023 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:3023 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:3023 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:3473 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:22 [ location:3473 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:22 [ location:3523 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ location:3523 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ location:3524 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ location:3524 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ location:3524 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:3530 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ controller:3531 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:22 [ controller:3532 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:3532 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:22 [ controller:3532 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ kafka-coordinator-heartbeat-thread | serviceSys:3958 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:23 [ controller:3964 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 15:54:23 [ controller:3964 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:23 [ kafka-coordinator-heartbeat-thread | serviceSys:3968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:23 [ location:3970 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:23 [ controller:3972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:54:23 [ controller:3972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:54:23 [ controller:3972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:23 [ location:3975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 15:54:23 [ location:3980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:54:23 [ location:3980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:54:23 [ location:3980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:23 [ location:4031 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ location:4032 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ location:4032 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ location:4032 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ location:4033 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ controller:4038 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ controller:4039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ controller:4039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ controller:4039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ controller:4039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ controller:4478 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:23 [ location:4478 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:23 [ location:4538 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ location:4539 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ location:4540 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ location:4540 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ location:4540 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ controller:4546 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ controller:4546 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:23 [ controller:4547 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ controller:4547 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:23 [ controller:4547 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:4967 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:24 [ controller:4973 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:54:24 [ controller:4973 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:54:24 [ location:4973 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:24 [ controller:4974 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:24 [ location:4981 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:54:24 [ location:4981 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:54:24 [ location:4981 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:24 [ location:5047 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ location:5047 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ location:5048 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ location:5048 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ location:5048 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:5052 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ controller:5052 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ controller:5052 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:5052 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:5053 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:5482 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:24 [ location:5482 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:24 [ location:5555 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ location:5556 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ location:5556 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ location:5556 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ location:5557 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:5558 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ controller:5559 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:24 [ controller:5559 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:5559 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:24 [ controller:5560 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ controller:5969 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:25 [ location:5976 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:25 [ controller:5977 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:54:25 [ controller:5977 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:54:25 [ controller:5978 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:25 [ location:5983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:54:25 [ location:5983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:54:25 [ location:5983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:25 [ location:6063 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ location:6063 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ location:6064 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ location:6064 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ location:6064 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ controller:6067 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ controller:6067 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ controller:6068 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ controller:6068 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ controller:6068 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ location:6499 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:25 [ controller:6499 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:25 [ location:6572 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ location:6572 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ location:6572 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ location:6573 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ location:6573 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ controller:6575 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ controller:6576 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:25 [ controller:6576 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ controller:6576 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:25 [ controller:6576 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ kafka-coordinator-heartbeat-thread | serviceSys:6959 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:26 [ controller:6962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 15:54:26 [ controller:6971 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:26 [ kafka-coordinator-heartbeat-thread | serviceSys:6971 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 15:54:26 [ location:6977 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:26 [ location:6979 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 15:54:26 [ controller:6982 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:54:26 [ controller:6982 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:54:26 [ controller:6982 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:26 [ location:6985 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:54:26 [ location:6985 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:54:26 [ location:6985 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:26 [ location:7080 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ location:7080 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ location:7080 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ location:7081 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ location:7081 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ controller:7084 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ controller:7084 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ controller:7085 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ controller:7085 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ controller:7085 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ controller:7502 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:26 [ location:7505 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:26 [ location:7588 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ location:7589 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ location:7589 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ location:7589 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ location:7589 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ controller:7592 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ controller:7592 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:26 [ controller:7592 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ controller:7593 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:26 [ controller:7593 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:27 [ controller:7975 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:27 [ location:7980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:27 [ controller:7983 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 15:54:27 [ controller:7983 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 15:54:27 [ controller:7983 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:27 [ location:7987 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 516 for partition msg0200-0
2019-12-18 15:54:27 [ location:7987 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 508 for partition msg0200-1
2019-12-18 15:54:27 [ location:7988 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:54:27 [ location:8095 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=508, lastStableOffset = 508, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:27 [ location:8096 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=516, lastStableOffset = 516, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:27 [ location:8096 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:27 [ location:8096 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:27 [ location:8096 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:27 [ kafka-coordinator-heartbeat-thread | serviceSys:8102 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:27 [ kafka-coordinator-heartbeat-thread | serviceSys:8102 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 15:54:27 [ controller:8103 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:27 [ controller:8103 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:27 [ controller:8103 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:54:27 [ controller:8507 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:27 [ location:8508 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 15:54:28 [ controller:8980 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 15:54:28 [ location:8985 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=516, metadata=''}, msg0200-1=OffsetAndMetadata{offset=508, metadata=''}}
2019-12-18 15:59:24 [ main:1 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 15:59:24 [ main:193 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 15:59:24 [ main:205 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 15:59:24 [ main:214 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 15:59:24 [ main:234 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 15:59:24 [ main:273 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 15:59:24 [ main:281 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 15:59:24 [ main:289 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 15:59:24 [ main:296 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 15:59:24 [ main:300 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 15:59:24 [ main:301 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 15:59:24 [ main:302 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 15:59:24 [ main:304 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 15:59:24 [ main:305 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 15:59:24 [ main:320 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 15:59:24 [ main:320 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 15:59:24 [ main:321 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 15:59:24 [ main:322 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 15:59:24 [ main:323 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 15:59:24 [ main:324 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 15:59:24 [ main:325 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 15:59:24 [ main:329 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 15:59:24 [ main:331 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 15:59:24 [ kafka-producer-network-thread | producer-1:333 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 15:59:24 [ main:336 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 15:59:24 [ main:336 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 15:59:24 [ main:339 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 15:59:24 [ main:340 ] - [ INFO ] 开始发送数据 ---
2019-12-18 15:59:24 [ kafka-producer-network-thread | producer-1:348 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 15:59:24 [ kafka-producer-network-thread | producer-1:349 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:10908 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:10910 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:10911 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:10921 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11094 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11095 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11111 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11112 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11117 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11139 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11140 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11142 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11142 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11143 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11143 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11143 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11146 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11156 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-per-batch
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11157 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11157 ] - [ DEBUG ] Added sensor with name topic.msg0200.compression-rate
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11158 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-retries
2019-12-18 15:59:35 [ kafka-producer-network-thread | producer-1:11159 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-errors
2019-12-18 15:59:36 [ main:11674 ] - [ INFO ] 发送成功 ---
2019-12-18 16:00:20 [ location:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 16:00:20 [ controller:1 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-12-18 16:00:20 [ location:5 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:00:20 [ controller:5 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:00:20 [ location:150 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:00:20 [ controller:150 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:00:20 [ controller:181 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:00:20 [ location:181 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:00:20 [ controller:218 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:00:20 [ location:218 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:00:20 [ location:231 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:00:20 [ controller:231 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:00:20 [ location:232 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:00:20 [ controller:232 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:00:20 [ location:233 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:00:20 [ controller:233 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:00:20 [ location:234 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:00:20 [ controller:235 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:00:20 [ location:236 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:00:20 [ controller:238 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:00:20 [ location:240 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:00:20 [ controller:240 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:00:20 [ controller:242 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:00:20 [ location:242 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:00:20 [ controller:246 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:00:20 [ location:246 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:00:20 [ controller:300 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:00:20 [ location:301 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:00:20 [ location:302 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:00:20 [ location:303 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:00:20 [ controller:305 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:00:20 [ controller:307 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:00:20 [ location:307 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:00:20 [ controller:314 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:00:20 [ location:321 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:00:20 [ controller:321 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:00:20 [ location:323 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:00:20 [ location:324 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:00:20 [ controller:325 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:00:20 [ location:325 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:00:20 [ controller:327 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:00:20 [ controller:329 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:00:20 [ location:331 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:00:20 [ location:332 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:00:20 [ location:335 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:00:20 [ location:336 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 16:00:20 [ location:336 ] - [ INFO ] 开始接收数据。
2019-12-18 16:00:20 [ controller:336 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:00:20 [ controller:337 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:00:20 [ controller:338 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:00:20 [ controller:338 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Subscribed to topic(s): command
2019-12-18 16:00:20 [ controller:338 ] - [ INFO ] 开始接收数据。
2019-12-18 16:00:20 [ location:350 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 16:00:20 [ controller:359 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 16:00:20 [ location:374 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:00:20 [ controller:376 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:00:20 [ location:391 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:00:20 [ location:392 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:00:20 [ controller:396 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:00:20 [ controller:396 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:00:20 [ location:401 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:00:20 [ controller:402 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:00:20 [ location:403 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:00:20 [ controller:403 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:00:20 [ location:404 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:00:20 [ controller:404 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:00:20 [ location:404 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:00:20 [ controller:405 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:00:20 [ location:405 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:00:20 [ controller:405 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:00:20 [ location:405 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:00:20 [ controller:406 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:00:20 [ location:406 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:00:20 [ controller:406 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:00:20 [ location:407 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:00:20 [ controller:410 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:00:20 [ controller:411 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:00:20 [ location:412 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:00:20 [ controller:412 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:00:20 [ location:413 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:00:20 [ location:415 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:00:20 [ controller:415 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:00:20 [ controller:416 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:00:20 [ controller:416 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:00:20 [ controller:417 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:00:20 [ controller:417 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:00:20 [ location:418 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:00:20 [ location:419 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:00:20 [ location:419 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:00:20 [ controller:419 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:00:20 [ location:420 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:00:20 [ controller:420 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:00:20 [ location:421 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:00:20 [ location:421 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:00:20 [ controller:421 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:00:20 [ location:425 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:00:20 [ controller:427 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:00:20 [ location:428 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:00:20 [ kafka-producer-network-thread | producer-2:429 ] - [ DEBUG ] [Producer clientId=producer-2] Starting Kafka producer I/O thread.
2019-12-18 16:00:20 [ kafka-producer-network-thread | producer-1:429 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 16:00:20 [ controller:429 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:00:20 [ controller:429 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:00:20 [ controller:431 ] - [ DEBUG ] [Producer clientId=producer-2] Kafka producer started
2019-12-18 16:00:20 [ location:431 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:00:20 [ location:431 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:00:20 [ controller:431 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:00:20 [ location:432 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 16:00:20 [ location:432 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:00:20 [ controller:669 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:00:20 [ location:669 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:00:21 [ location:824 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:00:21 [ controller:825 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:00:21 [ location:826 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:00:21 [ controller:827 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:00:21 [ location:828 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:00:21 [ controller:829 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:00:21 [ location:836 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:00:21 [ location:836 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:00:21 [ location:837 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:00:21 [ controller:837 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:00:21 [ controller:838 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:00:21 [ controller:838 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:00:21 [ controller:863 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:00:21 [ controller:863 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:00:21 [ location:864 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:00:21 [ location:865 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:00:21 [ location:874 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:00:21 [ controller:876 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:00:21 [ location:878 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656021103, latencyMs=214, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:00:21 [ location:878 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:21 [ location:879 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:21 [ controller:879 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656021105, latencyMs=216, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:00:21 [ controller:880 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:21 [ controller:880 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:21 [ kafka-coordinator-heartbeat-thread | serviceSys:881 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:00:21 [ location:881 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:00:21 [ kafka-coordinator-heartbeat-thread | serviceSys:882 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:00:21 [ location:882 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:00:21 [ location:882 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:00:21 [ location:882 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 16:00:21 [ controller:884 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:00:21 [ controller:884 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:00:21 [ controller:884 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:00:21 [ controller:884 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] (Re-)joining group
2019-12-18 16:00:21 [ controller:885 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@73b78c28)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:21 [ location:885 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@429d32e2)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:21 [ location:887 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:00:21 [ controller:887 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:00:21 [ location:888 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:00:21 [ location:889 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:00:21 [ location:890 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:00:21 [ location:890 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:00:21 [ location:890 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:00:21 [ controller:892 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:00:21 [ controller:893 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:00:21 [ controller:894 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:00:21 [ controller:894 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:00:21 [ controller:894 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:00:21 [ location:897 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:00:21 [ controller:898 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:00:21 [ controller:909 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@1ea01aad
2019-12-18 16:00:21 [ controller:910 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending follower SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=13, memberId=consumer-2-2c062392-be25-429d-89a2-6c6ac6fa49b5, groupAssignment=)
2019-12-18 16:00:21 [ location:913 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@65483af5
2019-12-18 16:00:21 [ location:913 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: 1 rack: null) for sending metadata request
2019-12-18 16:00:21 [ location:914 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:914 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:00:21 [ location:916 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:00:21 [ location:917 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:00:21 [ location:918 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:00:21 [ location:918 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:00:21 [ location:918 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:00:21 [ location:922 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:00:21 [ location:923 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200,command) to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:928 ] - [ DEBUG ] Updated cluster metadata version 3 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:00:21 [ location:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-2-2c062392-be25-429d-89a2-6c6ac6fa49b5=Subscription(topics=[command]), consumer-1-e9b93a65-9821-45b3-b128-cb17a5e018ac=Subscription(topics=[msg0200])}
2019-12-18 16:00:21 [ location:930 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-2-2c062392-be25-429d-89a2-6c6ac6fa49b5=Assignment(partitions=[command-0, command-1]), consumer-1-e9b93a65-9821-45b3-b128-cb17a5e018ac=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 16:00:21 [ location:932 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=13, memberId=consumer-1-e9b93a65-9821-45b3-b128-cb17a5e018ac, groupAssignment=consumer-2-2c062392-be25-429d-89a2-6c6ac6fa49b5,consumer-1-e9b93a65-9821-45b3-b128-cb17a5e018ac)
2019-12-18 16:00:21 [ controller:936 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Successfully joined group with generation 13
2019-12-18 16:00:21 [ controller:936 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:00:21 [ location:941 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 13
2019-12-18 16:00:21 [ location:942 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:00:21 [ controller:942 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Setting newly assigned partitions [command-0, command-1]
2019-12-18 16:00:21 [ location:942 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 16:00:21 [ controller:943 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetching committed offsets for partitions: [command-0, command-1]
2019-12-18 16:00:21 [ location:943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 16:00:21 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 516
2019-12-18 16:00:21 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 508
2019-12-18 16:00:21 [ controller:947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-0 to the committed offset 0
2019-12-18 16:00:21 [ controller:948 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-1 to the committed offset 0
2019-12-18 16:00:21 [ location:948 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 508 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ controller:948 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:949 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 516 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ controller:949 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ controller:949 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:949 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ controller:951 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ controller:952 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:00:21 [ controller:953 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:00:21 [ controller:954 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:00:21 [ controller:955 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:00:21 [ controller:956 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:00:21 [ controller:956 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:00:21 [ controller:959 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:00:21 [ location:967 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 508 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=533, lastStableOffset = 533, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=1750)
2019-12-18 16:00:21 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 516 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=541, lastStableOffset = 541, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=1750)
2019-12-18 16:00:21 [ location:988 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 16:00:21 [ location:991 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 16:00:21 [ location:992 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 16:00:21 [ location:993 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 16:00:21 [ location:994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:997 ] - [ INFO ] 接收到50条数据。
2019-12-18 16:00:21 [ location:1000 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1000 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1155 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1158 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1163 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1163 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1164 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1164 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1164 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1164 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1164 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1165 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1165 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1165 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1165 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1165 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1165 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1166 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1166 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1166 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1166 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1166 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1166 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1166 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1167 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1167 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1167 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1167 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1167 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1167 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1167 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1168 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1168 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1168 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1168 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1168 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1169 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1169 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1170 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1170 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1173 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1173 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1173 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1174 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1174 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1174 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1174 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1174 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1174 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1175 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1175 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1175 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1175 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1175 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1175 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1176 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1176 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1176 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1176 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1176 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1176 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1176 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1177 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1177 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1177 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1178 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1178 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1178 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1179 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1179 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1179 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1179 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1180 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1180 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1180 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1180 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1182 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1185 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1186 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1187 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1188 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1188 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1189 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1189 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1189 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1189 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1189 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1189 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1189 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1190 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1190 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1190 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1190 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1190 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1190 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1190 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1191 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1191 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1191 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1191 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1191 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1192 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1192 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1192 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1194 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1195 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1195 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1195 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1195 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1195 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1195 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1195 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1196 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1196 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1196 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1196 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1196 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1196 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1196 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1197 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1197 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1197 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1197 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1197 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1197 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1197 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1198 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1198 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1198 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1198 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1198 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1198 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1198 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1198 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1199 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1199 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1199 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1199 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1199 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1200 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1200 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1200 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1201 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1201 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1201 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1201 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1201 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1202 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1203 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1203 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1203 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1203 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1204 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1204 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1204 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1204 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1204 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1204 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1204 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1205 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1205 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1205 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1205 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1206 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1206 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1206 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1206 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1206 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1207 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1207 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1207 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1207 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1209 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1209 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1209 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1209 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1209 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1209 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1209 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1209 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1210 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1210 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1210 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1210 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1210 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1210 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1211 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1213 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1213 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1213 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1213 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1214 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1214 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1214 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1214 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1214 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ location:1214 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:00:21 [ location:1214 ] - [ INFO ] hex: 0101
2019-12-18 16:00:21 [ location:1214 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:00:21 [ location:1214 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:00:21 [ controller:1436 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:00:21 [ controller:1469 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:21 [ controller:1470 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:21 [ controller:1470 ] - [ DEBUG ] Added sensor with name command-0.records-lag
2019-12-18 16:00:21 [ controller:1470 ] - [ DEBUG ] Added sensor with name topic.command.bytes-fetched
2019-12-18 16:00:21 [ controller:1471 ] - [ DEBUG ] Added sensor with name topic.command.records-fetched
2019-12-18 16:00:21 [ controller:1472 ] - [ DEBUG ] Added sensor with name command-1.records-lag
2019-12-18 16:00:21 [ controller:1472 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ controller:1472 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ controller:1472 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ kafka-coordinator-heartbeat-thread | serviceSys:1505 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 533 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=533, lastStableOffset = 533, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:21 [ kafka-coordinator-heartbeat-thread | serviceSys:1505 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 541 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=541, lastStableOffset = 541, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:21 [ location:1506 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:1506 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:21 [ location:1506 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ controller:1946 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 16:00:22 [ location:1946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=541, metadata=''}, msg0200-1=OffsetAndMetadata{offset=533, metadata=''}}
2019-12-18 16:00:22 [ controller:1957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 16:00:22 [ controller:1957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 16:00:22 [ controller:1958 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 16:00:22 [ location:1960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 541 for partition msg0200-0
2019-12-18 16:00:22 [ location:1960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 533 for partition msg0200-1
2019-12-18 16:00:22 [ location:1960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=541, metadata=''}, msg0200-1=OffsetAndMetadata{offset=533, metadata=''}}
2019-12-18 16:00:22 [ controller:1977 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ controller:1977 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ controller:1978 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ controller:1978 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ controller:1978 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ location:2013 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 533 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=533, lastStableOffset = 533, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ location:2013 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 541 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=541, lastStableOffset = 541, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ location:2014 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ location:2014 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ location:2014 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ location:2218 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:00:22 [ controller:2440 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:00:22 [ controller:2482 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ controller:2483 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ controller:2483 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ controller:2483 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ controller:2483 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ location:2518 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 533 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=533, lastStableOffset = 533, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ location:2519 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 541 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=541, lastStableOffset = 541, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:22 [ location:2519 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ location:2519 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:22 [ location:2519 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ location:2951 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=541, metadata=''}, msg0200-1=OffsetAndMetadata{offset=533, metadata=''}}
2019-12-18 16:00:23 [ controller:2951 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 16:00:23 [ controller:2970 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 16:00:23 [ controller:2970 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 16:00:23 [ controller:2970 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 16:00:23 [ location:2973 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 541 for partition msg0200-0
2019-12-18 16:00:23 [ location:2973 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 533 for partition msg0200-1
2019-12-18 16:00:23 [ location:2973 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=541, metadata=''}, msg0200-1=OffsetAndMetadata{offset=533, metadata=''}}
2019-12-18 16:00:23 [ controller:2988 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ controller:2988 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ controller:2989 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ controller:2989 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ controller:2989 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ location:3025 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 533 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=533, lastStableOffset = 533, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ location:3025 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 541 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=541, lastStableOffset = 541, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ location:3026 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ location:3026 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ location:3026 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ location:3222 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:00:23 [ controller:3445 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:00:23 [ controller:3493 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ controller:3494 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ controller:3494 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ controller:3494 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ controller:3494 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ kafka-coordinator-heartbeat-thread | serviceSys:3535 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 533 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=533, lastStableOffset = 533, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ kafka-coordinator-heartbeat-thread | serviceSys:3535 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 541 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=541, lastStableOffset = 541, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:23 [ location:3536 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ location:3536 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:23 [ location:3536 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:24 [ kafka-coordinator-heartbeat-thread | serviceSys:3941 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:24 [ kafka-coordinator-heartbeat-thread | serviceSys:3946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:00:24 [ controller:3946 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:00:24 [ location:3950 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:00:24 [ controller:3951 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 16:00:24 [ location:3952 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=541, metadata=''}, msg0200-1=OffsetAndMetadata{offset=533, metadata=''}}
2019-12-18 16:00:24 [ controller:3959 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-0
2019-12-18 16:00:24 [ controller:3959 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 0 for partition command-1
2019-12-18 16:00:24 [ controller:3959 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=0, metadata=''}, command-1=OffsetAndMetadata{offset=0, metadata=''}}
2019-12-18 16:00:24 [ location:3961 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 541 for partition msg0200-0
2019-12-18 16:00:24 [ location:3961 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 533 for partition msg0200-1
2019-12-18 16:00:24 [ location:3961 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=541, metadata=''}, msg0200-1=OffsetAndMetadata{offset=533, metadata=''}}
2019-12-18 16:00:24 [ controller:3998 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:24 [ controller:3998 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:24 [ controller:3998 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:24 [ controller:3998 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:24 [ controller:3998 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:24 [ location:4041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 533 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=533, lastStableOffset = 533, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:24 [ location:4041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 541 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=541, lastStableOffset = 541, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:00:24 [ location:4041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:24 [ location:4041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:00:24 [ location:4041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:46 [ main:0 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 16:03:46 [ main:308 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:03:46 [ main:328 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:03:46 [ main:335 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:03:47 [ main:367 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:03:47 [ main:389 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:03:47 [ main:389 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:03:47 [ main:390 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:03:47 [ main:391 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:03:47 [ main:391 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:03:47 [ main:392 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:03:47 [ main:393 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:03:47 [ main:394 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:03:47 [ main:395 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:03:47 [ main:400 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:03:47 [ main:401 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:03:47 [ main:401 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:03:47 [ main:401 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:03:47 [ main:402 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:03:47 [ main:405 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:03:47 [ main:405 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:03:47 [ main:406 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:03:47 [ main:407 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:408 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 16:03:47 [ main:411 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:03:47 [ main:411 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:03:47 [ main:413 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 16:03:47 [ main:414 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:422 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:422 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:548 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:550 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:551 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:556 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:708 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:708 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:736 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:737 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:744 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:762 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:763 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:765 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:765 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:767 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:767 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:767 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:772 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:777 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-per-batch
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:778 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:778 ] - [ DEBUG ] Added sensor with name topic.msg0200.compression-rate
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:779 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-retries
2019-12-18 16:03:47 [ kafka-producer-network-thread | producer-1:780 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-errors
2019-12-18 16:03:47 [ main:795 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:805 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:813 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:823 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:836 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:850 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:861 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:873 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:883 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:893 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:903 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:915 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:928 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:938 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:950 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:961 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:971 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:988 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:997 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1014 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1031 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1056 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1071 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1095 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1109 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1119 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1129 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1149 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1162 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1172 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1181 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1194 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1210 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1228 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1249 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1267 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1292 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1310 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1322 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1335 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1345 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:47 [ main:1358 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1372 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1386 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1395 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1411 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1426 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1438 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1452 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1464 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1477 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1488 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1501 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1522 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1534 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1545 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1555 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1565 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1574 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1586 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1596 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1609 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1619 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1638 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1652 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1666 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1688 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1699 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1712 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1723 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1737 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1749 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1758 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1767 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1781 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1797 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1808 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1819 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1831 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1841 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1853 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1868 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1879 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1893 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1902 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1913 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1930 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1940 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1953 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1965 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1974 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:1989 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2003 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2019 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2034 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2051 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2068 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2088 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2105 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2118 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2137 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2154 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2171 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2190 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2217 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2228 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2237 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2247 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2257 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2266 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2280 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2297 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2311 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2324 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2334 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2348 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:48 [ main:2360 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2370 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2382 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2392 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2403 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2411 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2421 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2431 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2443 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2457 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2469 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2483 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2500 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2521 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2539 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2551 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2568 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2587 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2597 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2607 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2617 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2628 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2638 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2649 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2658 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2667 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2677 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2689 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2703 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2721 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2731 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2742 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2753 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2765 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:49 [ main:2766 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 16:03:49 [ main:2767 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:03:49 [ main:2768 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:03:49 [ main:2768 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:03:49 [ main:2769 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:03:49 [ main:2769 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:03:49 [ main:2770 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:03:49 [ main:2770 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:03:49 [ main:2771 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:03:49 [ main:2771 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:03:49 [ main:2775 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:03:49 [ main:2778 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:03:49 [ main:2779 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:03:49 [ main:2780 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:03:49 [ main:2781 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:03:49 [ main:2782 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:03:49 [ main:2782 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:03:49 [ main:2782 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:03:49 [ main:2782 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:03:49 [ main:2783 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:03:49 [ main:2784 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:03:49 [ main:2785 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:03:49 [ main:2787 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2789 ] - [ DEBUG ] [Producer clientId=producer-2] Starting Kafka producer I/O thread.
2019-12-18 16:03:49 [ main:2789 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:03:49 [ main:2789 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:03:49 [ main:2789 ] - [ DEBUG ] [Producer clientId=producer-2] Kafka producer started
2019-12-18 16:03:49 [ main:2790 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2791 ] - [ DEBUG ] [Producer clientId=producer-2] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2792 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2793 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2794 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2795 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2795 ] - [ DEBUG ] [Producer clientId=producer-2] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2796 ] - [ DEBUG ] [Producer clientId=producer-2] Completed connection to node -1. Fetching API versions.
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2796 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating API versions fetch from node -1.
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2798 ] - [ DEBUG ] [Producer clientId=producer-2] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2798 ] - [ DEBUG ] [Producer clientId=producer-2] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2802 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2808 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2808 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2809 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2810 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2811 ] - [ DEBUG ] [Producer clientId=producer-2] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2811 ] - [ DEBUG ] [Producer clientId=producer-2] Completed connection to node 1. Fetching API versions.
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2811 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating API versions fetch from node 1.
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2813 ] - [ DEBUG ] [Producer clientId=producer-2] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2813 ] - [ DEBUG ] Added sensor with name topic.command.records-per-batch
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2813 ] - [ DEBUG ] Added sensor with name topic.command.bytes
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2814 ] - [ DEBUG ] Added sensor with name topic.command.compression-rate
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2814 ] - [ DEBUG ] Added sensor with name topic.command.record-retries
2019-12-18 16:03:49 [ kafka-producer-network-thread | producer-2:2814 ] - [ DEBUG ] Added sensor with name topic.command.record-errors
2019-12-18 16:03:49 [ main:2818 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2826 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2836 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2844 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2853 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2861 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2871 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2880 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2889 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2901 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2911 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2921 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2931 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2943 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2952 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2964 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2975 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2987 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:2998 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3009 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3017 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3026 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3035 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3042 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3050 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3058 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3067 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3075 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3083 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3092 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3100 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3110 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3122 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3134 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3147 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3161 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3171 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3185 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3197 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3212 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3222 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3230 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3239 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3248 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3256 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3266 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3274 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3282 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3290 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3299 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3307 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3317 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3326 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3337 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3349 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:49 [ main:3361 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3373 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3384 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3394 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3402 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3412 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3424 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3435 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3443 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3454 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3463 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3474 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3482 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3490 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3499 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3507 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3516 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3529 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3541 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3552 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3566 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3577 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3590 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3600 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3615 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3627 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3636 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3645 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3653 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3661 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3670 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3679 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3687 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3695 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3705 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3712 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3721 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3729 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3739 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3751 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3760 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3769 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3781 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3791 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3803 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3815 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3825 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3839 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3848 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3857 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3865 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3874 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3881 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3890 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3898 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3906 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3915 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3923 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3931 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3939 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3949 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3960 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3969 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3978 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3987 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:3998 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4010 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4021 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4036 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4048 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4056 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4063 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4071 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4079 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4086 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4096 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4104 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4113 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4123 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4132 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4142 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4150 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4160 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4169 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4180 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4187 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4196 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4206 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4217 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4230 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4240 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4253 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4264 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4274 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:50 [ main:4281 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:57 [ location:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 16:03:57 [ controller:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-12-18 16:03:57 [ location:3 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:03:57 [ controller:3 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:03:57 [ location:150 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:03:57 [ controller:150 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:03:57 [ location:178 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:03:57 [ controller:182 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:03:57 [ controller:208 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:03:57 [ location:213 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:03:57 [ controller:220 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:03:57 [ location:220 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:03:57 [ controller:220 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:03:57 [ location:221 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:03:57 [ controller:222 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:03:57 [ location:223 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:03:57 [ controller:224 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:03:57 [ controller:225 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:03:57 [ location:225 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:03:57 [ controller:227 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:03:57 [ location:228 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:03:57 [ controller:236 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:03:57 [ location:236 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:03:57 [ controller:240 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:03:57 [ location:242 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:03:57 [ location:248 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:03:57 [ controller:318 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:03:57 [ location:319 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:03:57 [ location:320 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:03:57 [ controller:319 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:03:57 [ controller:321 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:03:58 [ controller:328 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:03:58 [ location:330 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:03:58 [ location:333 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:03:58 [ controller:336 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:03:58 [ location:336 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:03:58 [ controller:337 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:03:58 [ controller:337 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:03:58 [ location:338 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:03:58 [ controller:340 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:03:58 [ location:340 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:03:58 [ location:341 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:03:58 [ controller:346 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:03:58 [ controller:347 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:03:58 [ controller:352 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:03:58 [ controller:352 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Subscribed to topic(s): command
2019-12-18 16:03:58 [ controller:353 ] - [ INFO ] 开始接收数据。
2019-12-18 16:03:58 [ location:358 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:03:58 [ location:358 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:03:58 [ location:362 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:03:58 [ location:363 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 16:03:58 [ location:363 ] - [ INFO ] 开始接收数据。
2019-12-18 16:03:58 [ controller:369 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 16:03:58 [ location:371 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 16:03:58 [ controller:402 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:03:58 [ location:402 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:03:58 [ location:413 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:03:58 [ controller:414 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:03:58 [ location:414 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:03:58 [ controller:414 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:03:58 [ location:422 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:03:58 [ controller:423 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:03:58 [ location:423 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:03:58 [ controller:424 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:03:58 [ location:424 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:03:58 [ controller:424 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:03:58 [ controller:425 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:03:58 [ controller:425 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:03:58 [ location:426 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:03:58 [ controller:427 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:03:58 [ location:427 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:03:58 [ controller:427 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:03:58 [ controller:429 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:03:58 [ location:429 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:03:58 [ controller:430 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:03:58 [ controller:431 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:03:58 [ location:432 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:03:58 [ location:433 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:03:58 [ location:434 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:03:58 [ controller:435 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:03:58 [ controller:436 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:03:58 [ controller:436 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:03:58 [ controller:437 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:03:58 [ controller:437 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:03:58 [ controller:438 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:03:58 [ controller:439 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:03:58 [ controller:439 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:03:58 [ location:441 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:03:58 [ location:442 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:03:58 [ location:442 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:03:58 [ location:443 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:03:58 [ location:443 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:03:58 [ controller:443 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:03:58 [ location:446 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:03:58 [ location:449 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:03:58 [ location:449 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:03:58 [ location:450 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:03:58 [ location:451 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:03:58 [ kafka-producer-network-thread | producer-1:453 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 16:03:58 [ controller:453 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:03:58 [ controller:454 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:03:58 [ controller:455 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 16:03:58 [ controller:456 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:58 [ kafka-producer-network-thread | producer-2:461 ] - [ DEBUG ] [Producer clientId=producer-2] Starting Kafka producer I/O thread.
2019-12-18 16:03:58 [ location:461 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:03:58 [ location:462 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:03:58 [ location:463 ] - [ DEBUG ] [Producer clientId=producer-2] Kafka producer started
2019-12-18 16:03:58 [ location:463 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:58 [ location:740 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:58 [ controller:745 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:58 [ location:874 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:03:58 [ controller:875 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:03:58 [ location:877 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:03:58 [ controller:878 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:03:58 [ location:879 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:03:58 [ controller:881 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:03:58 [ controller:890 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:03:58 [ controller:892 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:03:58 [ controller:892 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:03:58 [ location:892 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:03:58 [ location:892 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:03:58 [ location:893 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:03:58 [ controller:918 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:58 [ location:918 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:58 [ controller:919 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:58 [ location:919 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:58 [ controller:927 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:03:58 [ location:927 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:03:58 [ controller:929 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656238600, latencyMs=203, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:03:58 [ controller:929 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:03:58 [ location:930 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656238600, latencyMs=202, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:03:58 [ location:930 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:03:58 [ location:930 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:03:58 [ controller:930 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:03:58 [ location:933 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:03:58 [ kafka-coordinator-heartbeat-thread | serviceSys:933 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:03:58 [ location:933 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:03:58 [ location:934 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:03:58 [ location:934 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 16:03:58 [ kafka-coordinator-heartbeat-thread | serviceSys:934 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:03:58 [ controller:934 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:03:58 [ controller:935 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:03:58 [ controller:935 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:03:58 [ controller:935 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] (Re-)joining group
2019-12-18 16:03:58 [ controller:936 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@2c0c4708)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:03:58 [ location:937 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@21843ee)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:03:58 [ controller:939 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:03:58 [ location:939 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:03:58 [ location:941 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:03:58 [ location:942 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:03:58 [ controller:942 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:03:58 [ location:943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:03:58 [ location:943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:03:58 [ location:943 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:03:58 [ controller:943 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:03:58 [ controller:944 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:03:58 [ controller:944 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:03:58 [ controller:945 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:03:58 [ location:950 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:58 [ controller:954 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:58 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@9594bca
2019-12-18 16:03:58 [ location:968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960=Subscription(topics=[msg0200])}
2019-12-18 16:03:58 [ location:974 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 16:03:58 [ location:975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=15, memberId=consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960, groupAssignment=consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960)
2019-12-18 16:03:58 [ location:982 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] SyncGroup failed due to group rebalance
2019-12-18 16:03:58 [ location:983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:03:58 [ location:983 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 16:03:58 [ location:984 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@2f97dc81)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:03:58 [ controller:994 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@62dc9837
2019-12-18 16:03:58 [ controller:994 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending follower SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=16, memberId=consumer-2-03251324-dfd0-4d6a-9a03-7ee1e01bae38, groupAssignment=)
2019-12-18 16:03:58 [ location:999 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@701a1318
2019-12-18 16:03:58 [ location:1000 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: 1 rack: null) for sending metadata request
2019-12-18 16:03:58 [ location:1000 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ location:1001 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:03:58 [ location:1002 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:03:58 [ location:1004 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:03:58 [ location:1004 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:03:58 [ location:1004 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:03:58 [ location:1005 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:03:58 [ location:1008 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:58 [ location:1008 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200,command) to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ location:1013 ] - [ DEBUG ] Updated cluster metadata version 3 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:03:58 [ location:1013 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960=Subscription(topics=[msg0200]), consumer-2-03251324-dfd0-4d6a-9a03-7ee1e01bae38=Subscription(topics=[command])}
2019-12-18 16:03:58 [ location:1013 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Finished assignment for group: {consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960=Assignment(partitions=[msg0200-0, msg0200-1]), consumer-2-03251324-dfd0-4d6a-9a03-7ee1e01bae38=Assignment(partitions=[command-0, command-1])}
2019-12-18 16:03:58 [ location:1013 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=16, memberId=consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960, groupAssignment=consumer-1-044b43c5-368a-4957-a567-0fe6fcb56960,consumer-2-03251324-dfd0-4d6a-9a03-7ee1e01bae38)
2019-12-18 16:03:58 [ controller:1020 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Successfully joined group with generation 16
2019-12-18 16:03:58 [ controller:1020 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:03:58 [ controller:1022 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Setting newly assigned partitions [command-0, command-1]
2019-12-18 16:03:58 [ controller:1023 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetching committed offsets for partitions: [command-0, command-1]
2019-12-18 16:03:58 [ location:1024 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 16
2019-12-18 16:03:58 [ location:1025 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:03:58 [ location:1025 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 16:03:58 [ location:1025 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 16:03:58 [ controller:1030 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-0 to the committed offset 0
2019-12-18 16:03:58 [ location:1030 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 541
2019-12-18 16:03:58 [ location:1030 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 533
2019-12-18 16:03:58 [ location:1031 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 533 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ location:1031 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 541 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ location:1032 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1032 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-1 to the committed offset 0
2019-12-18 16:03:58 [ controller:1032 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1032 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 0 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1033 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1033 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1035 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:03:58 [ controller:1037 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:03:58 [ controller:1038 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:03:58 [ controller:1038 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:03:58 [ controller:1038 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:03:58 [ controller:1039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:03:58 [ controller:1041 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:58 [ controller:1050 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=9375)
2019-12-18 16:03:58 [ location:1050 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 533 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=5250)
2019-12-18 16:03:58 [ controller:1051 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 0 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=9375)
2019-12-18 16:03:58 [ location:1051 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 541 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=5250)
2019-12-18 16:03:58 [ location:1081 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 16:03:58 [ location:1085 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 16:03:58 [ controller:1085 ] - [ DEBUG ] Added sensor with name command-0.records-lag
2019-12-18 16:03:58 [ location:1086 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 16:03:58 [ location:1086 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 16:03:58 [ location:1087 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ location:1087 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ location:1087 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1089 ] - [ DEBUG ] Added sensor with name topic.command.bytes-fetched
2019-12-18 16:03:58 [ controller:1089 ] - [ DEBUG ] Added sensor with name topic.command.records-fetched
2019-12-18 16:03:58 [ controller:1090 ] - [ DEBUG ] Added sensor with name command-1.records-lag
2019-12-18 16:03:58 [ controller:1090 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1091 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ controller:1091 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:58 [ location:1093 ] - [ INFO ] 接收到150条数据。
2019-12-18 16:03:58 [ location:1102 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:58 [ location:1103 ] - [ INFO ] hex: 0101
2019-12-18 16:03:58 [ controller:1103 ] - [ INFO ] 接收到150条数据。
2019-12-18 16:03:58 [ controller:1103 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:58 [ controller:1318 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:58 [ kafka-producer-network-thread | producer-1:1320 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 16:03:58 [ kafka-producer-network-thread | producer-1:1320 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1329 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1330 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1331 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1332 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1332 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1332 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1335 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1336 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=hexMsg) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:03:59 [ location:1392 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1393 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1396 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1396 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1396 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1397 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1397 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1397 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1397 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1398 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1398 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1398 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1398 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1399 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1399 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1399 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1399 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1399 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1399 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1399 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1400 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1400 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1400 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1400 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1400 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1400 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1401 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1401 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1401 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1401 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1401 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1402 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1402 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1403 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1403 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1403 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1403 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1404 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1404 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1404 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1404 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1405 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1405 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1405 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1405 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1405 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1405 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1406 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1406 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1406 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1406 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1406 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1406 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1406 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1407 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1407 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1407 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1407 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1407 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1407 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1407 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1408 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1408 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1408 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1408 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1408 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1408 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1408 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1408 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1409 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1409 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1409 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1409 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1413 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1413 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1413 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1413 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1413 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1413 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1414 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1414 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1414 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1414 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1414 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1414 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1414 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1415 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1415 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1415 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1415 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1420 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1420 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1420 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1420 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1420 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1420 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1421 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1421 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1421 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1421 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1421 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1421 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1421 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1421 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1421 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1422 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1422 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1422 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1422 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1422 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1422 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1422 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1422 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1422 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1423 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1423 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1423 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1423 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1423 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1423 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1423 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1423 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1424 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1424 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1424 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1430 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1430 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1430 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1430 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1430 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1430 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1431 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1431 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1431 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1431 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1431 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1431 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1431 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1431 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1432 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1432 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1432 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1432 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1432 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1432 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1432 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1432 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1433 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1433 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1433 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1433 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1433 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1433 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1433 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1433 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1433 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1434 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1435 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1436 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1436 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1436 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1436 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1436 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1436 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1436 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1437 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1437 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1437 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1437 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1437 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1437 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1437 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1437 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1437 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1438 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1438 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1438 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1438 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1438 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1438 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1438 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1438 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1438 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1438 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1438 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1439 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1439 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1439 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1439 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1439 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1439 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1439 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1439 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1439 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1439 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1439 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1440 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1440 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1440 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1440 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1440 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1440 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1440 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1440 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1440 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1440 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1441 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1441 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1441 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1441 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1441 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1441 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1441 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1441 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1441 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1441 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1442 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1442 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1442 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1442 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1442 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1442 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1442 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1442 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1442 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1442 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1443 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1443 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1443 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1443 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1443 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1443 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1443 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1443 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1443 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1444 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1444 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1454 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1454 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1454 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1454 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1454 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1454 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1454 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1454 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1454 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1455 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1455 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1455 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1455 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1455 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1455 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1455 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1455 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1455 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1455 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1455 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1455 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1456 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1456 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1456 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1456 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1456 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1456 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1456 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1456 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1456 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1456 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1457 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1457 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1457 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1457 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1457 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1457 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1457 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1457 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1462 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1463 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1463 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1463 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1463 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1463 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1463 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1463 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1463 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1463 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1464 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1464 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1464 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1464 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1464 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1464 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1464 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1464 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1464 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1464 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1464 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1465 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1465 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1465 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1465 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1465 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1465 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1465 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1465 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1465 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1465 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1465 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1466 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1466 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1466 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1466 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1466 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1466 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1466 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1466 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1466 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1466 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1466 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1467 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1467 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1485 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1485 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1485 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1485 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1485 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1485 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1485 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1486 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1486 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1486 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1486 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1486 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1486 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1486 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1486 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1486 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1486 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1487 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1487 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1487 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1487 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1487 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1487 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1487 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1487 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1487 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1487 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1487 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1487 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1488 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1488 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1488 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1488 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1488 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1488 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1488 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1488 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1488 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1488 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1488 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1489 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1489 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1489 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1489 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1489 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1489 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1489 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1489 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1489 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1489 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1489 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1490 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1490 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1490 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1490 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1490 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1490 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1490 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1490 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1490 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1490 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1490 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1490 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1491 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1491 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1491 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1491 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1491 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1491 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1491 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1491 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1491 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1491 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1491 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1491 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1492 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1492 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1492 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1492 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1492 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1492 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1492 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1492 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1492 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1492 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1492 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1492 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1492 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1493 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1493 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1493 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1493 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1493 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1493 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1493 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1493 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1493 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1493 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1493 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1493 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1493 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1494 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1494 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1494 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1494 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1494 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1494 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1494 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1494 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1498 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1498 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1498 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1498 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1525 ] - [ WARN ] [Producer clientId=producer-1] Error while fetching metadata with correlation id 1 : {hexMsg=LEADER_NOT_AVAILABLE}
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1525 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [])
2019-12-18 16:03:59 [ location:1526 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1534 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1535 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1537 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1537 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1537 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1537 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1537 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1537 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1537 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1538 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1538 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1539 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1539 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1539 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1539 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1540 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1540 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1540 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1540 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1540 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1540 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1540 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1540 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1540 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1540 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1541 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1541 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1544 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1544 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1544 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1544 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1544 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1544 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1551 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1551 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1551 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1551 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1551 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1551 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1551 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1551 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1552 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1552 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1552 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1552 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1552 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1552 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1552 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1552 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1552 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1552 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1552 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1552 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1552 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1553 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1553 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1553 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1553 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1553 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1560 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1560 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1561 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1561 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1561 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1561 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1562 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1562 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1562 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1562 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1562 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1562 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1562 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1562 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1562 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1562 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1562 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1562 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1563 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1563 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1564 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1564 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1565 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1565 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1565 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1565 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1565 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1565 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1565 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1565 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1565 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1565 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1565 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1565 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1568 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1573 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1574 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1574 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1574 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1574 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1574 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1575 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1575 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1575 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1575 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1575 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1575 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1575 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1575 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1575 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1575 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1575 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1575 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1575 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1576 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1576 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1576 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1576 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1576 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1576 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1576 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1576 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1576 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1576 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1576 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1576 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1576 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1577 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1577 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1577 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1577 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1577 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1577 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:03:59 [ location:1577 ] - [ INFO ] hex: 0101
2019-12-18 16:03:59 [ location:1577 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:03:59 [ location:1577 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:03:59 [ location:1599 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:03:59 [ location:1599 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:03:59 [ location:1600 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ location:1600 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ location:1600 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1630 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: 1 rack: null) for sending metadata request
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1631 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1635 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1636 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1637 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1637 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1637 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1637 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2019-12-18 16:03:59 [ kafka-coordinator-heartbeat-thread | serviceSys:1643 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:03:59 [ kafka-coordinator-heartbeat-thread | serviceSys:1643 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1807 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1807 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=hexMsg) to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1856 ] - [ WARN ] [Producer clientId=producer-1] Error while fetching metadata with correlation id 3 : {hexMsg=LEADER_NOT_AVAILABLE}
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1856 ] - [ DEBUG ] Updated cluster metadata version 3 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [])
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1957 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=hexMsg) to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1977 ] - [ DEBUG ] Updated cluster metadata version 4 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = hexMsg, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1991 ] - [ DEBUG ] Added sensor with name topic.hexMsg.records-per-batch
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1992 ] - [ DEBUG ] Added sensor with name topic.hexMsg.bytes
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1992 ] - [ DEBUG ] Added sensor with name topic.hexMsg.compression-rate
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1992 ] - [ DEBUG ] Added sensor with name topic.hexMsg.record-retries
2019-12-18 16:03:59 [ kafka-producer-network-thread | producer-1:1992 ] - [ DEBUG ] Added sensor with name topic.hexMsg.record-errors
2019-12-18 16:03:59 [ controller:2006 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2006 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2007 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2017 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2017 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2018 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2028 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2029 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ location:2029 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:03:59 [ controller:2029 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2039 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2039 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2040 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2069 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2070 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2070 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2099 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2099 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2100 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2120 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ location:2120 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:03:59 [ location:2121 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:03:59 [ controller:2120 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ location:2122 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:03:59 [ location:2123 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:03:59 [ controller:2123 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ location:2124 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:03:59 [ location:2124 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ location:2124 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ location:2124 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:03:59 [ controller:2135 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2135 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2136 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2156 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2157 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2158 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2182 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2182 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2182 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2202 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2202 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2202 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2222 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2222 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2222 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2232 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2232 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2232 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2247 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2247 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2248 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2257 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2257 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2262 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2272 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2272 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2273 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2294 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2294 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2294 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:03:59 [ controller:2313 ] - [ INFO ] 发送成功 ---
2019-12-18 16:03:59 [ controller:2313 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:03:59 [ controller:2314 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2333 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2333 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2334 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2355 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2356 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2357 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2374 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2374 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2375 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2394 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2394 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2394 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2414 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2414 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2415 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2434 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2434 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2435 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2454 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2454 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2455 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2465 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2466 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2466 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2476 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2476 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2477 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2497 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2497 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2498 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2514 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2514 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2515 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2526 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2526 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2527 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2540 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2540 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2541 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2561 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2561 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2562 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ location:2581 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:04:00 [ controller:2591 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2591 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2591 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2611 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2611 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2611 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2621 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2621 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2621 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2635 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ location:2635 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:00 [ location:2635 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:00 [ location:2636 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:00 [ location:2636 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:00 [ location:2636 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:00 [ controller:2635 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2637 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2648 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2648 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2649 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2660 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2660 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2661 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2670 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2670 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2671 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2689 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2689 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2690 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2706 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2707 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2707 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2728 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2729 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2730 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2743 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2743 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2744 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2756 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2756 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2757 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2778 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2778 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2779 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2792 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2792 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2792 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2813 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2813 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2814 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2826 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2826 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2826 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2835 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2835 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2835 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2847 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2847 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2848 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2858 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2858 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2859 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2868 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2868 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2868 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2877 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2878 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2878 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2888 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2888 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2889 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2903 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2903 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2905 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2917 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2917 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2917 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2928 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2929 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2929 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2941 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2941 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2941 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2951 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2952 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2952 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2965 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2965 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2965 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2982 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2982 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2983 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:2994 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:2994 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:2994 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3007 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3007 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3008 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3020 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3020 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3021 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3030 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3031 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3031 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ location:3034 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:00 [ location:3041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:04:00 [ location:3041 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:04:00 [ location:3042 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:00 [ controller:3041 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3042 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3042 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3051 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3051 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3052 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3064 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3064 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3064 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3075 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3075 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3076 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3084 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3084 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3085 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3095 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3095 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3096 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3105 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3106 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3106 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3118 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3118 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3118 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3131 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3131 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3131 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3144 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3145 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3145 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ location:3146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:00 [ location:3146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:00 [ location:3146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:00 [ location:3146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:00 [ location:3146 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:00 [ controller:3156 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3156 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3156 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3167 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3167 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3168 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3180 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3180 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3180 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3192 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3193 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3193 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3203 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3203 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3203 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3215 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3215 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3215 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3225 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3225 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3225 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3234 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3234 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3235 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3245 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3245 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3245 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3254 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3254 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3255 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3265 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3265 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3266 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3275 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3275 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3275 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3285 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3285 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3285 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3294 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3295 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3296 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3306 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3306 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3307 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:00 [ controller:3318 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:00 [ controller:3319 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:00 [ controller:3319 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3331 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3331 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3332 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3344 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3344 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3344 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3357 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3357 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3357 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3368 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3368 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3368 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3379 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3379 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3379 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3387 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3388 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3389 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3400 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3400 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3401 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3412 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3412 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3413 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3425 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3425 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3426 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3438 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3438 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3439 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3448 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3448 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3449 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3457 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3458 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3458 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3468 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3468 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3469 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3477 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3477 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3478 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3486 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3486 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3487 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3497 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3497 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3497 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3507 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3507 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3507 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3516 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3516 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3517 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3529 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3529 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3530 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3539 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3539 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3539 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3548 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3549 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3549 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3561 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3561 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3562 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3573 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3574 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3574 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3584 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3584 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3584 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ location:3586 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:04:01 [ controller:3597 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3598 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3598 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3610 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3610 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3611 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3624 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3624 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3624 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3635 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3635 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3636 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3644 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3644 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3644 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ location:3650 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:01 [ location:3650 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:01 [ location:3650 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ location:3650 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ location:3650 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ controller:3652 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3652 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3652 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3660 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3661 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3661 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3670 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3670 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3670 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3679 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3679 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3680 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3687 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3688 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3688 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3697 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3697 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3697 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3704 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3705 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3706 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3714 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3715 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3715 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3724 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3725 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3725 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3735 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3735 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3736 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3747 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3747 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3747 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3760 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3760 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3760 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3771 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3771 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3771 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3784 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3784 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3785 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3795 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3795 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3796 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3808 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3808 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3808 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3827 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3827 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3828 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3846 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3846 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3847 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3856 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3856 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3857 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3864 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3864 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3864 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3873 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3873 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3873 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3881 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3881 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3882 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3889 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3889 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3890 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3899 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3899 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3899 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3909 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3909 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3909 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3918 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3918 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3919 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3927 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3927 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3928 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3938 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3938 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3938 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3951 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3951 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:04:01 [ controller:3951 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:04:01 [ controller:3962 ] - [ INFO ] 发送成功 ---
2019-12-18 16:04:01 [ controller:3962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:04:01 [ controller:3962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ controller:3962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ controller:3962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ controller:3966 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:04:01 [ controller:3966 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:04:01 [ controller:3966 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:04:01 [ kafka-coordinator-heartbeat-thread | serviceSys:4024 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:04:01 [ controller:4028 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:04:01 [ kafka-coordinator-heartbeat-thread | serviceSys:4030 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:04:01 [ location:4035 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:04:01 [ location:4035 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:01 [ location:4039 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:04:01 [ location:4039 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:04:01 [ location:4040 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:01 [ location:4156 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:01 [ location:4156 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:01 [ location:4157 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ location:4157 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:01 [ location:4157 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ controller:4467 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ controller:4467 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ controller:4467 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ controller:4468 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ controller:4468 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ location:4591 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:04:02 [ location:4663 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ location:4663 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ location:4664 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ location:4664 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ location:4664 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ controller:4967 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:04:02 [ controller:4967 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:04:02 [ controller:4971 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:04:02 [ controller:4971 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:04:02 [ controller:4971 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:04:02 [ controller:4972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ controller:4973 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ controller:4973 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ controller:4973 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ controller:4973 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ location:5040 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:02 [ location:5045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:04:02 [ location:5045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:04:02 [ location:5045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:02 [ location:5168 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ location:5168 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:02 [ location:5169 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ location:5169 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:02 [ location:5169 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ controller:5479 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ controller:5479 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ controller:5480 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ controller:5480 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ controller:5480 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ location:5597 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:04:03 [ location:5679 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ location:5679 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ location:5680 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ location:5680 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ location:5680 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ controller:5969 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:04:03 [ controller:5969 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:04:03 [ controller:5974 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:04:03 [ controller:5974 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:04:03 [ controller:5974 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:04:03 [ controller:5985 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ controller:5985 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ controller:5986 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ controller:5986 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ controller:5986 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ location:6043 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:03 [ location:6047 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:04:03 [ location:6047 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:04:03 [ location:6047 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:04:03 [ kafka-coordinator-heartbeat-thread | serviceSys:6185 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ kafka-coordinator-heartbeat-thread | serviceSys:6185 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:03 [ location:6185 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ location:6185 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:03 [ location:6185 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:04 [ kafka-coordinator-heartbeat-thread | serviceSys:6490 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:04 [ kafka-coordinator-heartbeat-thread | serviceSys:6491 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:04:04 [ controller:6491 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:04 [ controller:6491 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:04:04 [ controller:6491 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:36 [ controller:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-12-18 16:09:36 [ location:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 16:09:36 [ controller:4 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:09:36 [ location:4 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:09:37 [ location:159 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:09:37 [ controller:160 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:09:37 [ location:187 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:09:37 [ controller:192 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:09:37 [ location:231 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:09:37 [ controller:235 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:09:37 [ location:245 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:09:37 [ location:246 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:09:37 [ location:246 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:09:37 [ controller:247 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:09:37 [ location:248 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:09:37 [ location:251 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:09:37 [ location:254 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:09:37 [ controller:255 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:09:37 [ controller:256 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:09:37 [ location:256 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:09:37 [ controller:256 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:09:37 [ controller:257 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:09:37 [ controller:259 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:09:37 [ location:260 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:09:37 [ controller:261 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:09:37 [ controller:268 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:09:37 [ location:326 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:09:37 [ controller:326 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:09:37 [ location:327 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:09:37 [ location:328 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:09:37 [ location:332 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:09:37 [ location:341 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:09:37 [ location:342 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:09:37 [ location:343 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:09:37 [ location:344 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:09:37 [ controller:345 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:09:37 [ controller:349 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:09:37 [ controller:350 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:09:37 [ controller:352 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:09:37 [ controller:353 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:09:37 [ controller:354 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:09:37 [ location:354 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:09:37 [ location:355 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:09:37 [ controller:355 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:09:37 [ location:358 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:09:37 [ controller:358 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:09:37 [ controller:358 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:09:37 [ controller:359 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:09:37 [ controller:359 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): command
2019-12-18 16:09:37 [ controller:360 ] - [ INFO ] 开始接收数据。
2019-12-18 16:09:37 [ location:359 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 16:09:37 [ location:361 ] - [ INFO ] 开始接收数据。
2019-12-18 16:09:37 [ controller:375 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 16:09:37 [ location:376 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 16:09:37 [ controller:417 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:09:37 [ location:417 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:09:37 [ location:430 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:09:37 [ controller:431 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:09:37 [ location:432 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:09:37 [ controller:433 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:09:37 [ location:436 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:09:37 [ location:437 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:09:37 [ controller:436 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:09:37 [ location:438 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:09:37 [ controller:438 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:09:37 [ location:439 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:09:37 [ controller:440 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:09:37 [ controller:440 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:09:37 [ location:441 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:09:37 [ controller:441 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:09:37 [ location:441 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:09:37 [ location:442 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:09:37 [ location:444 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:09:37 [ location:445 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:09:37 [ controller:446 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:09:37 [ location:447 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:09:37 [ controller:449 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:09:37 [ location:451 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:09:37 [ controller:451 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:09:37 [ location:451 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:09:37 [ controller:452 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:09:37 [ location:453 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:09:37 [ location:453 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:09:37 [ location:454 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:09:37 [ location:454 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:09:37 [ location:454 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:09:37 [ location:455 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:09:37 [ controller:456 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:09:37 [ controller:457 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:09:37 [ location:458 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:09:37 [ controller:458 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:09:37 [ controller:458 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:09:37 [ controller:459 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:09:37 [ controller:459 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:09:37 [ controller:460 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:09:37 [ controller:461 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:09:37 [ controller:462 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:09:37 [ controller:463 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:09:37 [ kafka-producer-network-thread | producer-2:463 ] - [ DEBUG ] [Producer clientId=producer-2] Starting Kafka producer I/O thread.
2019-12-18 16:09:37 [ location:463 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:09:37 [ location:464 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:09:37 [ kafka-producer-network-thread | producer-1:464 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 16:09:37 [ location:465 ] - [ DEBUG ] [Producer clientId=producer-2] Kafka producer started
2019-12-18 16:09:37 [ location:465 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:37 [ controller:467 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:09:37 [ controller:467 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:09:37 [ controller:468 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 16:09:37 [ controller:468 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:37 [ location:711 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:37 [ controller:711 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:37 [ controller:837 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:09:37 [ location:837 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:09:37 [ controller:840 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:09:37 [ location:840 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:09:37 [ controller:841 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:09:37 [ location:843 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:09:37 [ location:849 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:09:37 [ location:850 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:09:37 [ location:850 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:09:37 [ controller:852 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:09:37 [ controller:852 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:09:37 [ controller:853 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:09:37 [ location:873 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:37 [ controller:874 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:37 [ controller:875 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:37 [ location:875 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:37 [ location:883 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:09:37 [ controller:883 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:09:37 [ location:885 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656577852, latencyMs=180, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:09:37 [ controller:885 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656577853, latencyMs=181, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:09:37 [ location:885 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:37 [ location:885 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:37 [ controller:885 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:37 [ controller:886 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:37 [ kafka-coordinator-heartbeat-thread | serviceSys:888 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:09:37 [ kafka-coordinator-heartbeat-thread | serviceSys:888 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:09:37 [ controller:888 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:09:37 [ controller:889 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:09:37 [ location:888 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:09:37 [ controller:889 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:09:37 [ location:889 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:09:37 [ controller:889 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 16:09:37 [ location:889 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:09:37 [ location:889 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] (Re-)joining group
2019-12-18 16:09:37 [ controller:891 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@2aff2034)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:37 [ location:892 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@3c944fc7)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:37 [ controller:893 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:09:37 [ location:893 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:09:37 [ location:894 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:09:37 [ location:894 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:09:37 [ location:895 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:09:37 [ location:895 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:09:37 [ location:895 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:09:37 [ controller:896 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:09:37 [ controller:897 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:09:37 [ controller:898 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:09:37 [ controller:898 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:09:37 [ controller:898 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:09:37 [ location:900 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:37 [ controller:901 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:37 [ location:907 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@18de04f1
2019-12-18 16:09:37 [ location:908 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562=Subscription(topics=[msg0200])}
2019-12-18 16:09:37 [ location:910 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Finished assignment for group: {consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562=Assignment(partitions=[msg0200-0, msg0200-1])}
2019-12-18 16:09:37 [ location:911 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=18, memberId=consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562, groupAssignment=consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562)
2019-12-18 16:09:37 [ location:914 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] SyncGroup failed due to group rebalance
2019-12-18 16:09:37 [ location:915 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:09:37 [ location:915 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] (Re-)joining group
2019-12-18 16:09:37 [ location:915 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@3fcbc4c)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:37 [ controller:918 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@1c47cc9
2019-12-18 16:09:37 [ controller:919 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending follower SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=19, memberId=consumer-1-772b5bd1-7a7b-433a-a0f0-bf6d0dd6570f, groupAssignment=)
2019-12-18 16:09:37 [ location:920 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@41eb4eac
2019-12-18 16:09:37 [ location:920 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: 1 rack: null) for sending metadata request
2019-12-18 16:09:37 [ location:920 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ location:921 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:09:37 [ location:922 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:09:37 [ location:923 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:09:37 [ location:924 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:09:37 [ location:924 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:09:37 [ location:924 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:09:37 [ location:928 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:37 [ location:929 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200,command) to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ location:932 ] - [ DEBUG ] Updated cluster metadata version 3 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:09:37 [ location:932 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562=Subscription(topics=[msg0200]), consumer-1-772b5bd1-7a7b-433a-a0f0-bf6d0dd6570f=Subscription(topics=[command])}
2019-12-18 16:09:37 [ location:932 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Finished assignment for group: {consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562=Assignment(partitions=[msg0200-0, msg0200-1]), consumer-1-772b5bd1-7a7b-433a-a0f0-bf6d0dd6570f=Assignment(partitions=[command-0, command-1])}
2019-12-18 16:09:37 [ location:933 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=19, memberId=consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562, groupAssignment=consumer-2-f86475e5-24fa-4a7c-b256-6d5f3ca69562,consumer-1-772b5bd1-7a7b-433a-a0f0-bf6d0dd6570f)
2019-12-18 16:09:37 [ controller:936 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 19
2019-12-18 16:09:37 [ controller:937 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:09:37 [ controller:938 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [command-0, command-1]
2019-12-18 16:09:37 [ controller:940 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [command-0, command-1]
2019-12-18 16:09:37 [ location:940 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Successfully joined group with generation 19
2019-12-18 16:09:37 [ location:941 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:09:37 [ location:941 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 16:09:37 [ location:941 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 16:09:37 [ controller:945 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition command-0 to the committed offset 75
2019-12-18 16:09:37 [ controller:945 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition command-1 to the committed offset 75
2019-12-18 16:09:37 [ controller:946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ controller:946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ controller:947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 616
2019-12-18 16:09:37 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 608
2019-12-18 16:09:37 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ controller:948 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:37 [ controller:950 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:09:37 [ controller:951 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:09:37 [ controller:952 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:09:37 [ controller:952 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:09:37 [ controller:952 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:09:37 [ controller:953 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:09:37 [ controller:955 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:38 [ location:1463 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ location:1464 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ kafka-coordinator-heartbeat-thread | serviceSys:1464 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ kafka-coordinator-heartbeat-thread | serviceSys:1464 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ location:1469 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 16:09:38 [ controller:1469 ] - [ DEBUG ] Added sensor with name command-0.records-lag
2019-12-18 16:09:38 [ controller:1471 ] - [ DEBUG ] Added sensor with name topic.command.bytes-fetched
2019-12-18 16:09:38 [ controller:1471 ] - [ DEBUG ] Added sensor with name topic.command.records-fetched
2019-12-18 16:09:38 [ controller:1472 ] - [ DEBUG ] Added sensor with name command-1.records-lag
2019-12-18 16:09:38 [ controller:1473 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:38 [ controller:1474 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ controller:1474 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ controller:1474 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ location:1474 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 16:09:38 [ location:1475 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 16:09:38 [ location:1476 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 16:09:38 [ location:1477 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:38 [ location:1478 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ location:1479 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ location:1479 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ controller:1942 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:38 [ location:1945 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:38 [ controller:1952 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:09:38 [ controller:1952 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:09:38 [ controller:1955 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:38 [ location:1957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:09:38 [ location:1957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:09:38 [ location:1957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:38 [ controller:1979 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ controller:1980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ controller:1980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ controller:1980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ controller:1980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ location:1984 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ location:1984 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:38 [ location:1985 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ location:1985 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:38 [ location:1985 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ controller:2476 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:39 [ location:2483 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:39 [ controller:2484 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ controller:2484 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ controller:2485 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ controller:2485 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ controller:2485 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ location:2490 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ location:2490 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ location:2490 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ location:2490 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ location:2491 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ controller:2946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:39 [ location:2946 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:39 [ location:2956 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:09:39 [ location:2957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:09:39 [ location:2957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:39 [ controller:2958 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:09:39 [ controller:2958 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:09:39 [ controller:2958 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:39 [ controller:2989 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ controller:2990 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ controller:2990 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ controller:2990 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ controller:2990 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ location:2994 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ location:2994 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:39 [ location:2994 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ location:2994 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:39 [ location:2994 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ controller:3477 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:40 [ location:3488 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:40 [ controller:3495 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ controller:3495 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ controller:3496 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ controller:3496 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ controller:3496 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ location:3499 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ location:3500 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ location:3500 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ location:3500 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ location:3500 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ kafka-coordinator-heartbeat-thread | serviceSys:3941 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:40 [ kafka-coordinator-heartbeat-thread | serviceSys:3946 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:40 [ location:3947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:40 [ controller:3949 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:09:40 [ controller:3949 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:40 [ location:3954 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:09:40 [ controller:3957 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:09:40 [ controller:3957 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:09:40 [ controller:3957 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:40 [ location:3962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:09:40 [ location:3962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:09:40 [ location:3962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:40 [ controller:4002 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ controller:4002 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ controller:4003 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ controller:4003 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ controller:4003 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ location:4008 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ location:4008 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:40 [ location:4010 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ location:4010 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:40 [ location:4010 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ controller:4480 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:41 [ location:4494 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:41 [ controller:4512 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ controller:4512 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ controller:4512 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ controller:4513 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ controller:4513 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ location:4515 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ location:4515 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ location:4515 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ location:4515 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ location:4516 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ controller:4951 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:41 [ location:4951 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:41 [ controller:4960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:09:41 [ location:4960 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:09:41 [ location:4960 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:09:41 [ location:4962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:41 [ controller:4960 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:09:41 [ controller:4963 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:41 [ controller:5017 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ controller:5017 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ controller:5017 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ controller:5018 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ controller:5018 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ location:5021 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ location:5021 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:41 [ location:5021 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ location:5021 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:41 [ location:5022 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:42 [ controller:5484 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:42 [ location:5500 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:42 [ controller:5524 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:42 [ controller:5524 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:42 [ controller:5526 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:42 [ controller:5526 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:42 [ controller:5526 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:42 [ location:5529 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:42 [ location:5530 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:42 [ location:5530 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:42 [ location:5531 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:42 [ location:5531 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:42 [ location:5955 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:42 [ controller:5955 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:42 [ location:5963 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:09:42 [ location:5963 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:09:42 [ location:5963 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:42 [ controller:5964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:09:42 [ controller:5964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:09:42 [ controller:5964 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:43 [ controller:6033 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ controller:6033 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ controller:6034 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ controller:6034 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ controller:6034 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ location:6039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ location:6039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ location:6040 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ location:6040 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ location:6040 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ controller:6489 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:43 [ location:6505 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:09:43 [ controller:6542 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ controller:6542 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ controller:6542 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ controller:6543 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ controller:6543 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ location:6545 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ location:6545 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:43 [ location:6546 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ location:6546 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ location:6546 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:43 [ kafka-coordinator-heartbeat-thread | serviceSys:6946 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:43 [ controller:6950 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:09:43 [ kafka-coordinator-heartbeat-thread | serviceSys:6950 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:43 [ controller:6956 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:43 [ location:6956 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:43 [ location:6962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:09:43 [ controller:6968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-0
2019-12-18 16:09:43 [ controller:6968 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 75 for partition command-1
2019-12-18 16:09:43 [ controller:6969 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=75, metadata=''}, command-1=OffsetAndMetadata{offset=75, metadata=''}}
2019-12-18 16:09:43 [ location:6972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 616 for partition msg0200-0
2019-12-18 16:09:43 [ location:6972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 608 for partition msg0200-1
2019-12-18 16:09:43 [ location:6972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=616, metadata=''}, msg0200-1=OffsetAndMetadata{offset=608, metadata=''}}
2019-12-18 16:09:44 [ controller:7049 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:44 [ controller:7049 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=75, lastStableOffset = 75, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:44 [ controller:7049 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:44 [ controller:7049 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:44 [ controller:7050 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:44 [ location:7056 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=608, lastStableOffset = 608, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:44 [ location:7056 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=616, lastStableOffset = 616, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:44 [ location:7057 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:44 [ location:7057 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:44 [ location:7057 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:48 [ main:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4123
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 16:09:48 [ main:2 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initializing the Kafka consumer
2019-12-18 16:09:49 [ main:131 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:09:49 [ main:167 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:09:49 [ main:191 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:09:49 [ main:194 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:09:49 [ main:195 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:09:49 [ main:195 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:09:49 [ main:196 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:09:49 [ main:199 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:09:49 [ main:201 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:09:49 [ main:202 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:09:49 [ main:203 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:09:49 [ main:278 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:09:49 [ main:279 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:09:49 [ main:280 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:09:49 [ main:285 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:09:49 [ main:306 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:09:49 [ main:307 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:09:49 [ main:308 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:09:49 [ main:309 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:09:49 [ main:314 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:09:49 [ main:314 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:09:49 [ main:318 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Kafka consumer initialized
2019-12-18 16:09:49 [ main:319 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Subscribed to topic(s): haha
2019-12-18 16:09:49 [ main:319 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:49 [ main:508 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:49 [ main:644 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:09:49 [ main:645 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:09:49 [ main:648 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:09:49 [ main:655 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:09:49 [ main:656 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed connection to node -1. Fetching API versions.
2019-12-18 16:09:49 [ main:656 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating API versions fetch from node -1.
2019-12-18 16:09:49 [ main:676 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:49 [ main:677 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending metadata request (type=MetadataRequest, topics=haha) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:09:49 [ main:684 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = haha, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:09:49 [ main:687 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656589573, latencyMs=182, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:09:49 [ main:687 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:49 [ main:687 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:49 [ kafka-coordinator-heartbeat-thread | 4123:691 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Heartbeat thread started
2019-12-18 16:09:49 [ main:691 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending synchronous auto-commit of offsets {}
2019-12-18 16:09:49 [ main:691 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Revoking previously assigned partitions []
2019-12-18 16:09:49 [ main:692 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Disabling heartbeat thread
2019-12-18 16:09:49 [ main:692 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] (Re-)joining group
2019-12-18 16:09:49 [ main:694 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending JoinGroup ((type: JoinGroupRequest, groupId=4123, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@143640d5)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:49 [ main:696 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:09:49 [ main:696 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:09:49 [ main:697 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:09:49 [ main:697 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:09:49 [ main:698 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:09:49 [ main:698 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating API versions fetch from node 2147483646.
2019-12-18 16:09:49 [ main:701 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:49 [ main:706 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@2aa5fe93
2019-12-18 16:09:49 [ main:707 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Performing assignment using strategy range with subscriptions {consumer-1-dbc373c1-abe6-43a2-9b2f-03a0d15d857b=Subscription(topics=[haha])}
2019-12-18 16:09:49 [ main:708 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Finished assignment for group: {consumer-1-dbc373c1-abe6-43a2-9b2f-03a0d15d857b=Assignment(partitions=[haha-0])}
2019-12-18 16:09:49 [ main:710 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=4123, generationId=146, memberId=consumer-1-dbc373c1-abe6-43a2-9b2f-03a0d15d857b, groupAssignment=consumer-1-dbc373c1-abe6-43a2-9b2f-03a0d15d857b)
2019-12-18 16:09:49 [ main:716 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Successfully joined group with generation 146
2019-12-18 16:09:49 [ main:717 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Enabling heartbeat thread
2019-12-18 16:09:49 [ main:718 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=4123] Setting newly assigned partitions [haha-0]
2019-12-18 16:09:49 [ main:719 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetching committed offsets for partitions: [haha-0]
2019-12-18 16:09:49 [ main:723 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Resetting offset for partition haha-0 to the committed offset 103
2019-12-18 16:09:49 [ main:724 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:49 [ main:725 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:49 [ main:727 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:49 [ main:728 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:09:49 [ main:729 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:09:49 [ main:732 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:09:49 [ main:733 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:09:49 [ main:733 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed connection to node 1. Fetching API versions.
2019-12-18 16:09:49 [ main:733 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Initiating API versions fetch from node 1.
2019-12-18 16:09:49 [ main:736 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:09:50 [ main:1250 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:50 [ main:1257 ] - [ DEBUG ] Added sensor with name topic.haha.bytes-fetched
2019-12-18 16:09:50 [ main:1258 ] - [ DEBUG ] Added sensor with name topic.haha.records-fetched
2019-12-18 16:09:50 [ main:1259 ] - [ DEBUG ] Added sensor with name haha-0.records-lag
2019-12-18 16:09:50 [ main:1260 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:50 [ main:1260 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:50 [ main:1720 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:50 [ main:1727 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:50 [ main:1728 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:50 [ main:1764 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:50 [ main:1765 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:50 [ main:1765 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:51 [ main:2268 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:51 [ main:2268 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:51 [ main:2269 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:51 [ main:2726 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:51 [ main:2732 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:51 [ main:2732 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:51 [ main:2772 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:51 [ main:2773 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:51 [ main:2774 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:52 [ main:3279 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:52 [ main:3279 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:52 [ main:3279 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:52 [ kafka-coordinator-heartbeat-thread | 4123:3722 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:52 [ main:3725 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:52 [ main:3730 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Received successful Heartbeat response
2019-12-18 16:09:52 [ main:3734 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:52 [ main:3734 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:52 [ main:3785 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:52 [ main:3785 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:52 [ main:3786 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:53 [ main:4292 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:53 [ main:4292 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:53 [ main:4293 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:53 [ main:4730 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:53 [ main:4737 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:53 [ main:4738 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:53 [ main:4798 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:53 [ main:4799 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:53 [ main:4800 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:54 [ main:5305 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:54 [ main:5306 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:54 [ main:5306 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:54 [ main:5735 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:54 [ main:5739 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:54 [ main:5740 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:54 [ main:5810 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:54 [ main:5810 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:54 [ main:5810 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:55 [ main:6316 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:55 [ main:6317 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:55 [ main:6317 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:55 [ kafka-coordinator-heartbeat-thread | 4123:6726 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:09:55 [ main:6729 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Received successful Heartbeat response
2019-12-18 16:09:55 [ main:6736 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:55 [ main:6739 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:55 [ main:6739 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:55 [ main:6824 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:55 [ main:6824 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:55 [ main:6825 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:56 [ main:7330 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:56 [ main:7330 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:56 [ main:7331 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:56 [ main:7740 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:56 [ main:7746 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:56 [ main:7746 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:56 [ main:7835 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:56 [ main:7835 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:56 [ main:7835 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:57 [ main:8340 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:57 [ main:8340 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:57 [ main:8341 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:57 [ main:8746 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:57 [ main:8752 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Committed offset 103 for partition haha-0
2019-12-18 16:09:57 [ main:8752 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Completed asynchronous auto-commit of offsets {haha-0=OffsetAndMetadata{offset=103, metadata=''}}
2019-12-18 16:09:57 [ main:8845 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:57 [ main:8846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:57 [ main:8846 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:58 [ kafka-coordinator-heartbeat-thread | 4123:9353 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Fetch READ_UNCOMMITTED at offset 103 for partition haha-0 returned fetch data (error=NONE, highWaterMark=103, lastStableOffset = 103, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:09:58 [ main:9354 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Added READ_UNCOMMITTED fetch request for partition haha-0 at offset 103 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:09:58 [ main:9354 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=4123] Sending READ_UNCOMMITTED fetch for partitions [haha-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:07 [ main:1 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 16:10:07 [ main:168 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:10:07 [ main:184 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:10:07 [ main:191 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:10:07 [ main:203 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:10:07 [ main:230 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:10:07 [ main:233 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:10:07 [ main:239 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:10:07 [ main:244 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:10:07 [ main:248 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:10:07 [ main:249 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:10:07 [ main:256 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:10:07 [ main:257 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:10:07 [ main:261 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:10:07 [ main:269 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:10:07 [ main:270 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:10:07 [ main:271 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:10:07 [ main:271 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:10:07 [ main:275 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:10:07 [ main:277 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:10:07 [ main:277 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:10:07 [ main:278 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:10:07 [ main:279 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:281 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 16:10:07 [ main:284 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:10:07 [ main:285 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:10:07 [ main:294 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 16:10:07 [ main:295 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:307 ] - [ DEBUG ] [Producer clientId=producer-1] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:308 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:447 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:448 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:449 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:457 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:615 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:615 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:639 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:639 ] - [ DEBUG ] [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:646 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:664 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:665 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:666 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:666 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:667 ] - [ DEBUG ] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:667 ] - [ DEBUG ] [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:667 ] - [ DEBUG ] [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:678 ] - [ DEBUG ] [Producer clientId=producer-1] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:682 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-per-batch
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:683 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:683 ] - [ DEBUG ] Added sensor with name topic.msg0200.compression-rate
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:684 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-retries
2019-12-18 16:10:07 [ kafka-producer-network-thread | producer-1:684 ] - [ DEBUG ] Added sensor with name topic.msg0200.record-errors
2019-12-18 16:10:07 [ main:695 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:705 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:714 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:725 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:734 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:744 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:753 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:765 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:778 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:786 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:07 [ main:796 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:806 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:815 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:824 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:834 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:843 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:851 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:858 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:871 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:886 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:904 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:921 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:942 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:966 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:979 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:993 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1006 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1027 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1037 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1047 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1056 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1066 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1074 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1084 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1094 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1111 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1131 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1142 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1155 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1171 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1183 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1196 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1209 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1223 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1233 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1243 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1253 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1261 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1272 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1281 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1290 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1299 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1311 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1324 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1337 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1359 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1376 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1397 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1410 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1431 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1442 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1452 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1462 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1472 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1482 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1491 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1500 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1508 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1516 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1533 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1548 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1563 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1576 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1588 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1598 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1611 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1626 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1667 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1686 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1696 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1708 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1718 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1726 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1740 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1754 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1771 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1782 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:08 [ main:1793 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1805 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1815 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1830 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1842 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1856 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1867 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1876 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1885 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1893 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1902 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1910 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1919 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1928 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1936 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1945 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1964 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1978 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1990 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:1999 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2011 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2027 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2040 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2051 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2062 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2070 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2078 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2086 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2094 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2104 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2112 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2121 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2134 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2144 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2166 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2180 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2194 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2207 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2229 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2243 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2257 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2267 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2276 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2289 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2298 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2306 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2314 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2327 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2344 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2371 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2383 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2404 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2417 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2430 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2444 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2460 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2473 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2484 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2495 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2504 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2525 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2535 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2544 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:09 [ main:2545 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 16:10:09 [ main:2546 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:10:09 [ main:2547 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:10:09 [ main:2547 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:10:09 [ main:2548 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:10:09 [ main:2548 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:10:09 [ main:2549 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:10:09 [ main:2549 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:10:09 [ main:2550 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:10:09 [ main:2550 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:10:09 [ main:2551 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:10:09 [ main:2552 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:10:09 [ main:2553 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:10:09 [ main:2554 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:10:09 [ main:2554 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:10:09 [ main:2555 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:10:09 [ main:2555 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:10:09 [ main:2556 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:10:09 [ main:2556 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:10:09 [ main:2557 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:10:09 [ main:2557 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:10:09 [ main:2557 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:10:09 [ main:2558 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:10:09 [ main:2558 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2558 ] - [ DEBUG ] [Producer clientId=producer-2] Starting Kafka producer I/O thread.
2019-12-18 16:10:09 [ main:2558 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:10:09 [ main:2559 ] - [ DEBUG ] [Producer clientId=producer-2] Kafka producer started
2019-12-18 16:10:09 [ main:2559 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2560 ] - [ DEBUG ] [Producer clientId=producer-2] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2560 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2560 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2561 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2562 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2563 ] - [ DEBUG ] [Producer clientId=producer-2] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2563 ] - [ DEBUG ] [Producer clientId=producer-2] Completed connection to node -1. Fetching API versions.
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2563 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating API versions fetch from node -1.
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2565 ] - [ DEBUG ] [Producer clientId=producer-2] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2566 ] - [ DEBUG ] [Producer clientId=producer-2] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2568 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2575 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2575 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2577 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2578 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2579 ] - [ DEBUG ] [Producer clientId=producer-2] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2579 ] - [ DEBUG ] [Producer clientId=producer-2] Completed connection to node 1. Fetching API versions.
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2580 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating API versions fetch from node 1.
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2584 ] - [ DEBUG ] [Producer clientId=producer-2] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2584 ] - [ DEBUG ] Added sensor with name topic.command.records-per-batch
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2584 ] - [ DEBUG ] Added sensor with name topic.command.bytes
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2585 ] - [ DEBUG ] Added sensor with name topic.command.compression-rate
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2585 ] - [ DEBUG ] Added sensor with name topic.command.record-retries
2019-12-18 16:10:09 [ kafka-producer-network-thread | producer-2:2586 ] - [ DEBUG ] Added sensor with name topic.command.record-errors
2019-12-18 16:10:09 [ main:2593 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2605 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2615 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2627 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2638 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2654 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2665 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2679 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2689 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2697 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2705 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2714 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2722 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2732 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2741 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2749 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2757 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2765 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2774 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2783 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:09 [ main:2792 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2802 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2809 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2817 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2825 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2833 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2843 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2854 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2862 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2872 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2881 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2893 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2905 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2913 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2923 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2931 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2941 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2953 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2961 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2970 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2978 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2986 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:2995 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3003 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3013 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3026 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3039 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3049 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3061 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3076 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3087 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3097 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3109 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3119 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3129 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3138 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3146 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3156 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3168 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3177 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3188 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3197 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3210 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3219 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3228 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3243 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3254 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3270 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3281 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3290 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3301 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3313 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3325 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3335 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3343 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3352 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3359 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3370 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3378 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3389 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3397 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3406 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3414 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3422 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3430 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3438 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3454 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3470 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3480 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3504 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3514 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3526 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3534 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3544 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3554 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3563 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3573 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3582 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3590 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3598 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3605 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3614 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3622 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3639 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3649 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3663 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3677 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3687 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3697 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3709 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3720 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3730 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3738 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3745 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3753 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3760 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3768 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3776 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3785 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:10 [ main:3793 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3802 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3811 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3818 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3825 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3834 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3842 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3851 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3863 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3877 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3888 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3898 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3908 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3917 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3925 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3939 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3950 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3958 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3966 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3976 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3983 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3991 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:3999 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4008 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4016 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4024 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4032 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4040 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4053 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4063 ] - [ INFO ] 开始发送数据 ---
2019-12-18 16:10:11 [ main:4072 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:15 [ location:0 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-12-18 16:10:15 [ controller:1 ] - [ INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [10.211.55.3:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = serviceSys
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 12000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-12-18 16:10:15 [ location:4 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:10:15 [ controller:5 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initializing the Kafka consumer
2019-12-18 16:10:15 [ controller:195 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:10:15 [ location:196 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:10:15 [ controller:243 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:10:15 [ location:243 ] - [ DEBUG ] Added sensor with name fetch-throttle-time
2019-12-18 16:10:16 [ location:327 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:10:16 [ controller:327 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:10:16 [ location:334 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:10:16 [ controller:335 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:10:16 [ controller:340 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:10:16 [ location:340 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:10:16 [ controller:340 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:10:16 [ controller:341 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:10:16 [ location:342 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:10:16 [ location:342 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:10:16 [ location:343 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:10:16 [ controller:344 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:10:16 [ controller:346 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:10:16 [ location:353 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:10:16 [ controller:354 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:10:16 [ location:354 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:10:16 [ controller:356 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:10:16 [ location:358 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:10:16 [ location:390 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:10:16 [ location:391 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:10:16 [ location:392 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:10:16 [ controller:392 ] - [ DEBUG ] Added sensor with name heartbeat-latency
2019-12-18 16:10:16 [ controller:394 ] - [ DEBUG ] Added sensor with name join-latency
2019-12-18 16:10:16 [ controller:396 ] - [ DEBUG ] Added sensor with name sync-latency
2019-12-18 16:10:16 [ location:400 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:10:16 [ controller:401 ] - [ DEBUG ] Added sensor with name commit-latency
2019-12-18 16:10:16 [ location:406 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:10:16 [ controller:406 ] - [ DEBUG ] Added sensor with name bytes-fetched
2019-12-18 16:10:16 [ controller:407 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:10:16 [ controller:408 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:10:16 [ controller:409 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:10:16 [ location:410 ] - [ DEBUG ] Added sensor with name records-fetched
2019-12-18 16:10:16 [ location:410 ] - [ DEBUG ] Added sensor with name fetch-latency
2019-12-18 16:10:16 [ location:411 ] - [ DEBUG ] Added sensor with name records-lag
2019-12-18 16:10:16 [ controller:419 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:10:16 [ controller:419 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:10:16 [ controller:425 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:10:16 [ location:425 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:10:16 [ location:426 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:10:16 [ controller:426 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Subscribed to topic(s): command
2019-12-18 16:10:16 [ controller:426 ] - [ INFO ] 开始接收数据。
2019-12-18 16:10:16 [ location:426 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Kafka consumer initialized
2019-12-18 16:10:16 [ location:426 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Subscribed to topic(s): msg0200
2019-12-18 16:10:16 [ location:427 ] - [ INFO ] 开始接收数据。
2019-12-18 16:10:16 [ location:452 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-12-18 16:10:16 [ controller:454 ] - [ INFO ] ProducerConfig values: 
	acks = -1
	batch.size = 262144
	bootstrap.servers = [10.211.55.3:9092]
	buffer.memory = 67108864
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-12-18 16:10:16 [ location:483 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:10:16 [ controller:483 ] - [ DEBUG ] Added sensor with name bufferpool-wait-time
2019-12-18 16:10:16 [ location:494 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:10:16 [ location:495 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:10:16 [ controller:496 ] - [ DEBUG ] Added sensor with name buffer-exhausted-records
2019-12-18 16:10:16 [ controller:497 ] - [ DEBUG ] Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.211.55.3:9092 (id: -1 rack: null)], partitions = [])
2019-12-18 16:10:16 [ location:501 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:10:16 [ location:502 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:10:16 [ location:503 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:10:16 [ location:504 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:10:16 [ controller:504 ] - [ DEBUG ] Added sensor with name produce-throttle-time
2019-12-18 16:10:16 [ location:504 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:10:16 [ controller:504 ] - [ DEBUG ] Added sensor with name connections-closed:
2019-12-18 16:10:16 [ location:505 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:10:16 [ controller:505 ] - [ DEBUG ] Added sensor with name connections-created:
2019-12-18 16:10:16 [ controller:506 ] - [ DEBUG ] Added sensor with name successful-authentication:
2019-12-18 16:10:16 [ controller:506 ] - [ DEBUG ] Added sensor with name failed-authentication:
2019-12-18 16:10:16 [ controller:507 ] - [ DEBUG ] Added sensor with name bytes-sent-received:
2019-12-18 16:10:16 [ location:505 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:10:16 [ location:508 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:10:16 [ location:509 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:10:16 [ location:510 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:10:16 [ controller:507 ] - [ DEBUG ] Added sensor with name bytes-sent:
2019-12-18 16:10:16 [ controller:514 ] - [ DEBUG ] Added sensor with name bytes-received:
2019-12-18 16:10:16 [ location:513 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:10:16 [ controller:515 ] - [ DEBUG ] Added sensor with name select-time:
2019-12-18 16:10:16 [ location:516 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:10:16 [ controller:516 ] - [ DEBUG ] Added sensor with name io-time:
2019-12-18 16:10:16 [ controller:517 ] - [ DEBUG ] Added sensor with name batch-size
2019-12-18 16:10:16 [ controller:518 ] - [ DEBUG ] Added sensor with name compression-rate
2019-12-18 16:10:16 [ location:517 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:10:16 [ controller:518 ] - [ DEBUG ] Added sensor with name queue-time
2019-12-18 16:10:16 [ location:519 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:10:16 [ controller:519 ] - [ DEBUG ] Added sensor with name request-time
2019-12-18 16:10:16 [ controller:519 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:10:16 [ controller:520 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:10:16 [ controller:521 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:10:16 [ location:521 ] - [ DEBUG ] Added sensor with name records-per-request
2019-12-18 16:10:16 [ controller:521 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:10:16 [ location:522 ] - [ DEBUG ] Added sensor with name record-retries
2019-12-18 16:10:16 [ location:523 ] - [ DEBUG ] Added sensor with name errors
2019-12-18 16:10:16 [ location:523 ] - [ DEBUG ] Added sensor with name record-size
2019-12-18 16:10:16 [ controller:523 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:10:16 [ location:524 ] - [ DEBUG ] Added sensor with name batch-split-rate
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-1:527 ] - [ DEBUG ] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2019-12-18 16:10:16 [ location:527 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:10:16 [ location:528 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:529 ] - [ DEBUG ] [Producer clientId=producer-2] Starting Kafka producer I/O thread.
2019-12-18 16:10:16 [ location:529 ] - [ DEBUG ] [Producer clientId=producer-1] Kafka producer started
2019-12-18 16:10:16 [ location:530 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ controller:530 ] - [ INFO ] Kafka version : 1.0.0
2019-12-18 16:10:16 [ controller:531 ] - [ INFO ] Kafka commitId : aaa7af6d4a11b29d
2019-12-18 16:10:16 [ controller:532 ] - [ DEBUG ] [Producer clientId=producer-2] Kafka producer started
2019-12-18 16:10:16 [ controller:532 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending GroupCoordinator request to broker 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ location:762 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ controller:765 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ location:880 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:10:16 [ location:881 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:10:16 [ controller:882 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:10:16 [ location:882 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:10:16 [ controller:883 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:10:16 [ controller:884 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:10:16 [ controller:892 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:10:16 [ controller:893 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:10:16 [ controller:893 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:10:16 [ location:894 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:10:16 [ location:894 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node -1. Fetching API versions.
2019-12-18 16:10:16 [ location:894 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node -1.
2019-12-18 16:10:16 [ controller:913 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ controller:914 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=command) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ location:914 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ location:914 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ location:922 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:10:16 [ controller:922 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:10:16 [ controller:924 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656616650, latencyMs=167, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:10:16 [ controller:924 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:16 [ controller:925 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:16 [ location:926 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received GroupCoordinator response ClientResponse(receivedTimeMs=1576656616653, latencyMs=170, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=10.211.55.3:9092 (id: 1 rack: null)))
2019-12-18 16:10:16 [ location:926 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Discovered coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:16 [ location:926 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:16 [ kafka-coordinator-heartbeat-thread | serviceSys:928 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:10:16 [ controller:928 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:10:16 [ kafka-coordinator-heartbeat-thread | serviceSys:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Heartbeat thread started
2019-12-18 16:10:16 [ location:928 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending synchronous auto-commit of offsets {}
2019-12-18 16:10:16 [ controller:928 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:10:16 [ location:928 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Revoking previously assigned partitions []
2019-12-18 16:10:16 [ controller:929 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:10:16 [ location:929 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Disabling heartbeat thread
2019-12-18 16:10:16 [ location:929 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] (Re-)joining group
2019-12-18 16:10:16 [ controller:929 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] (Re-)joining group
2019-12-18 16:10:16 [ location:931 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@2325b243)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:16 [ controller:931 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending JoinGroup ((type: JoinGroupRequest, groupId=serviceSys, sessionTimeout=12000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@6371f98e)) to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:16 [ location:932 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:10:16 [ controller:932 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-sent
2019-12-18 16:10:16 [ location:935 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:10:16 [ controller:935 ] - [ DEBUG ] Added sensor with name node-2147483646.bytes-received
2019-12-18 16:10:16 [ location:936 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:10:16 [ controller:936 ] - [ DEBUG ] Added sensor with name node-2147483646.latency
2019-12-18 16:10:16 [ controller:936 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:10:16 [ controller:936 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:10:16 [ controller:937 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:10:16 [ location:937 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
2019-12-18 16:10:16 [ location:938 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 2147483646. Fetching API versions.
2019-12-18 16:10:16 [ location:939 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 2147483646.
2019-12-18 16:10:16 [ controller:941 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ location:942 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ location:947 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@3229bf43
2019-12-18 16:10:16 [ controller:947 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@7517f333
2019-12-18 16:10:16 [ location:948 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending follower SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=21, memberId=consumer-1-7edfeb99-ff38-471d-9dac-2c6ecb2dcb49, groupAssignment=)
2019-12-18 16:10:16 [ controller:948 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initialize connection to node 10.211.55.3:9092 (id: 1 rack: null) for sending metadata request
2019-12-18 16:10:16 [ controller:948 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:949 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:10:16 [ controller:950 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:10:16 [ controller:953 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:10:16 [ controller:953 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:10:16 [ controller:954 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:10:16 [ controller:954 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:10:16 [ controller:956 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ controller:957 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending metadata request (type=MetadataRequest, topics=msg0200,command) to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:960 ] - [ DEBUG ] Updated cluster metadata version 3 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = command, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = msg0200, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = command, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:10:16 [ controller:960 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Performing assignment using strategy range with subscriptions {consumer-1-7edfeb99-ff38-471d-9dac-2c6ecb2dcb49=Subscription(topics=[msg0200]), consumer-2-700aabae-d6e5-4fab-ba35-9e663aa47aa1=Subscription(topics=[command])}
2019-12-18 16:10:16 [ controller:961 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Finished assignment for group: {consumer-1-7edfeb99-ff38-471d-9dac-2c6ecb2dcb49=Assignment(partitions=[msg0200-0, msg0200-1]), consumer-2-700aabae-d6e5-4fab-ba35-9e663aa47aa1=Assignment(partitions=[command-0, command-1])}
2019-12-18 16:10:16 [ controller:962 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending leader SyncGroup to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=serviceSys, generationId=21, memberId=consumer-2-700aabae-d6e5-4fab-ba35-9e663aa47aa1, groupAssignment=consumer-1-7edfeb99-ff38-471d-9dac-2c6ecb2dcb49,consumer-2-700aabae-d6e5-4fab-ba35-9e663aa47aa1)
2019-12-18 16:10:16 [ location:968 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Successfully joined group with generation 21
2019-12-18 16:10:16 [ location:970 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:10:16 [ location:971 ] - [ INFO ] [Consumer clientId=consumer-1, groupId=serviceSys] Setting newly assigned partitions [msg0200-0, msg0200-1]
2019-12-18 16:10:16 [ controller:972 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Successfully joined group with generation 21
2019-12-18 16:10:16 [ controller:972 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Enabling heartbeat thread
2019-12-18 16:10:16 [ controller:972 ] - [ INFO ] [Consumer clientId=consumer-2, groupId=serviceSys] Setting newly assigned partitions [command-0, command-1]
2019-12-18 16:10:16 [ controller:973 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetching committed offsets for partitions: [command-0, command-1]
2019-12-18 16:10:16 [ location:973 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetching committed offsets for partitions: [msg0200-0, msg0200-1]
2019-12-18 16:10:16 [ controller:978 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-0 to the committed offset 75
2019-12-18 16:10:16 [ location:978 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-0 to the committed offset 616
2019-12-18 16:10:16 [ controller:978 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Resetting offset for partition command-1 to the committed offset 75
2019-12-18 16:10:16 [ location:978 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Resetting offset for partition msg0200-1 to the committed offset 608
2019-12-18 16:10:16 [ location:979 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 608 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:979 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ location:979 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 616 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ location:980 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:979 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 75 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:981 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ location:981 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ location:982 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:10:16 [ location:989 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:10:16 [ location:990 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:10:16 [ location:991 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:10:16 [ location:991 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed connection to node 1. Fetching API versions.
2019-12-18 16:10:16 [ location:991 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Initiating API versions fetch from node 1.
2019-12-18 16:10:16 [ location:994 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ controller:1003 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-0 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=9375)
2019-12-18 16:10:16 [ location:1003 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 608 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=5250)
2019-12-18 16:10:16 [ location:1003 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 616 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=5250)
2019-12-18 16:10:16 [ controller:1003 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 75 for partition command-1 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=9375)
2019-12-18 16:10:16 [ controller:1029 ] - [ DEBUG ] Added sensor with name command-0.records-lag
2019-12-18 16:10:16 [ location:1034 ] - [ DEBUG ] Added sensor with name msg0200-1.records-lag
2019-12-18 16:10:16 [ controller:1036 ] - [ DEBUG ] Added sensor with name topic.command.bytes-fetched
2019-12-18 16:10:16 [ controller:1037 ] - [ DEBUG ] Added sensor with name topic.command.records-fetched
2019-12-18 16:10:16 [ controller:1037 ] - [ DEBUG ] Added sensor with name command-1.records-lag
2019-12-18 16:10:16 [ controller:1038 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:1038 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:1039 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ controller:1041 ] - [ INFO ] 接收到150条数据。
2019-12-18 16:10:16 [ controller:1043 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:16 [ location:1043 ] - [ DEBUG ] Added sensor with name topic.msg0200.bytes-fetched
2019-12-18 16:10:16 [ location:1043 ] - [ DEBUG ] Added sensor with name topic.msg0200.records-fetched
2019-12-18 16:10:16 [ location:1044 ] - [ DEBUG ] Added sensor with name msg0200-0.records-lag
2019-12-18 16:10:16 [ location:1045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ location:1045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ location:1045 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ location:1046 ] - [ INFO ] 接收到150条数据。
2019-12-18 16:10:16 [ location:1049 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1051 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ controller:1136 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1138 ] - [ DEBUG ] [Producer clientId=producer-2] Initialize connection to node 10.211.55.3:9092 (id: -1 rack: null) for sending metadata request
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1138 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating connection to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1139 ] - [ DEBUG ] Added sensor with name node--1.bytes-sent
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1140 ] - [ DEBUG ] Added sensor with name node--1.bytes-received
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1141 ] - [ DEBUG ] Added sensor with name node--1.latency
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1141 ] - [ DEBUG ] [Producer clientId=producer-2] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -1
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1141 ] - [ DEBUG ] [Producer clientId=producer-2] Completed connection to node -1. Fetching API versions.
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1141 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating API versions fetch from node -1.
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1150 ] - [ DEBUG ] [Producer clientId=producer-2] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1151 ] - [ DEBUG ] [Producer clientId=producer-2] Sending metadata request (type=MetadataRequest, topics=hexMsg) to node 10.211.55.3:9092 (id: -1 rack: null)
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1160 ] - [ DEBUG ] Updated cluster metadata version 2 to Cluster(id = u4oaGaTHTnOvv6pHHZ193w, nodes = [10.211.55.3:9092 (id: 1 rack: null)], partitions = [Partition(topic = hexMsg, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])])
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1181 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating connection to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1182 ] - [ DEBUG ] Added sensor with name node-1.bytes-sent
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1185 ] - [ DEBUG ] Added sensor with name node-1.bytes-received
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1187 ] - [ DEBUG ] Added sensor with name node-1.latency
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1187 ] - [ DEBUG ] [Producer clientId=producer-2] Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1187 ] - [ DEBUG ] [Producer clientId=producer-2] Completed connection to node 1. Fetching API versions.
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1187 ] - [ DEBUG ] [Producer clientId=producer-2] Initiating API versions fetch from node 1.
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1193 ] - [ DEBUG ] [Producer clientId=producer-2] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 5], Fetch(1): 0 to 10 [usable: 6], ListOffsets(2): 0 to 4 [usable: 2], Metadata(3): 0 to 7 [usable: 5], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 3], OffsetFetch(9): 0 to 5 [usable: 3], FindCoordinator(10): 0 to 2 [usable: 1], JoinGroup(11): 0 to 3 [usable: 2], Heartbeat(12): 0 to 2 [usable: 1], LeaveGroup(13): 0 to 2 [usable: 1], SyncGroup(14): 0 to 2 [usable: 1], DescribeGroups(15): 0 to 2 [usable: 1], ListGroups(16): 0 to 2 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 1], CreateTopics(19): 0 to 3 [usable: 2], DeleteTopics(20): 0 to 3 [usable: 1], DeleteRecords(21): 0 to 1 [usable: 0], InitProducerId(22): 0 to 1 [usable: 0], OffsetForLeaderEpoch(23): 0 to 2 [usable: 0], AddPartitionsToTxn(24): 0 to 1 [usable: 0], AddOffsetsToTxn(25): 0 to 1 [usable: 0], EndTxn(26): 0 to 1 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 0], DescribeAcls(29): 0 to 1 [usable: 0], CreateAcls(30): 0 to 1 [usable: 0], DeleteAcls(31): 0 to 1 [usable: 0], DescribeConfigs(32): 0 to 2 [usable: 0], AlterConfigs(33): 0 to 1 [usable: 0], AlterReplicaLogDirs(34): 0 to 1 [usable: 0], DescribeLogDirs(35): 0 to 1 [usable: 0], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 0], UNKNOWN(38): 0 to 1, UNKNOWN(39): 0 to 1, UNKNOWN(40): 0 to 1, UNKNOWN(41): 0 to 1, UNKNOWN(42): 0 to 1)
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1196 ] - [ DEBUG ] Added sensor with name topic.hexMsg.records-per-batch
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1198 ] - [ DEBUG ] Added sensor with name topic.hexMsg.bytes
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1198 ] - [ DEBUG ] Added sensor with name topic.hexMsg.compression-rate
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1198 ] - [ DEBUG ] Added sensor with name topic.hexMsg.record-retries
2019-12-18 16:10:16 [ kafka-producer-network-thread | producer-2:1199 ] - [ DEBUG ] Added sensor with name topic.hexMsg.record-errors
2019-12-18 16:10:16 [ controller:1208 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:16 [ controller:1209 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:16 [ controller:1211 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:16 [ controller:1222 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:16 [ controller:1222 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:16 [ controller:1223 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:16 [ controller:1236 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:16 [ controller:1237 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:16 [ controller:1238 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:16 [ controller:1248 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:16 [ controller:1249 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:16 [ controller:1249 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:16 [ controller:1258 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:16 [ location:1258 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ controller:1258 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:16 [ location:1260 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ controller:1260 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:16 [ location:1261 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1261 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1262 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1262 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1262 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1262 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1262 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1262 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1262 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1262 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1263 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1263 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1263 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1263 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1263 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1263 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1263 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1263 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1264 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1264 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1264 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1264 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1264 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1264 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1265 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1265 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1265 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1267 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1267 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1268 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1268 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1268 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1268 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1268 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1269 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1269 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1269 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1269 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1269 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1270 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1270 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1270 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ location:1270 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1270 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:16 [ location:1270 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:16 [ location:1270 ] - [ INFO ] hex: 0101
2019-12-18 16:10:16 [ controller:1269 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:16 [ controller:1271 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:16 [ controller:1271 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:16 [ location:1271 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:16 [ location:1272 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1273 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1273 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1274 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1274 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1274 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1274 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1274 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1274 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1274 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1275 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1276 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1276 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1277 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1277 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1277 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1277 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1277 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1277 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1278 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1278 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1278 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1278 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1278 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1278 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1279 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1279 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1279 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1279 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1279 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1279 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1279 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1279 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1280 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1280 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1280 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1280 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1280 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1280 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1280 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1280 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1280 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1280 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1281 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1281 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1281 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1281 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1281 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1281 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1281 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1281 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1282 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1282 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1282 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1282 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1282 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1282 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1282 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1282 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1282 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1283 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1283 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1283 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1283 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1283 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1284 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1284 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1284 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1284 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1284 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1284 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1284 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1285 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1285 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1285 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1285 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1285 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1285 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1286 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1286 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1286 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1286 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1286 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1286 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1286 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1287 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1287 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1287 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1287 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1287 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1287 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1287 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1288 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ controller:1285 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1295 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1295 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1296 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1296 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1296 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1296 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1296 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1296 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1296 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1296 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1297 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1297 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1297 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1297 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1297 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1297 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1297 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1297 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1297 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1298 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1298 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1298 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1298 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1298 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1298 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1298 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1298 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1298 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1298 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1298 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1299 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1299 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1299 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1299 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1299 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1299 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1299 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1299 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1300 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1300 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1300 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1300 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1300 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1300 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1300 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1300 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1300 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1300 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1300 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1301 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1301 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1301 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1306 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1306 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1306 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1306 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1306 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1307 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1307 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1307 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1307 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1307 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1307 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1307 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1308 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1308 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1308 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1308 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1308 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1308 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1308 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1309 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ controller:1309 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ location:1309 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ controller:1309 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ location:1309 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1309 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1309 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1310 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1310 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ controller:1310 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1310 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1310 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1310 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1310 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1310 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1312 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1313 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1314 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1314 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1314 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1315 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1315 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1315 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1315 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1315 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1315 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1316 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1316 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1316 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1319 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1320 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1320 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1321 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1321 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1321 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1321 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1321 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1321 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1321 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1321 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1322 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1322 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1322 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1322 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ controller:1322 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ location:1322 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ controller:1322 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ location:1323 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1323 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1323 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1323 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1323 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ controller:1323 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1323 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1324 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1324 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1324 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1324 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1325 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1325 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1325 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1325 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1325 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1325 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1325 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1326 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1326 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1326 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1326 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1326 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1326 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1326 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1326 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1326 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1326 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1326 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1326 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1327 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1327 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1327 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1327 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1327 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1327 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1327 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1327 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1327 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1327 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1328 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1328 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1328 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1328 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1328 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1328 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1328 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1328 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1328 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1329 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1329 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1329 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1329 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1329 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1329 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1329 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1329 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1329 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1330 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1330 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1330 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1330 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1330 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1330 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1330 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1330 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1330 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1330 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1331 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1331 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1331 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1331 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1331 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1331 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1331 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1331 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1331 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1331 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1332 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1332 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1332 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1332 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1332 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1332 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1332 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1332 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1332 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1332 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1333 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1333 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1333 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1333 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1333 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1333 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1333 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1333 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1333 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1333 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1334 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1334 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1334 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1334 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1334 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1334 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1334 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1334 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1334 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1334 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1335 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1335 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1335 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1335 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1335 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1335 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1335 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1335 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ controller:1340 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1340 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1341 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1343 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1343 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1345 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1345 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1345 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1345 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1346 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1346 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1346 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1356 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1356 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1356 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1356 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ controller:1356 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1356 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ location:1356 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1356 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1357 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1357 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1357 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ controller:1357 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1357 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1357 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1357 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1358 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1358 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1358 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1358 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1358 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1358 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1359 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1359 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1359 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1359 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1359 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1361 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1362 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1362 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1362 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1363 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1363 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1363 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1363 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1363 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1363 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1363 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1363 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1363 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1364 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1364 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1365 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1365 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1365 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1365 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1365 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1371 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1371 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1371 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1371 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1371 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1371 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1371 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1371 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1372 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1372 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1372 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1372 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1372 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1372 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1372 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1372 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1372 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1372 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1372 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1373 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1373 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1373 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1373 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1373 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1373 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1373 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1373 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1373 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1374 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1374 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1374 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1374 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1374 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1374 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1375 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1375 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1375 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1375 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1375 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1375 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1375 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ controller:1381 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1396 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1396 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1413 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1414 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1417 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1419 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1422 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1422 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1423 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1423 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1430 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1431 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1431 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1431 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1431 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1431 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1431 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1431 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1431 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1432 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1433 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1433 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1433 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1433 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1433 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1433 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1433 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1433 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1433 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1433 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1434 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1437 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1438 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1438 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1439 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1439 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1439 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1439 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1439 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1440 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1441 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1441 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1441 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1441 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ controller:1440 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1441 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1442 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1442 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1442 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1443 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1443 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1443 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1443 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1443 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1443 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1443 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1443 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1443 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1443 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1444 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1444 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1444 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1444 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1444 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1444 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1455 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1455 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1455 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1455 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1455 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1455 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1455 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1457 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1457 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1457 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1457 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1457 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1457 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1458 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1458 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1458 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1458 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1458 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1458 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1458 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1458 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1458 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1459 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1459 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1459 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1459 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1459 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1459 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1459 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1459 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1459 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1462 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ controller:1460 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1463 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ location:1463 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1464 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1465 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1465 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1465 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1465 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1465 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1465 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1465 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1465 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1465 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1465 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1466 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1466 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1466 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1466 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1466 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1466 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1466 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1466 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1466 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1466 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1466 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1466 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1466 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1467 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1467 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1467 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1467 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1467 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1467 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1467 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1467 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1468 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1468 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1468 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1468 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ location:1468 ] - [ INFO ] 接收到的数据为: 1 1 
2019-12-18 16:10:17 [ location:1468 ] - [ INFO ] hex: 0101
2019-12-18 16:10:17 [ location:1468 ] - [ ERROR ] 数据解析失败，查看传输数据是否正确
2019-12-18 16:10:17 [ location:1468 ] - [ ERROR ] 解析数据异常，此数据不会发送
2019-12-18 16:10:17 [ controller:1468 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1482 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1482 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1483 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1491 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1491 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1492 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1502 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1502 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1503 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1519 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1519 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1521 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1530 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1531 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1531 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1541 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1541 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1542 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1566 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1566 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ location:1566 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:17 [ location:1566 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:17 [ location:1567 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:17 [ location:1567 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:17 [ location:1567 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:17 [ controller:1567 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1588 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1588 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1589 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ kafka-coordinator-heartbeat-thread | serviceSys:1590 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-0 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:17 [ kafka-coordinator-heartbeat-thread | serviceSys:1590 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-1 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:17 [ controller:1604 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1604 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1604 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1627 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1628 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1629 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1645 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1646 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1648 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1675 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1676 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1676 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1688 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1688 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1689 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1704 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1704 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1705 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1716 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1716 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1716 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1731 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1731 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1732 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1752 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1752 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1752 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1769 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1769 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1770 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1786 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1787 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1789 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1815 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1815 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1817 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1833 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1834 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1834 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1852 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1852 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1853 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1868 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1868 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1868 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1878 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1878 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1879 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1891 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1892 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1892 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1901 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1902 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1902 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1911 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1911 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1912 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1922 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1922 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1922 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1931 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1931 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1931 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1940 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1940 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1940 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:1965 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1965 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1966 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:17 [ controller:1982 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:1983 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:1986 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:1992 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 691 for partition msg0200-0
2019-12-18 16:10:17 [ location:1993 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 683 for partition msg0200-1
2019-12-18 16:10:17 [ location:1993 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:17 [ controller:2003 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2003 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2003 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2023 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2024 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2024 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2043 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2044 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2047 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2063 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2064 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2064 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:2073 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:17 [ controller:2073 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2073 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2074 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ location:2073 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:17 [ location:2074 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:17 [ location:2074 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:17 [ location:2074 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:17 [ controller:2083 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2083 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2084 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2093 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2093 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2094 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2103 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2104 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2104 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2118 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2118 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2118 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2132 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2132 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2133 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2144 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2144 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2145 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2160 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2160 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2161 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2180 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2181 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2182 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2200 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2201 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2201 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2230 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2231 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2231 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2254 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2254 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2255 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:17 [ controller:2271 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:17 [ controller:2271 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:17 [ controller:2272 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2291 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2291 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2291 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2314 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2314 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2315 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2331 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2332 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2333 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2352 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2352 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2353 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2371 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2371 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2371 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2381 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2381 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2382 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2401 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2401 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2402 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2423 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2424 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2424 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2443 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2443 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2443 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2459 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2459 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2460 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ location:2474 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:10:18 [ controller:2481 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2482 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2484 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2498 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2498 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2499 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2509 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2509 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2510 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2518 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2518 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2519 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2530 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2531 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2531 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2540 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2540 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2541 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2557 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2557 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2557 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2567 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2567 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2567 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ location:2581 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:18 [ controller:2581 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ location:2581 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:18 [ controller:2581 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ location:2581 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:18 [ location:2582 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:18 [ location:2582 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:18 [ controller:2582 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2591 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2591 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2592 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2612 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2612 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2613 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2632 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2632 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2633 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2652 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2652 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2653 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2672 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2672 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2673 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2693 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2693 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2693 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2714 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2714 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2714 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2723 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2723 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2724 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2736 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2736 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2736 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2751 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2752 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2752 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2771 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2771 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2772 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2788 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2788 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2789 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2808 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2809 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2810 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2829 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2829 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2830 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2853 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2853 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2853 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2869 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2869 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2871 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2889 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2889 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2890 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2909 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2909 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2910 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2930 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2930 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2931 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2939 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2939 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2940 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2956 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2956 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2956 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2964 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2964 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2965 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2978 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2978 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2979 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ location:2979 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:18 [ location:2988 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 691 for partition msg0200-0
2019-12-18 16:10:18 [ location:2988 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 683 for partition msg0200-1
2019-12-18 16:10:18 [ location:2989 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:18 [ controller:2988 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2989 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:2989 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:2999 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:2999 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3000 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3009 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3009 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3010 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3020 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3020 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3021 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3033 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3033 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3033 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3046 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3046 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3046 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3063 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3063 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3065 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3083 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3083 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3083 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ location:3093 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:18 [ location:3093 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:18 [ location:3094 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:18 [ location:3094 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:18 [ location:3094 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:18 [ controller:3105 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3105 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3105 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3118 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3118 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3119 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3131 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3131 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3132 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3141 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3142 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3142 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3153 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3153 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3154 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3162 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3162 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3162 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3172 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3172 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3173 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3183 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3183 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3183 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3193 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3193 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3194 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3202 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3202 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3203 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3213 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3213 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3214 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3223 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3223 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3223 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3234 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3234 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3235 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3249 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3250 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3250 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3260 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3260 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3260 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:18 [ controller:3270 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:18 [ controller:3270 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:18 [ controller:3272 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3284 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3285 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3287 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3301 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3302 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3302 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3314 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3314 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3315 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3326 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3326 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3327 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3340 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3340 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3341 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3354 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3354 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3355 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3365 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3365 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3366 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3384 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3384 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3385 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3397 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3398 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3398 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3408 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3408 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3408 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3416 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3417 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3417 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3430 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3430 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3431 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3441 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3441 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3442 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3458 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3458 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3459 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3470 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3470 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3471 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ location:3479 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:10:19 [ controller:3487 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3488 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3489 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3504 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3504 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3505 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3516 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3517 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3517 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3536 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3536 ] - [ INFO ] 接收到的数据是{"id":8300,
    "indicate":"12",
    "text":"你好吗"
}
2019-12-18 16:10:19 [ controller:3537 ] - [ INFO ] 开始发送数据 ---383330303a3132c4e3bac3c2f0
2019-12-18 16:10:19 [ controller:3557 ] - [ INFO ] 发送成功 ---
2019-12-18 16:10:19 [ controller:3557 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=150, metadata=''}, command-1=OffsetAndMetadata{offset=150, metadata=''}}
2019-12-18 16:10:19 [ controller:3561 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ controller:3561 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ controller:3561 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ controller:3568 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 150 for partition command-0
2019-12-18 16:10:19 [ controller:3568 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 150 for partition command-1
2019-12-18 16:10:19 [ controller:3568 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=150, metadata=''}, command-1=OffsetAndMetadata{offset=150, metadata=''}}
2019-12-18 16:10:19 [ location:3599 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:19 [ location:3599 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:19 [ location:3599 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ location:3599 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ location:3600 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ kafka-coordinator-heartbeat-thread | serviceSys:3971 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:19 [ location:3975 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:10:19 [ kafka-coordinator-heartbeat-thread | serviceSys:3977 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending Heartbeat request to coordinator 10.211.55.3:9092 (id: 2147483646 rack: null)
2019-12-18 16:10:19 [ controller:3979 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Received successful Heartbeat response
2019-12-18 16:10:19 [ location:3979 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:19 [ location:3983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 691 for partition msg0200-0
2019-12-18 16:10:19 [ location:3983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 683 for partition msg0200-1
2019-12-18 16:10:19 [ location:3983 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:19 [ controller:4069 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-0 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:19 [ controller:4069 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-1 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:19 [ controller:4069 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ controller:4069 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ controller:4069 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ location:4103 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:19 [ location:4103 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:19 [ location:4104 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ location:4104 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:19 [ location:4104 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ location:4482 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:10:20 [ controller:4562 ] - [ WARN ] 没有接收到数据，数据记录数为: 0条。
2019-12-18 16:10:20 [ controller:4563 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=150, metadata=''}, command-1=OffsetAndMetadata{offset=150, metadata=''}}
2019-12-18 16:10:20 [ controller:4567 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 150 for partition command-0
2019-12-18 16:10:20 [ controller:4568 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Committed offset 150 for partition command-1
2019-12-18 16:10:20 [ controller:4568 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Completed asynchronous auto-commit of offsets {command-0=OffsetAndMetadata{offset=150, metadata=''}, command-1=OffsetAndMetadata{offset=150, metadata=''}}
2019-12-18 16:10:20 [ controller:4572 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-0 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ controller:4572 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-1 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ controller:4572 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ controller:4573 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ controller:4573 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ location:4607 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ location:4607 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ location:4607 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ location:4607 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ location:4608 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ location:4984 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:20 [ location:4989 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 691 for partition msg0200-0
2019-12-18 16:10:20 [ location:4989 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Committed offset 683 for partition msg0200-1
2019-12-18 16:10:20 [ location:4989 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Completed asynchronous auto-commit of offsets {msg0200-0=OffsetAndMetadata{offset=691, metadata=''}, msg0200-1=OffsetAndMetadata{offset=683, metadata=''}}
2019-12-18 16:10:20 [ controller:5077 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-0 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ controller:5077 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 150 for partition command-1 returned fetch data (error=NONE, highWaterMark=150, lastStableOffset = 150, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ controller:5078 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-0 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ controller:5078 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition command-1 at offset 150 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ controller:5078 ] - [ DEBUG ] [Consumer clientId=consumer-2, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [command-0, command-1] to broker 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ kafka-coordinator-heartbeat-thread | serviceSys:5112 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 683 for partition msg0200-1 returned fetch data (error=NONE, highWaterMark=683, lastStableOffset = 683, logStartOffset = 407, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ kafka-coordinator-heartbeat-thread | serviceSys:5113 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Fetch READ_UNCOMMITTED at offset 691 for partition msg0200-0 returned fetch data (error=NONE, highWaterMark=691, lastStableOffset = 691, logStartOffset = 415, abortedTransactions = null, recordsSizeInBytes=0)
2019-12-18 16:10:20 [ location:5113 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-1 at offset 683 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ location:5113 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Added READ_UNCOMMITTED fetch request for partition msg0200-0 at offset 691 to node 10.211.55.3:9092 (id: 1 rack: null)
2019-12-18 16:10:20 [ location:5113 ] - [ DEBUG ] [Consumer clientId=consumer-1, groupId=serviceSys] Sending READ_UNCOMMITTED fetch for partitions [msg0200-1, msg0200-0] to broker 10.211.55.3:9092 (id: 1 rack: null)
>>>>>>> b65d7b8dda37aec7bc9305c755d181d5b9efe717
